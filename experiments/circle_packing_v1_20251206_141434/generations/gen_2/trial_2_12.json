{
  "trial_id": "trial_2_12",
  "generation": 2,
  "parent_id": null,
  "code": "import numpy as np\nfrom scipy.optimize import minimize\nfrom scipy.spatial.distance import cdist\n\ndef construct_packing():\n    \"\"\"\n    Constructs an initial packing of 26 circles in [0,1]x[0,1] using a grid layout.\n    \n    Returns:\n        centers: numpy array of shape (26, 2) with circle centers\n        radii: numpy array of shape (26,) with circle radii\n        sum_radii: float, sum of all radii\n    \"\"\"\n    # Initialize 26 circles in a grid pattern\n    # Use a 5x6 grid (30 positions, we'll use 26)\n    grid_x = 6\n    grid_y = 5\n    \n    centers = []\n    for i in range(grid_y):\n        for j in range(grid_x):\n            if len(centers) >= 26:\n                break\n            x = (j + 0.5) / grid_x\n            y = (i + 0.5) / grid_y\n            centers.append([x, y])\n    \n    centers = np.array(centers[:26])\n    \n    # Compute initial radii based on distances\n    radii = compute_radii(centers)\n    sum_radii = np.sum(radii)\n    \n    return centers, radii, sum_radii\n\ndef compute_radii(centers):\n    \"\"\"\n    Compute the maximum feasible radius for each circle given their centers.\n    \n    Args:\n        centers: numpy array of shape (n, 2)\n    \n    Returns:\n        radii: numpy array of shape (n,)\n    \"\"\"\n    n = len(centers)\n    radii = np.zeros(n)\n    \n    for i in range(n):\n        # Distance to boundaries\n        min_radius = min(centers[i, 0], 1 - centers[i, 0], \n                        centers[i, 1], 1 - centers[i, 1])\n        \n        # Distance to other circles\n        for j in range(n):\n            if i != j:\n                dist = np.linalg.norm(centers[i] - centers[j])\n                min_radius = min(min_radius, dist / 2)\n        \n        radii[i] = max(min_radius, 1e-6)\n    \n    return radii\n\ndef compute_gradients(centers, radii):\n    \"\"\"\n    Compute gradients of the objective (sum of radii) with respect to center positions.\n    Uses finite differences for gradient estimation.\n    \n    Args:\n        centers: numpy array of shape (n, 2)\n        radii: numpy array of shape (n,)\n    \n    Returns:\n        gradients: numpy array of shape (n, 2)\n    \"\"\"\n    n = len(centers)\n    gradients = np.zeros_like(centers)\n    epsilon = 1e-6\n    \n    for i in range(n):\n        for dim in range(2):\n            # Perturb center in positive direction\n            centers_plus = centers.copy()\n            centers_plus[i, dim] += epsilon\n            radii_plus = compute_radii(centers_plus)\n            \n            # Perturb center in negative direction\n            centers_minus = centers.copy()\n            centers_minus[i, dim] -= epsilon\n            radii_minus = compute_radii(centers_minus)\n            \n            # Compute gradient using central difference\n            gradients[i, dim] = (np.sum(radii_plus) - np.sum(radii_minus)) / (2 * epsilon)\n    \n    return gradients\n\ndef project_to_feasible(centers, radii, margin=0.001):\n    \"\"\"\n    Project centers back to feasible region, ensuring circles stay within bounds.\n    \n    Args:\n        centers: numpy array of shape (n, 2)\n        radii: numpy array of shape (n,)\n        margin: minimum margin from boundaries\n    \n    Returns:\n        centers: projected centers\n    \"\"\"\n    centers_proj = centers.copy()\n    \n    for i in range(len(centers)):\n        r = max(radii[i], margin)\n        # Clamp to [r, 1-r] in each dimension\n        centers_proj[i, 0] = np.clip(centers_proj[i, 0], r, 1 - r)\n        centers_proj[i, 1] = np.clip(centers_proj[i, 1], r, 1 - r)\n    \n    return centers_proj\n\ndef adam_optimizer(centers, num_iterations=500, learning_rate=0.01, \n                   beta1=0.9, beta2=0.999, epsilon=1e-8):\n    \"\"\"\n    Optimize circle positions using Adam optimizer with momentum.\n    \n    Args:\n        centers: initial centers, shape (n, 2)\n        num_iterations: number of optimization steps\n        learning_rate: learning rate for Adam\n        beta1: exponential decay rate for first moment\n        beta2: exponential decay rate for second moment\n        epsilon: small constant for numerical stability\n    \n    Returns:\n        centers: optimized centers\n        radii: final radii\n        history: list of sum_radii at each iteration\n    \"\"\"\n    n = len(centers)\n    centers = centers.copy()\n    \n    # Initialize Adam parameters\n    m = np.zeros_like(centers)  # First moment\n    v = np.zeros_like(centers)  # Second moment\n    t = 0\n    \n    history = []\n    best_sum = -np.inf\n    best_centers = centers.copy()\n    \n    for iteration in range(num_iterations):\n        t += 1\n        \n        # Compute current radii\n        radii = compute_radii(centers)\n        sum_radii = np.sum(radii)\n        history.append(sum_radii)\n        \n        if sum_radii > best_sum:\n            best_sum = sum_radii\n            best_centers = centers.copy()\n        \n        # Compute gradients\n        gradients = compute_gradients(centers, radii)\n        \n        # Update biased first moment estimate\n        m = beta1 * m + (1 - beta1) * gradients\n        \n        # Update biased second raw moment estimate\n        v = beta2 * v + (1 - beta2) * (gradients ** 2)\n        \n        # Compute bias-corrected first moment estimate\n        m_hat = m / (1 - beta1 ** t)\n        \n        # Compute bias-corrected second raw moment estimate\n        v_hat = v / (1 - beta2 ** t)\n        \n        # Update centers\n        centers += learning_rate * m_hat / (np.sqrt(v_hat) + epsilon)\n        \n        # Project back to feasible region\n        centers = project_to_feasible(centers, radii)\n        \n        if iteration % 50 == 0:\n            print(f\"Iteration {iteration}: sum_radii = {sum_radii:.6f}\")\n    \n    # Return best configuration found\n    radii = compute_radii(best_centers)\n    return best_centers, radii, history\n\ndef refine_with_slsqp(centers, radii):\n    \"\"\"\n    Refine the packing using SLSQP optimizer.\n    \n    Args:\n        centers: initial centers, shape (n, 2)\n        radii: initial radii, shape (n,)\n    \n    Returns:\n        centers: refined centers\n        radii: refined radii\n        sum_radii: sum of refined radii\n    \"\"\"\n    n = len(centers)\n    \n    def objective(x):\n        centers_flat = x.reshape(n, 2)\n        radii = compute_radii(centers_flat)\n        return -np.sum(radii)  # Negative because we minimize\n    \n    def constraint_bounds(x):\n        centers_flat = x.reshape(n, 2)\n        radii = compute_radii(centers_flat)\n        constraints = []\n        \n        # Boundary constraints\n        for i in range(n):\n            constraints.append(centers_flat[i, 0] - radii[i])  # left\n            constraints.append(1 - centers_flat[i, 0] - radii[i])  # right\n            constraints.append(centers_flat[i, 1] - radii[i])  # bottom\n            constraints.append(1 - centers_flat[i, 1] - radii[i])  # top\n        \n        return np.array(constraints)\n    \n    # Bounds for centers\n    bounds = [(0, 1) for _ in range(2 * n)]\n    \n    # Optimize\n    x0 = centers.flatten()\n    result = minimize(objective, x0, method='SLSQP', \n                     bounds=bounds,\n                     options={'maxiter': 200, 'ftol': 1e-9})\n    \n    centers_opt = result.x.reshape(n, 2)\n    radii_opt = compute_radii(centers_opt)\n    sum_radii = np.sum(radii_opt)\n    \n    return centers_opt, radii_opt, sum_radii\n\ndef run_packing():\n    \"\"\"\n    Run the complete packing optimization pipeline.\n    \n    Returns:\n        centers: optimized circle centers, shape (26, 2)\n        radii: optimized circle radii, shape (26,)\n        sum_radii: sum of all radii\n    \"\"\"\n    print(\"Step 1: Initialize with grid...\")\n    centers, radii, sum_radii = construct_packing()\n    print(f\"Initial sum of radii: {sum_radii:.6f}\")\n    \n    print(\"\\nStep 2: Optimize with Adam (momentum-based)...\")\n    centers, radii, history = adam_optimizer(centers, num_iterations=500, learning_rate=0.005)\n    sum_radii = np.sum(radii)\n    print(f\"After Adam optimization: {sum_radii:.6f}\")\n    \n    print(\"\\nStep 3: Refine with SLSQP...\")\n    centers, radii, sum_radii = refine_with_slsqp(centers, radii)\n    print(f\"Final sum of radii: {sum_radii:.6f}\")\n    \n    return centers, radii, sum_radii\n\nif __name__ == \"__main__\":\n    centers, radii, sum_radii = run_packing()\n    \n    print(f\"\\n{'='*50}\")\n    print(f\"Final Results:\")\n    print(f\"Number of circles: {len(centers)}\")\n    print(f\"Sum of radii: {sum_radii:.6f}\")\n    print(f\"Average radius: {np.mean(radii):.6f}\")\n    print(f\"Min radius: {np.min(radii):.6f}\")\n    print(f\"Max radius: {np.max(radii):.6f}\")\n    print(f\"{'='*50}\")",
  "metrics": {
    "valid": true,
    "sum_radii": 2.523048881785187,
    "target_ratio": 0.9575138071291033,
    "combined_score": 0.9575138071291033,
    "eval_time": 51.722086906433105,
    "error": null
  },
  "prompt": "Create a gradient-based optimizer with momentum for 26 circles in [0,1]x[0,1].\n\nStrategy:\n1. Initialize with grid\n2. Compute gradients of objective (sum of radii) with respect to positions\n3. Use momentum-based updates (like Adam optimizer)\n4. Project back to feasible region after each step\n5. Final refinement with SLSQP\n\nInclude construct_packing() and run_packing() functions that return (centers, radii, sum_radii).",
  "response": "```python\nimport numpy as np\nfrom scipy.optimize import minimize\nfrom scipy.spatial.distance import cdist\n\ndef construct_packing():\n    \"\"\"\n    Constructs an initial packing of 26 circles in [0,1]x[0,1] using a grid layout.\n    \n    Returns:\n        centers: numpy array of shape (26, 2) with circle centers\n        radii: numpy array of shape (26,) with circle radii\n        sum_radii: float, sum of all radii\n    \"\"\"\n    # Initialize 26 circles in a grid pattern\n    # Use a 5x6 grid (30 positions, we'll use 26)\n    grid_x = 6\n    grid_y = 5\n    \n    centers = []\n    for i in range(grid_y):\n        for j in range(grid_x):\n            if len(centers) >= 26:\n                break\n            x = (j + 0.5) / grid_x\n            y = (i + 0.5) / grid_y\n            centers.append([x, y])\n    \n    centers = np.array(centers[:26])\n    \n    # Compute initial radii based on distances\n    radii = compute_radii(centers)\n    sum_radii = np.sum(radii)\n    \n    return centers, radii, sum_radii\n\ndef compute_radii(centers):\n    \"\"\"\n    Compute the maximum feasible radius for each circle given their centers.\n    \n    Args:\n        centers: numpy array of shape (n, 2)\n    \n    Returns:\n        radii: numpy array of shape (n,)\n    \"\"\"\n    n = len(centers)\n    radii = np.zeros(n)\n    \n    for i in range(n):\n        # Distance to boundaries\n        min_radius = min(centers[i, 0], 1 - centers[i, 0], \n                        centers[i, 1], 1 - centers[i, 1])\n        \n        # Distance to other circles\n        for j in range(n):\n            if i != j:\n                dist = np.linalg.norm(centers[i] - centers[j])\n                min_radius = min(min_radius, dist / 2)\n        \n        radii[i] = max(min_radius, 1e-6)\n    \n    return radii\n\ndef compute_gradients(centers, radii):\n    \"\"\"\n    Compute gradients of the objective (sum of radii) with respect to center positions.\n    Uses finite differences for gradient estimation.\n    \n    Args:\n        centers: numpy array of shape (n, 2)\n        radii: numpy array of shape (n,)\n    \n    Returns:\n        gradients: numpy array of shape (n, 2)\n    \"\"\"\n    n = len(centers)\n    gradients = np.zeros_like(centers)\n    epsilon = 1e-6\n    \n    for i in range(n):\n        for dim in range(2):\n            # Perturb center in positive direction\n            centers_plus = centers.copy()\n            centers_plus[i, dim] += epsilon\n            radii_plus = compute_radii(centers_plus)\n            \n            # Perturb center in negative direction\n            centers_minus = centers.copy()\n            centers_minus[i, dim] -= epsilon\n            radii_minus = compute_radii(centers_minus)\n            \n            # Compute gradient using central difference\n            gradients[i, dim] = (np.sum(radii_plus) - np.sum(radii_minus)) / (2 * epsilon)\n    \n    return gradients\n\ndef project_to_feasible(centers, radii, margin=0.001):\n    \"\"\"\n    Project centers back to feasible region, ensuring circles stay within bounds.\n    \n    Args:\n        centers: numpy array of shape (n, 2)\n        radii: numpy array of shape (n,)\n        margin: minimum margin from boundaries\n    \n    Returns:\n        centers: projected centers\n    \"\"\"\n    centers_proj = centers.copy()\n    \n    for i in range(len(centers)):\n        r = max(radii[i], margin)\n        # Clamp to [r, 1-r] in each dimension\n        centers_proj[i, 0] = np.clip(centers_proj[i, 0], r, 1 - r)\n        centers_proj[i, 1] = np.clip(centers_proj[i, 1], r, 1 - r)\n    \n    return centers_proj\n\ndef adam_optimizer(centers, num_iterations=500, learning_rate=0.01, \n                   beta1=0.9, beta2=0.999, epsilon=1e-8):\n    \"\"\"\n    Optimize circle positions using Adam optimizer with momentum.\n    \n    Args:\n        centers: initial centers, shape (n, 2)\n        num_iterations: number of optimization steps\n        learning_rate: learning rate for Adam\n        beta1: exponential decay rate for first moment\n        beta2: exponential decay rate for second moment\n        epsilon: small constant for numerical stability\n    \n    Returns:\n        centers: optimized centers\n        radii: final radii\n        history: list of sum_radii at each iteration\n    \"\"\"\n    n = len(centers)\n    centers = centers.copy()\n    \n    # Initialize Adam parameters\n    m = np.zeros_like(centers)  # First moment\n    v = np.zeros_like(centers)  # Second moment\n    t = 0\n    \n    history = []\n    best_sum = -np.inf\n    best_centers = centers.copy()\n    \n    for iteration in range(num_iterations):\n        t += 1\n        \n        # Compute current radii\n        radii = compute_radii(centers)\n        sum_radii = np.sum(radii)\n        history.append(sum_radii)\n        \n        if sum_radii > best_sum:\n            best_sum = sum_radii\n            best_centers = centers.copy()\n        \n        # Compute gradients\n        gradients = compute_gradients(centers, radii)\n        \n        # Update biased first moment estimate\n        m = beta1 * m + (1 - beta1) * gradients\n        \n        # Update biased second raw moment estimate\n        v = beta2 * v + (1 - beta2) * (gradients ** 2)\n        \n        # Compute bias-corrected first moment estimate\n        m_hat = m / (1 - beta1 ** t)\n        \n        # Compute bias-corrected second raw moment estimate\n        v_hat = v / (1 - beta2 ** t)\n        \n        # Update centers\n        centers += learning_rate * m_hat / (np.sqrt(v_hat) + epsilon)\n        \n        # Project back to feasible region\n        centers = project_to_feasible(centers, radii)\n        \n        if iteration % 50 == 0:\n            print(f\"Iteration {iteration}: sum_radii = {sum_radii:.6f}\")\n    \n    # Return best configuration found\n    radii = compute_radii(best_centers)\n    return best_centers, radii, history\n\ndef refine_with_slsqp(centers, radii):\n    \"\"\"\n    Refine the packing using SLSQP optimizer.\n    \n    Args:\n        centers: initial centers, shape (n, 2)\n        radii: initial radii, shape (n,)\n    \n    Returns:\n        centers: refined centers\n        radii: refined radii\n        sum_radii: sum of refined radii\n    \"\"\"\n    n = len(centers)\n    \n    def objective(x):\n        centers_flat = x.reshape(n, 2)\n        radii = compute_radii(centers_flat)\n        return -np.sum(radii)  # Negative because we minimize\n    \n    def constraint_bounds(x):\n        centers_flat = x.reshape(n, 2)\n        radii = compute_radii(centers_flat)\n        constraints = []\n        \n        # Boundary constraints\n        for i in range(n):\n            constraints.append(centers_flat[i, 0] - radii[i])  # left\n            constraints.append(1 - centers_flat[i, 0] - radii[i])  # right\n            constraints.append(centers_flat[i, 1] - radii[i])  # bottom\n            constraints.append(1 - centers_flat[i, 1] - radii[i])  # top\n        \n        return np.array(constraints)\n    \n    # Bounds for centers\n    bounds = [(0, 1) for _ in range(2 * n)]\n    \n    # Optimize\n    x0 = centers.flatten()\n    result = minimize(objective, x0, method='SLSQP', \n                     bounds=bounds,\n                     options={'maxiter': 200, 'ftol': 1e-9})\n    \n    centers_opt = result.x.reshape(n, 2)\n    radii_opt = compute_radii(centers_opt)\n    sum_radii = np.sum(radii_opt)\n    \n    return centers_opt, radii_opt, sum_radii\n\ndef run_packing():\n    \"\"\"\n    Run the complete packing optimization pipeline.\n    \n    Returns:\n        centers: optimized circle centers, shape (26, 2)\n        radii: optimized circle radii, shape (26,)\n        sum_radii: sum of all radii\n    \"\"\"\n    print(\"Step 1: Initialize with grid...\")\n    centers, radii, sum_radii = construct_packing()\n    print(f\"Initial sum of radii: {sum_radii:.6f}\")\n    \n    print(\"\\nStep 2: Optimize with Adam (momentum-based)...\")\n    centers, radii, history = adam_optimizer(centers, num_iterations=500, learning_rate=0.005)\n    sum_radii = np.sum(radii)\n    print(f\"After Adam optimization: {sum_radii:.6f}\")\n    \n    print(\"\\nStep 3: Refine with SLSQP...\")\n    centers, radii, sum_radii = refine_with_slsqp(centers, radii)\n    print(f\"Final sum of radii: {sum_radii:.6f}\")\n    \n    return centers, radii, sum_radii\n\nif __name__ == \"__main__\":\n    centers, radii, sum_radii = run_packing()\n    \n    print(f\"\\n{'='*50}\")\n    print(f\"Final Results:\")\n    print(f\"Number of circles: {len(centers)}\")\n    print(f\"Sum of radii: {sum_radii:.6f}\")\n    print(f\"Average radius: {np.mean(radii):.6f}\")\n    print(f\"Min radius: {np.min(radii):.6f}\")\n    print(f\"Max radius: {np.max(radii):.6f}\")\n    print(f\"{'='*50}\")\n```\n\nThis implementation provides:\n\n1. **Grid Initialization**: `construct_packing()` creates an initial 5\u00d76 grid layout for 26 circles\n2. **Gradient Computation**: Uses finite differences to estimate gradients of the objective\n3. **Adam Optimizer**: Implements momentum-based optimization with first and second moment estimates\n4. **Projection**: Ensures circles stay within [0,1]\u00d7[0,1] bounds\n5. **SLSQP Refinement**: Final polish using scipy's constrained optimizer\n6. **Complete Pipeline**: `run_packing()` orchestrates all steps\n\nThe Adam optimizer uses adaptive learning rates and momentum to efficiently navigate the optimization landscape, while the final SLSQP step ensures constraint satisfaction and local optimality.",
  "reasoning": "This implementation provides:\n\n1. **Grid Initialization**: `construct_packing()` creates an initial 5\u00d76 grid layout for 26 circles\n2. **Gradient Computation**: Uses finite differences to estimate gradients of the objective\n3. **Adam Optimizer**: Implements momentum-based optimization with first and second moment estimates\n4. **Projection**: Ensures circles stay within [0,1]\u00d7[0,1] bounds\n5. **SLSQP Refinement**: Final polish using scipy's constrained optimizer\n6. **Complete Pipeline**: `run_packing()` orchestrates all steps\n\nThe Adam optimizer uses adaptive learning rates and momentum to efficiently navigate the optimization landscape, while the final SLSQP step ensures constraint satisfaction and local optimality.",
  "timestamp": "2025-12-06T14:29:55.734253",
  "cost_data": null
}