{
  "trial_id": "trial_1_2",
  "generation": 1,
  "parent_id": "trial_0_4",
  "code": "import numpy as np\nfrom scipy.optimize import minimize, differential_evolution, basinhopping\nfrom scipy.stats import qmc\nfrom typing import Tuple, Optional\nfrom concurrent.futures import ProcessPoolExecutor, as_completed\nimport multiprocessing as mp\n\ndef construct_packing() -> Tuple[np.ndarray, np.ndarray, float]:\n    \"\"\"\n    Returns:\n        centers: np.array of shape (26, 2)\n        radii: np.array of shape (26,)\n        sum_radii: float\n    \"\"\"\n    n_circles = 26\n    n_trials = 20\n    \n    # Use parallel evaluation for multiple starting points\n    n_workers = min(mp.cpu_count(), 8)\n    \n    best_result = None\n    best_sum_radii = 0\n    \n    # Try different optimization strategies in parallel\n    with ProcessPoolExecutor(max_workers=n_workers) as executor:\n        futures = []\n        \n        # Strategy 1: Quasi-random initialization with local optimization (Sobol)\n        for trial in range(n_trials // 2):\n            futures.append(executor.submit(\n                optimize_with_quasirandom, n_circles, trial, 'sobol'\n            ))\n        \n        # Strategy 2: Quasi-random initialization with local optimization (Halton)\n        for trial in range(n_trials // 4):\n            futures.append(executor.submit(\n                optimize_with_quasirandom, n_circles, trial, 'halton'\n            ))\n        \n        # Strategy 3: Differential Evolution\n        futures.append(executor.submit(\n            optimize_with_differential_evolution, n_circles\n        ))\n        \n        # Strategy 4: Basin Hopping with best quasi-random start\n        futures.append(executor.submit(\n            optimize_with_basin_hopping, n_circles\n        ))\n        \n        # Collect results\n        for future in as_completed(futures):\n            try:\n                result = future.result()\n                if result is not None:\n                    centers_opt, radii_opt, sum_radii = result\n                    if sum_radii > best_sum_radii:\n                        best_sum_radii = sum_radii\n                        best_result = result\n                        print(f\"New best: {sum_radii:.6f}\")\n            except Exception as e:\n                print(f\"Optimization failed: {e}\")\n    \n    if best_result is None:\n        # Fallback: return a simple grid configuration\n        centers, radii = create_grid_packing(n_circles)\n        sum_radii = np.sum(radii)\n        best_result = (centers, radii, sum_radii)\n    \n    return best_result\n\ndef generate_quasirandom_initial(n_circles: int, seed: int, method: str = 'sobol') -> np.ndarray:\n    \"\"\"\n    Generate quasi-random initial positions using Sobol or Halton sequences\n    \"\"\"\n    if method == 'sobol':\n        sampler = qmc.Sobol(d=2, scramble=True, seed=seed)\n        centers = sampler.random(n_circles)\n    elif method == 'halton':\n        sampler = qmc.Halton(d=2, scramble=True, seed=seed)\n        centers = sampler.random(n_circles)\n    else:\n        # Latin Hypercube Sampling\n        sampler = qmc.LatinHypercube(d=2, seed=seed)\n        centers = sampler.random(n_circles)\n    \n    return centers\n\ndef optimize_with_quasirandom(n_circles: int, trial: int, method: str) -> Optional[Tuple[np.ndarray, np.ndarray, float]]:\n    \"\"\"\n    Optimize using quasi-random initialization with adaptive penalty\n    \"\"\"\n    centers = generate_quasirandom_initial(n_circles, trial, method)\n    radii = np.full(n_circles, 0.05)\n    \n    return optimize_packing_adaptive(centers, radii)\n\ndef optimize_with_differential_evolution(n_circles: int) -> Optional[Tuple[np.ndarray, np.ndarray, float]]:\n    \"\"\"\n    Use Differential Evolution for global optimization\n    \"\"\"\n    # Bounds for variables\n    bounds = []\n    # Centers: [0, 1]\n    for i in range(2 * n_circles):\n        bounds.append((0, 1))\n    # Radii: [0.001, 0.5]\n    for i in range(n_circles):\n        bounds.append((0.001, 0.5))\n    \n    def objective_with_penalty(x):\n        centers = x[:2*n_circles].reshape(n_circles, 2)\n        radii = x[2*n_circles:]\n        \n        # Base objective: maximize sum of radii\n        obj = -np.sum(radii)\n        \n        # Adaptive penalty for constraint violations\n        penalty = compute_penalty(centers, radii, penalty_weight=1000.0)\n        \n        return obj + penalty\n    \n    try:\n        result = differential_evolution(\n            objective_with_penalty,\n            bounds,\n            strategy='best1bin',\n            maxiter=300,\n            popsize=15,\n            mutation=(0.5, 1.5),\n            recombination=0.7,\n            seed=None,\n            workers=1,\n            updating='deferred',\n            polish=True\n        )\n        \n        if result.success or result.fun < 0:\n            centers_opt = result.x[:2*n_circles].reshape(n_circles, 2)\n            radii_opt = result.x[2*n_circles:]\n            \n            # Verify and potentially polish with local optimization\n            if verify_packing(centers_opt, radii_opt, tol=1e-3):\n                # Polish with local optimization\n                polished = optimize_packing_adaptive(centers_opt, radii_opt, max_iter=200)\n                if polished is not None:\n                    return polished\n                \n                sum_radii = np.sum(radii_opt)\n                return centers_opt, radii_opt, sum_radii\n    except Exception as e:\n        print(f\"Differential evolution failed: {e}\")\n    \n    return None\n\ndef optimize_with_basin_hopping(n_circles: int) -> Optional[Tuple[np.ndarray, np.ndarray, float]]:\n    \"\"\"\n    Use Basin Hopping for global optimization\n    \"\"\"\n    # Start with best quasi-random configuration\n    centers = generate_quasirandom_initial(n_circles, 42, 'sobol')\n    radii = np.full(n_circles, 0.05)\n    \n    x0 = np.concatenate([centers.flatten(), radii])\n    \n    # Bounds for variables\n    bounds = []\n    for i in range(2 * n_circles):\n        bounds.append((0, 1))\n    for i in range(n_circles):\n        bounds.append((0.001, 0.5))\n    \n    def objective_with_penalty(x):\n        centers = x[:2*n_circles].reshape(n_circles, 2)\n        radii = x[2*n_circles:]\n        \n        obj = -np.sum(radii)\n        penalty = compute_penalty(centers, radii, penalty_weight=500.0)\n        \n        return obj + penalty\n    \n    minimizer_kwargs = {\n        \"method\": \"L-BFGS-B\",\n        \"bounds\": bounds,\n        \"options\": {\"maxiter\": 100}\n    }\n    \n    try:\n        result = basinhopping(\n            objective_with_penalty,\n            x0,\n            minimizer_kwargs=minimizer_kwargs,\n            niter=50,\n            T=0.5,\n            stepsize=0.1,\n            seed=42\n        )\n        \n        if result.fun < 0:\n            centers_opt = result.x[:2*n_circles].reshape(n_circles, 2)\n            radii_opt = result.x[2*n_circles:]\n            \n            if verify_packing(centers_opt, radii_opt, tol=1e-3):\n                sum_radii = np.sum(radii_opt)\n                return centers_opt, radii_opt, sum_radii\n    except Exception as e:\n        print(f\"Basin hopping failed: {e}\")\n    \n    return None\n\ndef compute_penalty(centers: np.ndarray, radii: np.ndarray, penalty_weight: float = 100.0) -> float:\n    \"\"\"\n    Compute adaptive penalty for constraint violations\n    \"\"\"\n    n_circles = len(centers)\n    penalty = 0.0\n    \n    # Penalty for circles outside unit square\n    for i in range(n_circles):\n        if centers[i, 0] - radii[i] < 0:\n            penalty += penalty_weight * (radii[i] - centers[i, 0])**2\n        if centers[i, 0] + radii[i] > 1:\n            penalty += penalty_weight * (centers[i, 0] + radii[i] - 1)**2\n        if centers[i, 1] - radii[i] < 0:\n            penalty += penalty_weight * (radii[i] - centers[i, 1])**2\n        if centers[i, 1] + radii[i] > 1:\n            penalty += penalty_weight * (centers[i, 1] + radii[i] - 1)**2\n    \n    # Penalty for overlaps\n    for i in range(n_circles):\n        for j in range(i+1, n_circles):\n            dist = np.sqrt((centers[i, 0] - centers[j, 0])**2 + \n                          (centers[i, 1] - centers[j, 1])**2)\n            overlap = radii[i] + radii[j] - dist\n            if overlap > 0:\n                penalty += penalty_weight * overlap**2\n    \n    # Penalty for negative radii\n    for i in range(n_circles):\n        if radii[i] < 0:\n            penalty += penalty_weight * radii[i]**2\n    \n    return penalty\n\ndef optimize_packing_adaptive(centers_init: np.ndarray, radii_init: np.ndarray, \n                               max_iter: int = 500) -> Optional[Tuple[np.ndarray, np.ndarray, float]]:\n    \"\"\"\n    Optimize a packing configuration with adaptive penalty weights\n    \"\"\"\n    n_circles = len(centers_init)\n    x0 = np.concatenate([centers_init.flatten(), radii_init])\n    \n    # Adaptive penalty approach: increase penalty weight if constraints violated\n    penalty_weights = [10.0, 50.0, 200.0, 1000.0]\n    \n    best_result = None\n    best_sum_radii = 0\n    \n    for penalty_weight in penalty_weights:\n        def objective(x):\n            centers = x[:2*n_circles].reshape(n_circles, 2)\n            radii = x[2*n_circles:]\n            \n            obj = -np.sum(radii)\n            penalty = compute_penalty(centers, radii, penalty_weight)\n            \n            return obj + penalty\n        \n        # Bounds for variables\n        bounds = []\n        for i in range(2*n_circles):\n            bounds.append((0, 1))\n        for i in range(n_circles):\n            bounds.append((0.001, 0.5))\n        \n        try:\n            result = minimize(\n                objective,\n                x0,\n                method='L-BFGS-B',\n                bounds=bounds,\n                options={'maxiter': max_iter, 'ftol': 1e-9}\n            )\n            \n            if result.fun < 0:\n                centers_opt = result.x[:2*n_circles].reshape(n_circles, 2)\n                radii_opt = result.x[2*n_circles:]\n                \n                # Verify solution\n                if verify_packing(centers_opt, radii_opt, tol=1e-4):\n                    sum_radii = np.sum(radii_opt)\n                    if sum_radii > best_sum_radii:\n                        best_sum_radii = sum_radii\n                        best_result = (centers_opt, radii_opt, sum_radii)\n                    \n                    # Use this as starting point for next iteration\n                    x0 = result.x\n                else:\n                    # Constraints violated, increase penalty and continue\n                    x0 = result.x\n        except Exception as e:\n            pass\n    \n    return best_result\n\ndef verify_packing(centers: np.ndarray, radii: np.ndarray, tol: float = 1e-4) -> bool:\n    \"\"\"\n    Verify that a packing is valid\n    \"\"\"\n    n_circles = len(centers)\n    \n    # Check circles inside unit square\n    for i in range(n_circles):\n        if (centers[i, 0] - radii[i] < -tol or \n            centers[i, 0] + radii[i] > 1 + tol or\n            centers[i, 1] - radii[i] < -tol or \n            centers[i, 1] + radii[i] > 1 + tol):\n            return False\n    \n    # Check no overlaps\n    for i in range(n_circles):\n        for j in range(i+1, n_circles):\n            dist = np.sqrt((centers[i, 0] - centers[j, 0])**2 + \n                          (centers[i, 1] - centers[j, 1])**2)\n            if dist < radii[i] + radii[j] - tol:\n                return False\n    \n    # Check positive radii\n    if np.any(radii < 0):\n        return False\n    \n    return True\n\ndef create_grid_packing(n_circles: int) -> Tuple[np.ndarray, np.ndarray]:\n    \"\"\"\n    Create a simple grid-based packing as fallback\n    \"\"\"\n    grid_size = 6\n    spacing = 1.0 / grid_size\n    radius = spacing / 2.2\n    \n    centers = []\n    count = 0\n    for i in range(grid_size):\n        for j in range(grid_size):\n            if count >= n_circles:\n                break\n            x = (i + 0.5) * spacing\n            y = (j + 0.5) * spacing\n            centers.append([x, y])\n            count += 1\n        if count >= n_circles:\n            break\n    \n    centers = np.array(centers[:n_circles])\n    radii = np.full(n_circles, radius)\n    \n    return centers, radii\n\ndef run_packing():\n    return construct_packing()\n\nif __name__ == \"__main__\":\n    centers, radii, sum_radii = run_packing()\n    print(f\"\\n{'='*50}\")\n    print(f\"Final Results:\")\n    print(f\"{'='*50}\")\n    print(f\"Sum of radii: {sum_radii:.6f}\")\n    print(f\"Average radius: {np.mean(radii):.6f}\")\n    print(f\"Min radius: {np.min(radii):.6f}\")\n    print(f\"Max radius: {np.max(radii):.6f}\")\n    print(f\"Valid packing: {verify_packing(centers, radii)}\")\n    print(f\"{'='*50}\")",
  "metrics": {
    "valid": true,
    "sum_radii": 1.9696969696969693,
    "target_ratio": 0.7475130814789258,
    "combined_score": 0.7475130814789258,
    "eval_time": 0.8332827091217041,
    "error": null
  },
  "prompt": "Improve this random search with local optimization approach:\n\nimport numpy as np\nfrom scipy.optimize import minimize\nfrom typing import Tuple\n\ndef construct_packing() -> Tuple[np.ndarray, np.ndarray, float]:\n    \"\"\"\n    Returns:\n        centers: np.array of shape (26, 2)\n        radii: np.array of shape (26,)\n        sum_radii: float\n    \"\"\"\n    n_circles = 26\n    n_trials = 15\n    \n    best_result = None\n    best_sum_radii = 0\n    \n    for trial in range(n_trials):\n        # Generate random initial configuration\n        centers = np.random.rand(n_circles, 2)\n        \n        # Initial guess for radii (small values)\n        radii = np.full(n_circles, 0.05)\n        \n        # Optimize\n        result = optimize_packing(centers, radii)\n        \n        if result is not None:\n            centers_opt, radii_opt, sum_radii = result\n            if sum_radii > best_sum_radii:\n                best_sum_radii = sum_radii\n                best_result = result\n    \n    if best_result is None:\n        # Fallback: return a simple grid configuration\n        centers, radii = create_grid_packing(n_circles)\n        sum_radii = np.sum(radii)\n        best_result = (centers, radii, sum_radii)\n    \n    return best_result\n\ndef optimize_packing(centers_init: np.ndarray, radii_init: np.ndarray) -> Tuple[np.ndarray, np.ndarray, float]:\n    \"\"\"\n    Optimize a packing configuration using scipy.optimize\n    \"\"\"\n    n_circles = len(centers_init)\n    \n    # Pack parameters: [centers (flattened), radii]\n    x0 = np.concatenate([centers_init.flatten(), radii_init])\n    \n    def objective(x):\n        # Minimize negative sum of radii (maximize sum of radii)\n        radii = x[2*n_circles:]\n        return -np.sum(radii)\n    \n    def constraints_func(x):\n        centers = x[:2*n_circles].reshape(n_circles, 2)\n        radii = x[2*n_circles:]\n        \n        constraints = []\n        \n        # Constraint: circles inside unit square\n        for i in range(n_circles):\n            constraints.append(centers[i, 0] - radii[i])  # x - r >= 0\n            constraints.append(1 - centers[i, 0] - radii[i])  # 1 - x - r >= 0\n            constraints.append(centers[i, 1] - radii[i])  # y - r >= 0\n            constraints.append(1 - centers[i, 1] - radii[i])  # 1 - y - r >= 0\n        \n        # Constraint: no overlaps (distance >= sum of radii)\n        for i in range(n_circles):\n            for j in range(i+1, n_circles):\n                dist = np.sqrt((centers[i, 0] - centers[j, 0])**2 + \n                              (centers[i, 1] - centers[j, 1])**2)\n                constraints.append(dist - radii[i] - radii[j])\n        \n        # Constraint: radii positive\n        for i in range(n_circles):\n            constraints.append(radii[i])\n        \n        return np.array(constraints)\n    \n    # Bounds for variables\n    bounds = []\n    # Centers: [0, 1]\n    for i in range(2*n_circles):\n        bounds.append((0, 1))\n    # Radii: [0.001, 0.5]\n    for i in range(n_circles):\n        bounds.append((0.001, 0.5))\n    \n    # Constraints\n    constraints = {'type': 'ineq', 'fun': constraints_func}\n    \n    # Optimize\n    try:\n        result = minimize(\n            objective,\n            x0,\n            method='SLSQP',\n            bounds=bounds,\n            constraints=constraints,\n            options={'maxiter': 500, 'ftol': 1e-6}\n        )\n        \n        if result.success or result.fun < 0:\n            centers_opt = result.x[:2*n_circles].reshape(n_circles, 2)\n            radii_opt = result.x[2*n_circles:]\n            sum_radii = np.sum(radii_opt)\n            \n            # Verify solution\n            if verify_packing(centers_opt, radii_opt):\n                return centers_opt, radii_opt, sum_radii\n    except:\n        pass\n    \n    return None\n\ndef verify_packing(centers: np.ndarray, radii: np.ndarray, tol: float = 1e-4) -> bool:\n    \"\"\"\n    Verify that a packing is valid\n    \"\"\"\n    n_circles = len(centers)\n    \n    # Check circles inside unit square\n    for i in range(n_circles):\n        if (centers[i, 0] - radii[i] < -tol or \n            centers[i, 0] + radii[i] > 1 + tol or\n            centers[i, 1] - radii[i] < -tol or \n            centers[i, 1] + radii[i] > 1 + tol):\n            return False\n    \n    # Check no overlaps\n    for i in range(n_circles):\n        for j in range(i+1, n_circles):\n            dist = np.sqrt((centers[i, 0] - centers[j, 0])**2 + \n                          (centers[i, 1] - centers[j, 1])**2)\n            if dist < radii[i] + radii[j] - tol:\n                return False\n    \n    # Check positive radii\n    if np.any(radii < 0):\n        return False\n    \n    return True\n\ndef create_grid_packing(n_circles: int) -> Tuple[np.ndarray, np.ndarray]:\n    \"\"\"\n    Create a simple grid-based packing as fallback\n    \"\"\"\n    # Create a 6x5 grid (30 positions, use 26)\n    grid_size = 6\n    spacing = 1.0 / grid_size\n    radius = spacing / 2.2  # Leave some margin\n    \n    centers = []\n    count = 0\n    for i in range(grid_size):\n        for j in range(grid_size):\n            if count >= n_circles:\n                break\n            x = (i + 0.5) * spacing\n            y = (j + 0.5) * spacing\n            centers.append([x, y])\n            count += 1\n        if count >= n_circles:\n            break\n    \n    centers = np.array(centers[:n_circles])\n    radii = np.full(n_circles, radius)\n    \n    return centers, radii\n\ndef run_packing():\n    return construct_packing()\n\nif __name__ == \"__main__\":\n    centers, radii, sum_radii = run_packing()\n    print(f\"Sum of radii: {sum_radii:.6f}\")\n    print(f\"Average radius: {np.mean(radii):.6f}\")\n    print(f\"Valid packing: {verify_packing(centers, radii)}\")\n\nMake these improvements:\n1. Replace pure random initialization with quasi-random sequences (Sobol, Halton)\n2. Add adaptive penalty weights that increase for violated constraints\n3. Use basin-hopping or differential evolution for global optimization\n4. Implement parallel evaluation of multiple starting points\n\nFocus on better global optimization through smarter sampling.",
  "response": "Here's an improved version with better global optimization strategies:\n\n```python\nimport numpy as np\nfrom scipy.optimize import minimize, differential_evolution, basinhopping\nfrom scipy.stats import qmc\nfrom typing import Tuple, Optional\nfrom concurrent.futures import ProcessPoolExecutor, as_completed\nimport multiprocessing as mp\n\ndef construct_packing() -> Tuple[np.ndarray, np.ndarray, float]:\n    \"\"\"\n    Returns:\n        centers: np.array of shape (26, 2)\n        radii: np.array of shape (26,)\n        sum_radii: float\n    \"\"\"\n    n_circles = 26\n    n_trials = 20\n    \n    # Use parallel evaluation for multiple starting points\n    n_workers = min(mp.cpu_count(), 8)\n    \n    best_result = None\n    best_sum_radii = 0\n    \n    # Try different optimization strategies in parallel\n    with ProcessPoolExecutor(max_workers=n_workers) as executor:\n        futures = []\n        \n        # Strategy 1: Quasi-random initialization with local optimization (Sobol)\n        for trial in range(n_trials // 2):\n            futures.append(executor.submit(\n                optimize_with_quasirandom, n_circles, trial, 'sobol'\n            ))\n        \n        # Strategy 2: Quasi-random initialization with local optimization (Halton)\n        for trial in range(n_trials // 4):\n            futures.append(executor.submit(\n                optimize_with_quasirandom, n_circles, trial, 'halton'\n            ))\n        \n        # Strategy 3: Differential Evolution\n        futures.append(executor.submit(\n            optimize_with_differential_evolution, n_circles\n        ))\n        \n        # Strategy 4: Basin Hopping with best quasi-random start\n        futures.append(executor.submit(\n            optimize_with_basin_hopping, n_circles\n        ))\n        \n        # Collect results\n        for future in as_completed(futures):\n            try:\n                result = future.result()\n                if result is not None:\n                    centers_opt, radii_opt, sum_radii = result\n                    if sum_radii > best_sum_radii:\n                        best_sum_radii = sum_radii\n                        best_result = result\n                        print(f\"New best: {sum_radii:.6f}\")\n            except Exception as e:\n                print(f\"Optimization failed: {e}\")\n    \n    if best_result is None:\n        # Fallback: return a simple grid configuration\n        centers, radii = create_grid_packing(n_circles)\n        sum_radii = np.sum(radii)\n        best_result = (centers, radii, sum_radii)\n    \n    return best_result\n\ndef generate_quasirandom_initial(n_circles: int, seed: int, method: str = 'sobol') -> np.ndarray:\n    \"\"\"\n    Generate quasi-random initial positions using Sobol or Halton sequences\n    \"\"\"\n    if method == 'sobol':\n        sampler = qmc.Sobol(d=2, scramble=True, seed=seed)\n        centers = sampler.random(n_circles)\n    elif method == 'halton':\n        sampler = qmc.Halton(d=2, scramble=True, seed=seed)\n        centers = sampler.random(n_circles)\n    else:\n        # Latin Hypercube Sampling\n        sampler = qmc.LatinHypercube(d=2, seed=seed)\n        centers = sampler.random(n_circles)\n    \n    return centers\n\ndef optimize_with_quasirandom(n_circles: int, trial: int, method: str) -> Optional[Tuple[np.ndarray, np.ndarray, float]]:\n    \"\"\"\n    Optimize using quasi-random initialization with adaptive penalty\n    \"\"\"\n    centers = generate_quasirandom_initial(n_circles, trial, method)\n    radii = np.full(n_circles, 0.05)\n    \n    return optimize_packing_adaptive(centers, radii)\n\ndef optimize_with_differential_evolution(n_circles: int) -> Optional[Tuple[np.ndarray, np.ndarray, float]]:\n    \"\"\"\n    Use Differential Evolution for global optimization\n    \"\"\"\n    # Bounds for variables\n    bounds = []\n    # Centers: [0, 1]\n    for i in range(2 * n_circles):\n        bounds.append((0, 1))\n    # Radii: [0.001, 0.5]\n    for i in range(n_circles):\n        bounds.append((0.001, 0.5))\n    \n    def objective_with_penalty(x):\n        centers = x[:2*n_circles].reshape(n_circles, 2)\n        radii = x[2*n_circles:]\n        \n        # Base objective: maximize sum of radii\n        obj = -np.sum(radii)\n        \n        # Adaptive penalty for constraint violations\n        penalty = compute_penalty(centers, radii, penalty_weight=1000.0)\n        \n        return obj + penalty\n    \n    try:\n        result = differential_evolution(\n            objective_with_penalty,\n            bounds,\n            strategy='best1bin',\n            maxiter=300,\n            popsize=15,\n            mutation=(0.5, 1.5),\n            recombination=0.7,\n            seed=None,\n            workers=1,\n            updating='deferred',\n            polish=True\n        )\n        \n        if result.success or result.fun < 0:\n            centers_opt = result.x[:2*n_circles].reshape(n_circles, 2)\n            radii_opt = result.x[2*n_circles:]\n            \n            # Verify and potentially polish with local optimization\n            if verify_packing(centers_opt, radii_opt, tol=1e-3):\n                # Polish with local optimization\n                polished = optimize_packing_adaptive(centers_opt, radii_opt, max_iter=200)\n                if polished is not None:\n                    return polished\n                \n                sum_radii = np.sum(radii_opt)\n                return centers_opt, radii_opt, sum_radii\n    except Exception as e:\n        print(f\"Differential evolution failed: {e}\")\n    \n    return None\n\ndef optimize_with_basin_hopping(n_circles: int) -> Optional[Tuple[np.ndarray, np.ndarray, float]]:\n    \"\"\"\n    Use Basin Hopping for global optimization\n    \"\"\"\n    # Start with best quasi-random configuration\n    centers = generate_quasirandom_initial(n_circles, 42, 'sobol')\n    radii = np.full(n_circles, 0.05)\n    \n    x0 = np.concatenate([centers.flatten(), radii])\n    \n    # Bounds for variables\n    bounds = []\n    for i in range(2 * n_circles):\n        bounds.append((0, 1))\n    for i in range(n_circles):\n        bounds.append((0.001, 0.5))\n    \n    def objective_with_penalty(x):\n        centers = x[:2*n_circles].reshape(n_circles, 2)\n        radii = x[2*n_circles:]\n        \n        obj = -np.sum(radii)\n        penalty = compute_penalty(centers, radii, penalty_weight=500.0)\n        \n        return obj + penalty\n    \n    minimizer_kwargs = {\n        \"method\": \"L-BFGS-B\",\n        \"bounds\": bounds,\n        \"options\": {\"maxiter\": 100}\n    }\n    \n    try:\n        result = basinhopping(\n            objective_with_penalty,\n            x0,\n            minimizer_kwargs=minimizer_kwargs,\n            niter=50,\n            T=0.5,\n            stepsize=0.1,\n            seed=42\n        )\n        \n        if result.fun < 0:\n            centers_opt = result.x[:2*n_circles].reshape(n_circles, 2)\n            radii_opt = result.x[2*n_circles:]\n            \n            if verify_packing(centers_opt, radii_opt, tol=1e-3):\n                sum_radii = np.sum(radii_opt)\n                return centers_opt, radii_opt, sum_radii\n    except Exception as e:\n        print(f\"Basin hopping failed: {e}\")\n    \n    return None\n\ndef compute_penalty(centers: np.ndarray, radii: np.ndarray, penalty_weight: float = 100.0) -> float:\n    \"\"\"\n    Compute adaptive penalty for constraint violations\n    \"\"\"\n    n_circles = len(centers)\n    penalty = 0.0\n    \n    # Penalty for circles outside unit square\n    for i in range(n_circles):\n        if centers[i, 0] - radii[i] < 0:\n            penalty += penalty_weight * (radii[i] - centers[i, 0])**2\n        if centers[i, 0] + radii[i] > 1:\n            penalty += penalty_weight * (centers[i, 0] + radii[i] - 1)**2\n        if centers[i, 1] - radii[i] < 0:\n            penalty += penalty_weight * (radii[i] - centers[i, 1])**2\n        if centers[i, 1] + radii[i] > 1:\n            penalty += penalty_weight * (centers[i, 1] + radii[i] - 1)**2\n    \n    # Penalty for overlaps\n    for i in range(n_circles):\n        for j in range(i+1, n_circles):\n            dist = np.sqrt((centers[i, 0] - centers[j, 0])**2 + \n                          (centers[i, 1] - centers[j, 1])**2)\n            overlap = radii[i] + radii[j] - dist\n            if overlap > 0:\n                penalty += penalty_weight * overlap**2\n    \n    # Penalty for negative radii\n    for i in range(n_circles):\n        if radii[i] < 0:\n            penalty += penalty_weight * radii[i]**2\n    \n    return penalty\n\ndef optimize_packing_adaptive(centers_init: np.ndarray, radii_init: np.ndarray, \n                               max_iter: int = 500) -> Optional[Tuple[np.ndarray, np.ndarray, float]]:\n    \"\"\"\n    Optimize a packing configuration with adaptive penalty weights\n    \"\"\"\n    n_circles = len(centers_init)\n    x0 = np.concatenate([centers_init.flatten(), radii_init])\n    \n    # Adaptive penalty approach: increase penalty weight if constraints violated\n    penalty_weights = [10.0, 50.0, 200.0, 1000.0]\n    \n    best_result = None\n    best_sum_radii = 0\n    \n    for penalty_weight in penalty_weights:\n        def objective(x):\n            centers = x[:2*n_circles].reshape(n_circles, 2)\n            radii = x[2*n_circles:]\n            \n            obj = -np.sum(radii)\n            penalty = compute_penalty(centers, radii, penalty_weight)\n            \n            return obj + penalty\n        \n        # Bounds for variables\n        bounds = []\n        for i in range(2*n_circles):\n            bounds.append((0, 1))\n        for i in range(n_circles):\n            bounds.append((0.001, 0.5))\n        \n        try:\n            result = minimize(\n                objective,\n                x0,\n                method='L-BFGS-B',\n                bounds=bounds,\n                options={'maxiter': max_iter, 'ftol': 1e-9}\n            )\n            \n            if result.fun < 0:\n                centers_opt = result.x[:2*n_circles].reshape(n_circles, 2)\n                radii_opt = result.x[2*n_circles:]\n                \n                # Verify solution\n                if verify_packing(centers_opt, radii_opt, tol=1e-4):\n                    sum_radii = np.sum(radii_opt)\n                    if sum_radii > best_sum_radii:\n                        best_sum_radii = sum_radii\n                        best_result = (centers_opt, radii_opt, sum_radii)\n                    \n                    # Use this as starting point for next iteration\n                    x0 = result.x\n                else:\n                    # Constraints violated, increase penalty and continue\n                    x0 = result.x\n        except Exception as e:\n            pass\n    \n    return best_result\n\ndef verify_packing(centers: np.ndarray, radii: np.ndarray, tol: float = 1e-4) -> bool:\n    \"\"\"\n    Verify that a packing is valid\n    \"\"\"\n    n_circles = len(centers)\n    \n    # Check circles inside unit square\n    for i in range(n_circles):\n        if (centers[i, 0] - radii[i] < -tol or \n            centers[i, 0] + radii[i] > 1 + tol or\n            centers[i, 1] - radii[i] < -tol or \n            centers[i, 1] + radii[i] > 1 + tol):\n            return False\n    \n    # Check no overlaps\n    for i in range(n_circles):\n        for j in range(i+1, n_circles):\n            dist = np.sqrt((centers[i, 0] - centers[j, 0])**2 + \n                          (centers[i, 1] - centers[j, 1])**2)\n            if dist < radii[i] + radii[j] - tol:\n                return False\n    \n    # Check positive radii\n    if np.any(radii < 0):\n        return False\n    \n    return True\n\ndef create_grid_packing(n_circles: int) -> Tuple[np.ndarray, np.ndarray]:\n    \"\"\"\n    Create a simple grid-based packing as fallback\n    \"\"\"\n    grid_size = 6\n    spacing = 1.0 / grid_size\n    radius = spacing / 2.2\n    \n    centers = []\n    count = 0\n    for i in range(grid_size):\n        for j in range(grid_size):\n            if count >= n_circles:\n                break\n            x = (i + 0.5) * spacing\n            y = (j + 0.5) * spacing\n            centers.append([x, y])\n            count += 1\n        if count >= n_circles:\n            break\n    \n    centers = np.array(centers[:n_circles])\n    radii = np.full(n_circles, radius)\n    \n    return centers, radii\n\ndef run_packing():\n    return construct_packing()\n\nif __name__ == \"__main__\":\n    centers, radii, sum_radii = run_packing()\n    print(f\"\\n{'='*50}\")\n    print(f\"Final Results:\")\n    print(f\"{'='*50}\")\n    print(f\"Sum of radii: {sum_radii:.6f}\")\n    print(f\"Average radius: {np.mean(radii):.6f}\")\n    print(f\"Min radius: {np.min(radii):.6f}\")\n    print(f\"Max radius: {np.max(radii):.6f}\")\n    print(f\"Valid packing: {verify_packing(centers, radii)}\")\n    print(f\"{'='*50}\")\n```\n\nKey improvements:\n\n1. **Quasi-random sequences**: Uses Sobol and Halton sequences for better space coverage than pure random sampling\n\n2. **Adaptive penalty weights**: Progressively increases penalty weights (10 \u2192 50 \u2192 200 \u2192 1000) to handle constraint violations more effectively\n\n3. **Multiple global optimization methods**:\n   - Differential Evolution with polishing\n   - Basin Hopping for escaping local minima\n   - L-BFGS-B with adaptive penalties\n\n4. **Parallel evaluation**: Uses ProcessPoolExecutor to evaluate multiple strategies simultaneously, significantly speeding up the search\n\n5. **Better penalty function**: Squared penalties for smoother gradients and more effective constraint handling\n\n6. **Result polishing**: Successful DE solutions are further refined with local optimization\n\nThe parallel approach explores",
  "reasoning": "Here's an improved version with better global optimization strategies:\n\nKey improvements:\n\n1. **Quasi-random sequences**: Uses Sobol and Halton sequences for better space coverage than pure random sampling\n\n2. **Adaptive penalty weights**: Progressively increases penalty weights (10 \u2192 50 \u2192 200 \u2192 1000) to handle constraint violations more effectively\n\n3. **Multiple global optimization methods**:\n   - Differential Evolution with polishing\n   - Basin Hopping for escaping local minima\n   - L-BFGS-B with adaptive penalties\n\n4. **Parallel evaluation**: Uses ProcessPoolExecutor to evaluate multiple strategies simultaneously, significantly speeding up the search\n\n5. **Better penalty function**: Squared penalties for smoother gradients and more effective constraint handling\n\n6. **Result polishing**: Successful DE solutions are further refined with local optimization\n\nThe parallel approach explores",
  "timestamp": "2025-12-08T12:31:22.131489",
  "cost_data": null
}