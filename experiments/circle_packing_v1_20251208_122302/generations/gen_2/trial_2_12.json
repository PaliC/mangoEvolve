{
  "trial_id": "trial_2_12",
  "generation": 2,
  "parent_id": null,
  "code": "import numpy as np\nfrom scipy.optimize import minimize\nimport matplotlib.pyplot as plt\nfrom matplotlib.patches import Circle\nfrom copy import deepcopy\n\ndef compute_coverage(radii):\n    \"\"\"Compute total coverage area of circles.\"\"\"\n    return np.sum(np.pi * radii**2)\n\ndef check_constraints(positions, radii):\n    \"\"\"Check if packing satisfies all constraints.\"\"\"\n    n = len(radii)\n    \n    # Check if circles are within unit circle\n    for i in range(n):\n        if np.sqrt(positions[i, 0]**2 + positions[i, 1]**2) + radii[i] > 1.0 + 1e-6:\n            return False\n    \n    # Check for overlaps\n    for i in range(n):\n        for j in range(i + 1, n):\n            dist = np.sqrt((positions[i, 0] - positions[j, 0])**2 + \n                          (positions[i, 1] - positions[j, 1])**2)\n            if dist < radii[i] + radii[j] - 1e-6:\n                return False\n    \n    return True\n\ndef objective_function(x, n):\n    \"\"\"Objective function: negative coverage (to minimize).\"\"\"\n    radii = x[:n]\n    positions = x[n:].reshape(n, 2)\n    \n    # Penalize invalid configurations\n    penalty = 0.0\n    \n    # Penalty for circles outside container\n    for i in range(n):\n        dist_from_center = np.sqrt(positions[i, 0]**2 + positions[i, 1]**2)\n        overflow = dist_from_center + radii[i] - 1.0\n        if overflow > 0:\n            penalty += 1000 * overflow**2\n    \n    # Penalty for overlapping circles\n    for i in range(n):\n        for j in range(i + 1, n):\n            dist = np.sqrt((positions[i, 0] - positions[j, 0])**2 + \n                          (positions[i, 1] - positions[j, 1])**2)\n            overlap = radii[i] + radii[j] - dist\n            if overlap > 0:\n                penalty += 1000 * overlap**2\n    \n    coverage = compute_coverage(radii)\n    return -coverage + penalty\n\ndef create_random_individual(n, min_radius=0.05, max_radius=0.3):\n    \"\"\"Create a random packing configuration.\"\"\"\n    radii = np.random.uniform(min_radius, max_radius, n)\n    positions = np.random.uniform(-0.5, 0.5, (n, 2))\n    \n    # Adjust positions to be within container\n    for i in range(n):\n        dist = np.sqrt(positions[i, 0]**2 + positions[i, 1]**2)\n        max_dist = 1.0 - radii[i]\n        if dist > max_dist:\n            positions[i] *= max_dist / (dist + 1e-10)\n    \n    return np.concatenate([radii, positions.flatten()])\n\ndef evaluate_fitness(individual, n):\n    \"\"\"Evaluate fitness (negative of objective function).\"\"\"\n    return -objective_function(individual, n)\n\ndef tournament_selection(population, fitnesses, tournament_size=3):\n    \"\"\"Select individual using tournament selection.\"\"\"\n    indices = np.random.choice(len(population), tournament_size, replace=False)\n    best_idx = indices[np.argmax(fitnesses[indices])]\n    return population[best_idx].copy()\n\ndef crossover(parent1, parent2, n):\n    \"\"\"Blend crossover for positions and radii.\"\"\"\n    alpha = np.random.uniform(0.3, 0.7)\n    child = alpha * parent1 + (1 - alpha) * parent2\n    \n    # Ensure radii are positive and reasonable\n    child[:n] = np.clip(child[:n], 0.05, 0.3)\n    \n    # Ensure positions are within reasonable bounds\n    positions = child[n:].reshape(n, 2)\n    for i in range(n):\n        dist = np.sqrt(positions[i, 0]**2 + positions[i, 1]**2)\n        max_dist = 1.0 - child[i]\n        if dist > max_dist:\n            positions[i] *= max_dist / (dist + 1e-10)\n    child[n:] = positions.flatten()\n    \n    return child\n\ndef mutate(individual, n, mutation_rate=0.2, mutation_strength=0.1):\n    \"\"\"Gaussian mutation.\"\"\"\n    child = individual.copy()\n    \n    # Mutate radii\n    if np.random.rand() < mutation_rate:\n        child[:n] += np.random.normal(0, mutation_strength * 0.05, n)\n        child[:n] = np.clip(child[:n], 0.05, 0.3)\n    \n    # Mutate positions\n    if np.random.rand() < mutation_rate:\n        positions = child[n:].reshape(n, 2)\n        positions += np.random.normal(0, mutation_strength, (n, 2))\n        \n        # Keep within bounds\n        for i in range(n):\n            dist = np.sqrt(positions[i, 0]**2 + positions[i, 1]**2)\n            max_dist = 1.0 - child[i]\n            if dist > max_dist:\n                positions[i] *= max_dist / (dist + 1e-10)\n        \n        child[n:] = positions.flatten()\n    \n    return child\n\ndef gradient_descent_optimization(individual, n, max_iter=100):\n    \"\"\"Apply gradient descent to refine solution.\"\"\"\n    bounds = [(0.05, 0.3) for _ in range(n)]  # Radius bounds\n    bounds += [(-1.0, 1.0) for _ in range(2 * n)]  # Position bounds\n    \n    result = minimize(\n        objective_function,\n        individual,\n        args=(n,),\n        method='L-BFGS-B',\n        bounds=bounds,\n        options={'maxiter': max_iter, 'ftol': 1e-9}\n    )\n    \n    return result.x\n\ndef calculate_diversity(population):\n    \"\"\"Calculate population diversity.\"\"\"\n    if len(population) < 2:\n        return 0.0\n    \n    distances = []\n    for i in range(len(population)):\n        for j in range(i + 1, len(population)):\n            dist = np.linalg.norm(population[i] - population[j])\n            distances.append(dist)\n    \n    return np.mean(distances) if distances else 0.0\n\ndef construct_packing(n=26):\n    \"\"\"\n    Construct circle packing using hybrid genetic algorithm + gradient descent.\n    \n    Args:\n        n: Number of circles (default: 26)\n    \n    Returns:\n        radii: Array of circle radii\n        positions: Array of circle center positions (n x 2)\n    \"\"\"\n    # Genetic Algorithm parameters\n    population_size = 50\n    generations = 100\n    elite_size = 5\n    gradient_descent_interval = 10\n    \n    # Initialize population\n    print(f\"Initializing population of {population_size} individuals...\")\n    population = [create_random_individual(n) for _ in range(population_size)]\n    \n    best_individual = None\n    best_fitness = -np.inf\n    fitness_history = []\n    \n    for gen in range(generations):\n        # Evaluate fitness\n        fitnesses = np.array([evaluate_fitness(ind, n) for ind in population])\n        \n        # Track best solution\n        gen_best_idx = np.argmax(fitnesses)\n        if fitnesses[gen_best_idx] > best_fitness:\n            best_fitness = fitnesses[gen_best_idx]\n            best_individual = population[gen_best_idx].copy()\n        \n        fitness_history.append(best_fitness)\n        \n        # Calculate diversity\n        diversity = calculate_diversity(population)\n        \n        print(f\"Generation {gen + 1}/{generations}: \"\n              f\"Best Fitness = {best_fitness:.6f}, \"\n              f\"Diversity = {diversity:.4f}\")\n        \n        # Apply gradient descent to top individuals every N generations\n        if (gen + 1) % gradient_descent_interval == 0:\n            print(f\"  Applying gradient descent to top {elite_size} individuals...\")\n            elite_indices = np.argsort(fitnesses)[-elite_size:]\n            \n            for idx in elite_indices:\n                optimized = gradient_descent_optimization(population[idx], n)\n                new_fitness = evaluate_fitness(optimized, n)\n                \n                if new_fitness > fitnesses[idx]:\n                    population[idx] = optimized\n                    fitnesses[idx] = new_fitness\n                    \n                    if new_fitness > best_fitness:\n                        best_fitness = new_fitness\n                        best_individual = optimized.copy()\n        \n        # Create new population\n        new_population = []\n        \n        # Elitism: keep best individuals\n        elite_indices = np.argsort(fitnesses)[-elite_size:]\n        for idx in elite_indices:\n            new_population.append(population[idx].copy())\n        \n        # Generate offspring\n        while len(new_population) < population_size:\n            parent1 = tournament_selection(population, fitnesses)\n            parent2 = tournament_selection(population, fitnesses)\n            \n            child = crossover(parent1, parent2, n)\n            child = mutate(child, n)\n            \n            new_population.append(child)\n        \n        population = new_population\n        \n        # Diversity maintenance: if diversity is too low, inject random individuals\n        if diversity < 0.1 and gen < generations - 10:\n            num_random = population_size // 10\n            for i in range(num_random):\n                population[i] = create_random_individual(n)\n            print(f\"  Injected {num_random} random individuals to maintain diversity\")\n    \n    # Final intensive optimization on best individual\n    print(\"\\nApplying final intensive optimization...\")\n    best_individual = gradient_descent_optimization(best_individual, n, max_iter=500)\n    best_fitness = evaluate_fitness(best_individual, n)\n    \n    print(f\"\\nFinal Best Fitness: {best_fitness:.6f}\")\n    \n    # Extract radii and positions\n    radii = best_individual[:n]\n    positions = best_individual[n:].reshape(n, 2)\n    \n    # Verify constraints\n    coverage = compute_coverage(radii)\n    is_valid = check_constraints(positions, radii)\n    \n    print(f\"Total Coverage: {coverage:.6f}\")\n    print(f\"Valid Configuration: {is_valid}\")\n    \n    return radii, positions, fitness_history\n\ndef run_packing():\n    \"\"\"Run the circle packing algorithm and visualize results.\"\"\"\n    print(\"=\" * 60)\n    print(\"HYBRID GENETIC ALGORITHM + GRADIENT DESCENT\")\n    print(\"Circle Packing Problem (26 circles)\")\n    print(\"=\" * 60)\n    \n    # Run the algorithm\n    radii, positions, fitness_history = construct_packing(n=26)\n    \n    # Create visualization\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n    \n    # Plot 1: Circle packing\n    ax1.set_aspect('equal')\n    ax1.set_xlim(-1.1, 1.1)\n    ax1.set_ylim(-1.1, 1.1)\n    \n    # Draw container circle\n    container = Circle((0, 0), 1.0, fill=False, edgecolor='black', linewidth=2)\n    ax1.add_patch(container)\n    \n    # Draw packed circles\n    colors = plt.cm.viridis(np.linspace(0, 1, len(radii)))\n    for i, (pos, r) in enumerate(zip(positions, radii)):\n        circle = Circle(pos, r, facecolor=colors[i], edgecolor='black', \n                       linewidth=0.5, alpha=0.7)\n        ax1.add_patch(circle)\n        ax1.text(pos[0], pos[1], str(i+1), ha='center', va='center', \n                fontsize=6, fontweight='bold')\n    \n    coverage = compute_coverage(radii)\n    ax1.set_title(f'Circle Packing (n=26)\\nCoverage: {coverage:.4f}', \n                  fontsize=12, fontweight='bold')\n    ax1.grid(True, alpha=0.3)\n    ax1.set_xlabel('x')\n    ax1.set_ylabel('y')\n    \n    # Plot 2: Fitness evolution\n    ax2.plot(fitness_history, linewidth=2, color='blue')\n    ax2.set_xlabel('Generation', fontsize=11)\n    ax2.set_ylabel('Best Fitness', fontsize=11)\n    ax2.set_title('Fitness Evolution', fontsize=12, fontweight='bold')\n    ax2.grid(True, alpha=0.3)\n    \n    plt.tight_layout()\n    plt.savefig('hybrid_ga_gd_packing.png', dpi=300, bbox_inches='tight')\n    print(\"\\nVisualization saved as 'hybrid_ga_gd_packing.png'\")\n    plt.show()\n    \n    # Print statistics\n    print(\"\\n\" + \"=\" * 60)\n    print(\"STATISTICS\")\n    print(\"=\" * 60)\n    print(f\"Number of circles: {len(radii)}\")\n    print(f\"Total coverage: {coverage:.6f}\")\n    print(f\"Average radius: {np.mean(radii):.4f}\")\n    print(f\"Min radius: {np.min(radii):.4f}\")\n    print(f\"Max radius: {np.max(radii):.4f}\")\n    print(f\"Configuration valid: {check_constraints(positions, radii)}\")\n    \n    return radii, positions\n\nif __name__ == \"__main__\":\n    radii, positions = run_packing()",
  "metrics": {
    "valid": false,
    "sum_radii": 0.0,
    "target_ratio": 0.0,
    "combined_score": 0.0,
    "eval_time": 125.44379687309265,
    "error": "ValueError: not enough values to unpack (expected 3, got 2)"
  },
  "prompt": "Write a hybrid genetic algorithm + gradient descent for 26 circles.\n\nStrategy:\n1. Genetic algorithm for global exploration:\n   - Population of 50 packings\n   - Tournament selection\n   - Crossover: blend positions and radii from parents\n   - Mutation: gaussian perturbation\n2. Every 10 generations, apply gradient descent to top 5 individuals\n3. Use elitism: keep best solutions\n4. Add diversity maintenance: penalize similar solutions\n5. Final intensive optimization on best individual\n\nCombines evolutionary exploration with gradient-based exploitation.\n\nInclude construct_packing() and run_packing() functions.",
  "response": "```python\nimport numpy as np\nfrom scipy.optimize import minimize\nimport matplotlib.pyplot as plt\nfrom matplotlib.patches import Circle\nfrom copy import deepcopy\n\ndef compute_coverage(radii):\n    \"\"\"Compute total coverage area of circles.\"\"\"\n    return np.sum(np.pi * radii**2)\n\ndef check_constraints(positions, radii):\n    \"\"\"Check if packing satisfies all constraints.\"\"\"\n    n = len(radii)\n    \n    # Check if circles are within unit circle\n    for i in range(n):\n        if np.sqrt(positions[i, 0]**2 + positions[i, 1]**2) + radii[i] > 1.0 + 1e-6:\n            return False\n    \n    # Check for overlaps\n    for i in range(n):\n        for j in range(i + 1, n):\n            dist = np.sqrt((positions[i, 0] - positions[j, 0])**2 + \n                          (positions[i, 1] - positions[j, 1])**2)\n            if dist < radii[i] + radii[j] - 1e-6:\n                return False\n    \n    return True\n\ndef objective_function(x, n):\n    \"\"\"Objective function: negative coverage (to minimize).\"\"\"\n    radii = x[:n]\n    positions = x[n:].reshape(n, 2)\n    \n    # Penalize invalid configurations\n    penalty = 0.0\n    \n    # Penalty for circles outside container\n    for i in range(n):\n        dist_from_center = np.sqrt(positions[i, 0]**2 + positions[i, 1]**2)\n        overflow = dist_from_center + radii[i] - 1.0\n        if overflow > 0:\n            penalty += 1000 * overflow**2\n    \n    # Penalty for overlapping circles\n    for i in range(n):\n        for j in range(i + 1, n):\n            dist = np.sqrt((positions[i, 0] - positions[j, 0])**2 + \n                          (positions[i, 1] - positions[j, 1])**2)\n            overlap = radii[i] + radii[j] - dist\n            if overlap > 0:\n                penalty += 1000 * overlap**2\n    \n    coverage = compute_coverage(radii)\n    return -coverage + penalty\n\ndef create_random_individual(n, min_radius=0.05, max_radius=0.3):\n    \"\"\"Create a random packing configuration.\"\"\"\n    radii = np.random.uniform(min_radius, max_radius, n)\n    positions = np.random.uniform(-0.5, 0.5, (n, 2))\n    \n    # Adjust positions to be within container\n    for i in range(n):\n        dist = np.sqrt(positions[i, 0]**2 + positions[i, 1]**2)\n        max_dist = 1.0 - radii[i]\n        if dist > max_dist:\n            positions[i] *= max_dist / (dist + 1e-10)\n    \n    return np.concatenate([radii, positions.flatten()])\n\ndef evaluate_fitness(individual, n):\n    \"\"\"Evaluate fitness (negative of objective function).\"\"\"\n    return -objective_function(individual, n)\n\ndef tournament_selection(population, fitnesses, tournament_size=3):\n    \"\"\"Select individual using tournament selection.\"\"\"\n    indices = np.random.choice(len(population), tournament_size, replace=False)\n    best_idx = indices[np.argmax(fitnesses[indices])]\n    return population[best_idx].copy()\n\ndef crossover(parent1, parent2, n):\n    \"\"\"Blend crossover for positions and radii.\"\"\"\n    alpha = np.random.uniform(0.3, 0.7)\n    child = alpha * parent1 + (1 - alpha) * parent2\n    \n    # Ensure radii are positive and reasonable\n    child[:n] = np.clip(child[:n], 0.05, 0.3)\n    \n    # Ensure positions are within reasonable bounds\n    positions = child[n:].reshape(n, 2)\n    for i in range(n):\n        dist = np.sqrt(positions[i, 0]**2 + positions[i, 1]**2)\n        max_dist = 1.0 - child[i]\n        if dist > max_dist:\n            positions[i] *= max_dist / (dist + 1e-10)\n    child[n:] = positions.flatten()\n    \n    return child\n\ndef mutate(individual, n, mutation_rate=0.2, mutation_strength=0.1):\n    \"\"\"Gaussian mutation.\"\"\"\n    child = individual.copy()\n    \n    # Mutate radii\n    if np.random.rand() < mutation_rate:\n        child[:n] += np.random.normal(0, mutation_strength * 0.05, n)\n        child[:n] = np.clip(child[:n], 0.05, 0.3)\n    \n    # Mutate positions\n    if np.random.rand() < mutation_rate:\n        positions = child[n:].reshape(n, 2)\n        positions += np.random.normal(0, mutation_strength, (n, 2))\n        \n        # Keep within bounds\n        for i in range(n):\n            dist = np.sqrt(positions[i, 0]**2 + positions[i, 1]**2)\n            max_dist = 1.0 - child[i]\n            if dist > max_dist:\n                positions[i] *= max_dist / (dist + 1e-10)\n        \n        child[n:] = positions.flatten()\n    \n    return child\n\ndef gradient_descent_optimization(individual, n, max_iter=100):\n    \"\"\"Apply gradient descent to refine solution.\"\"\"\n    bounds = [(0.05, 0.3) for _ in range(n)]  # Radius bounds\n    bounds += [(-1.0, 1.0) for _ in range(2 * n)]  # Position bounds\n    \n    result = minimize(\n        objective_function,\n        individual,\n        args=(n,),\n        method='L-BFGS-B',\n        bounds=bounds,\n        options={'maxiter': max_iter, 'ftol': 1e-9}\n    )\n    \n    return result.x\n\ndef calculate_diversity(population):\n    \"\"\"Calculate population diversity.\"\"\"\n    if len(population) < 2:\n        return 0.0\n    \n    distances = []\n    for i in range(len(population)):\n        for j in range(i + 1, len(population)):\n            dist = np.linalg.norm(population[i] - population[j])\n            distances.append(dist)\n    \n    return np.mean(distances) if distances else 0.0\n\ndef construct_packing(n=26):\n    \"\"\"\n    Construct circle packing using hybrid genetic algorithm + gradient descent.\n    \n    Args:\n        n: Number of circles (default: 26)\n    \n    Returns:\n        radii: Array of circle radii\n        positions: Array of circle center positions (n x 2)\n    \"\"\"\n    # Genetic Algorithm parameters\n    population_size = 50\n    generations = 100\n    elite_size = 5\n    gradient_descent_interval = 10\n    \n    # Initialize population\n    print(f\"Initializing population of {population_size} individuals...\")\n    population = [create_random_individual(n) for _ in range(population_size)]\n    \n    best_individual = None\n    best_fitness = -np.inf\n    fitness_history = []\n    \n    for gen in range(generations):\n        # Evaluate fitness\n        fitnesses = np.array([evaluate_fitness(ind, n) for ind in population])\n        \n        # Track best solution\n        gen_best_idx = np.argmax(fitnesses)\n        if fitnesses[gen_best_idx] > best_fitness:\n            best_fitness = fitnesses[gen_best_idx]\n            best_individual = population[gen_best_idx].copy()\n        \n        fitness_history.append(best_fitness)\n        \n        # Calculate diversity\n        diversity = calculate_diversity(population)\n        \n        print(f\"Generation {gen + 1}/{generations}: \"\n              f\"Best Fitness = {best_fitness:.6f}, \"\n              f\"Diversity = {diversity:.4f}\")\n        \n        # Apply gradient descent to top individuals every N generations\n        if (gen + 1) % gradient_descent_interval == 0:\n            print(f\"  Applying gradient descent to top {elite_size} individuals...\")\n            elite_indices = np.argsort(fitnesses)[-elite_size:]\n            \n            for idx in elite_indices:\n                optimized = gradient_descent_optimization(population[idx], n)\n                new_fitness = evaluate_fitness(optimized, n)\n                \n                if new_fitness > fitnesses[idx]:\n                    population[idx] = optimized\n                    fitnesses[idx] = new_fitness\n                    \n                    if new_fitness > best_fitness:\n                        best_fitness = new_fitness\n                        best_individual = optimized.copy()\n        \n        # Create new population\n        new_population = []\n        \n        # Elitism: keep best individuals\n        elite_indices = np.argsort(fitnesses)[-elite_size:]\n        for idx in elite_indices:\n            new_population.append(population[idx].copy())\n        \n        # Generate offspring\n        while len(new_population) < population_size:\n            parent1 = tournament_selection(population, fitnesses)\n            parent2 = tournament_selection(population, fitnesses)\n            \n            child = crossover(parent1, parent2, n)\n            child = mutate(child, n)\n            \n            new_population.append(child)\n        \n        population = new_population\n        \n        # Diversity maintenance: if diversity is too low, inject random individuals\n        if diversity < 0.1 and gen < generations - 10:\n            num_random = population_size // 10\n            for i in range(num_random):\n                population[i] = create_random_individual(n)\n            print(f\"  Injected {num_random} random individuals to maintain diversity\")\n    \n    # Final intensive optimization on best individual\n    print(\"\\nApplying final intensive optimization...\")\n    best_individual = gradient_descent_optimization(best_individual, n, max_iter=500)\n    best_fitness = evaluate_fitness(best_individual, n)\n    \n    print(f\"\\nFinal Best Fitness: {best_fitness:.6f}\")\n    \n    # Extract radii and positions\n    radii = best_individual[:n]\n    positions = best_individual[n:].reshape(n, 2)\n    \n    # Verify constraints\n    coverage = compute_coverage(radii)\n    is_valid = check_constraints(positions, radii)\n    \n    print(f\"Total Coverage: {coverage:.6f}\")\n    print(f\"Valid Configuration: {is_valid}\")\n    \n    return radii, positions, fitness_history\n\ndef run_packing():\n    \"\"\"Run the circle packing algorithm and visualize results.\"\"\"\n    print(\"=\" * 60)\n    print(\"HYBRID GENETIC ALGORITHM + GRADIENT DESCENT\")\n    print(\"Circle Packing Problem (26 circles)\")\n    print(\"=\" * 60)\n    \n    # Run the algorithm\n    radii, positions, fitness_history = construct_packing(n=26)\n    \n    # Create visualization\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n    \n    # Plot 1: Circle packing\n    ax1.set_aspect('equal')\n    ax1.set_xlim(-1.1, 1.1)\n    ax1.set_ylim(-1.1, 1.1)\n    \n    # Draw container circle\n    container = Circle((0, 0), 1.0, fill=False, edgecolor='black', linewidth=2)\n    ax1.add_patch(container)\n    \n    # Draw packed circles\n    colors = plt.cm.viridis(np.linspace(0, 1, len(radii)))\n    for i, (pos, r) in enumerate(zip(positions, radii)):\n        circle = Circle(pos, r, facecolor=colors[i], edgecolor='black', \n                       linewidth=0.5, alpha=0.7)\n        ax1.add_patch(circle)\n        ax1.text(pos[0], pos[1], str(i+1), ha='center', va='center', \n                fontsize=6, fontweight='bold')\n    \n    coverage = compute_coverage(radii)\n    ax1.set_title(f'Circle Packing (n=26)\\nCoverage: {coverage:.4f}', \n                  fontsize=12, fontweight='bold')\n    ax1.grid(True, alpha=0.3)\n    ax1.set_xlabel('x')\n    ax1.set_ylabel('y')\n    \n    # Plot 2: Fitness evolution\n    ax2.plot(fitness_history, linewidth=2, color='blue')\n    ax2.set_xlabel('Generation', fontsize=11)\n    ax2.set_ylabel('Best Fitness', fontsize=11)\n    ax2.set_title('Fitness Evolution', fontsize=12, fontweight='bold')\n    ax2.grid(True, alpha=0.3)\n    \n    plt.tight_layout()\n    plt.savefig('hybrid_ga_gd_packing.png', dpi=300, bbox_inches='tight')\n    print(\"\\nVisualization saved as 'hybrid_ga_gd_packing.png'\")\n    plt.show()\n    \n    # Print statistics\n    print(\"\\n\" + \"=\" * 60)\n    print(\"STATISTICS\")\n    print(\"=\" * 60)\n    print(f\"Number of circles: {len(radii)}\")\n    print(f\"Total coverage: {coverage:.6f}\")\n    print(f\"Average radius: {np.mean(radii):.4f}\")\n    print(f\"Min radius: {np.min(radii):.4f}\")\n    print(f\"Max radius: {np.max(radii):.4f}\")\n    print(f\"Configuration valid: {check_constraints(positions, radii)}\")\n    \n    return radii, positions\n\nif __name__ == \"__main__\":\n    radii, positions = run_packing()\n```\n\nThis implementation features:\n\n1. **Genetic Algorithm Core**:\n   - Population of 50 individuals\n   - Tournament selection (size 3)\n   - Blend crossover with random alpha\n   - Gaussian mutation for both radii and positions\n\n2. **Gradient Descent Integration**:\n   - Applied every 10 generations to top 5 individuals\n   - Uses L-BFGS-B for constrained optimization\n   - Final intensive optimization (500 iterations) on best solution\n\n3. **Advanced Features**:\n   - Elitism: preserves top 5 solutions\n   - Diversity maintenance: injects random individuals if diversity drops\n   - Constraint handling via penalty functions\n   - Automatic bound enforcement\n\n4. **Optimization Strategy**:\n   - Global exploration via genetic operators\n   - Local exploitation via gradient descent\n   - Balance maintained through periodic gradient descent application\n\n5. **Visualization**:\n   - Circle packing display with numbered circles\n   - Fitness evolution plot showing convergence\n\nThe hybrid approach combines the genetic algorithm's ability to explore the solution space with gradient descent's precision for local optimization, resulting in high-quality packings.",
  "reasoning": "This implementation features:\n\n1. **Genetic Algorithm Core**:\n   - Population of 50 individuals\n   - Tournament selection (size 3)\n   - Blend crossover with random alpha\n   - Gaussian mutation for both radii and positions\n\n2. **Gradient Descent Integration**:\n   - Applied every 10 generations to top 5 individuals\n   - Uses L-BFGS-B for constrained optimization\n   - Final intensive optimization (500 iterations) on best solution\n\n3. **Advanced Features**:\n   - Elitism: preserves top 5 solutions\n   - Diversity maintenance: injects random individuals if diversity drops\n   - Constraint handling via penalty functions\n   - Automatic bound enforcement\n\n4. **Optimization Strategy**:\n   - Global exploration via genetic operators\n   - Local exploitation via gradient descent\n   - Balance maintained through periodic gradient descent application\n\n5. **Visualization**:\n   - Circle packing display with numbered circles\n   - Fitness evolution plot showing convergence\n\nThe hybrid approach combines the genetic algorithm's ability to explore the solution space with gradient descent's precision for local optimization, resulting in high-quality packings.",
  "timestamp": "2025-12-08T12:42:46.054577",
  "cost_data": null
}