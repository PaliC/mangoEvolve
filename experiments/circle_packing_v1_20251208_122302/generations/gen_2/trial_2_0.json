{
  "trial_id": "trial_2_0",
  "generation": 2,
  "parent_id": "trial_1_5",
  "code": "",
  "metrics": {},
  "prompt": "Further improve this hybrid random search + local optimization approach:\n\nimport numpy as np\nfrom scipy.optimize import minimize\nfrom typing import Tuple, List, Optional\n\ndef construct_packing() -> Tuple[np.ndarray, np.ndarray, float]:\n    \"\"\"\n    Hybrid approach: Random search + local optimization\n    \n    Returns:\n        centers: np.array of shape (26, 2)\n        radii: np.array of shape (26,)\n        sum_radii: float\n    \"\"\"\n    n_circles = 26\n    \n    # Phase 1: Random search to find promising starting points\n    print(\"Phase 1: Random search for initial configurations...\")\n    initial_candidates = random_search_phase(n_circles, n_trials=20)\n    \n    # Phase 2: Local optimization of top candidates\n    print(\"\\nPhase 2: Local optimization of top candidates...\")\n    best_result = local_optimization_phase(initial_candidates, n_circles, top_k=5)\n    \n    if best_result is None:\n        print(\"Optimization failed, using fallback grid packing\")\n        centers, radii = create_grid_packing(n_circles)\n        sum_radii = np.sum(radii)\n        best_result = (centers, radii, sum_radii)\n    \n    centers, radii, sum_radii = best_result\n    print(f\"\\nFinal result: Sum of radii = {sum_radii:.6f}\")\n    print(f\"Average radius: {np.mean(radii):.6f}\")\n    print(f\"Valid packing: {verify_packing(centers, radii)}\")\n    \n    return centers, radii, sum_radii\n\n\ndef random_search_phase(n_circles: int, n_trials: int = 20) -> List[Tuple[np.ndarray, np.ndarray, float]]:\n    \"\"\"\n    Phase 1: Generate multiple random configurations with quick local optimization\n    Returns list of (centers, radii, sum_radii) tuples\n    \"\"\"\n    candidates = []\n    \n    for trial in range(n_trials):\n        # Strategy: Mix different initialization strategies\n        if trial < n_trials // 3:\n            # Pure random\n            centers = np.random.rand(n_circles, 2)\n        elif trial < 2 * n_trials // 3:\n            # Grid with noise\n            centers = create_grid_centers(n_circles)\n            centers += np.random.normal(0, 0.05, centers.shape)\n            centers = np.clip(centers, 0.1, 0.9)\n        else:\n            # Hexagonal-like pattern with noise\n            centers = create_hex_centers(n_circles)\n            centers += np.random.normal(0, 0.03, centers.shape)\n            centers = np.clip(centers, 0.1, 0.9)\n        \n        # Compute initial radii based on nearest neighbors\n        radii = compute_initial_radii(centers, n_circles)\n        \n        # Quick local optimization (few iterations)\n        result = quick_optimize(centers, radii, max_iter=100)\n        \n        if result is not None:\n            candidates.append(result)\n            print(f\"  Trial {trial+1}/{n_trials}: sum_radii = {result[2]:.6f}\")\n    \n    # Sort by sum of radii (descending)\n    candidates.sort(key=lambda x: x[2], reverse=True)\n    \n    return candidates\n\n\ndef local_optimization_phase(candidates: List[Tuple], n_circles: int, top_k: int = 5) -> Optional[Tuple]:\n    \"\"\"\n    Phase 2: Intensive local optimization of top candidates\n    \"\"\"\n    best_result = None\n    best_sum_radii = 0\n    \n    # Take top_k candidates\n    top_candidates = candidates[:min(top_k, len(candidates))]\n    \n    for idx, (centers, radii, sum_radii) in enumerate(top_candidates):\n        print(f\"\\n  Optimizing candidate {idx+1}/{len(top_candidates)} (initial sum: {sum_radii:.6f})...\")\n        \n        # Intensive optimization with scipy\n        result = intensive_optimize(centers, radii, n_circles, max_iter=1000)\n        \n        if result is not None:\n            centers_opt, radii_opt, sum_radii_opt = result\n            print(f\"    -> Optimized sum: {sum_radii_opt:.6f}\")\n            \n            if sum_radii_opt > best_sum_radii:\n                best_sum_radii = sum_radii_opt\n                best_result = result\n        \n        # Also try perturbation + re-optimization\n        if result is not None:\n            for perturb in range(2):\n                centers_pert = centers_opt + np.random.normal(0, 0.01, centers_opt.shape)\n                centers_pert = np.clip(centers_pert, 0, 1)\n                radii_pert = radii_opt * (1 + np.random.normal(0, 0.05, radii_opt.shape))\n                radii_pert = np.clip(radii_pert, 0.001, 0.5)\n                \n                result_pert = intensive_optimize(centers_pert, radii_pert, n_circles, max_iter=500)\n                \n                if result_pert is not None and result_pert[2] > best_sum_radii:\n                    best_sum_radii = result_pert[2]\n                    best_result = result_pert\n                    print(f\"    -> Perturbation improved: {best_sum_radii:.6f}\")\n    \n    return best_result\n\n\ndef quick_optimize(centers: np.ndarray, radii: np.ndarray, max_iter: int = 100) -> Optional[Tuple]:\n    \"\"\"Quick optimization with fewer iterations\"\"\"\n    n_circles = len(centers)\n    x0 = np.concatenate([centers.flatten(), radii])\n    \n    bounds = [(0, 1)] * (2 * n_circles) + [(0.001, 0.5)] * n_circles\n    \n    def objective(x):\n        return -np.sum(x[2*n_circles:])\n    \n    constraints = create_constraints(n_circles)\n    \n    try:\n        result = minimize(\n            objective,\n            x0,\n            method='SLSQP',\n            bounds=bounds,\n            constraints=constraints,\n            options={'maxiter': max_iter, 'ftol': 1e-4}\n        )\n        \n        if result.fun < 0:\n            centers_opt = result.x[:2*n_circles].reshape(n_circles, 2)\n            radii_opt = result.x[2*n_circles:]\n            sum_radii = np.sum(radii_opt)\n            \n            if verify_packing(centers_opt, radii_opt, tol=1e-3):\n                return centers_opt, radii_opt, sum_radii\n    except:\n        pass\n    \n    return None\n\n\ndef intensive_optimize(centers: np.ndarray, radii: np.ndarray, n_circles: int, \n                       max_iter: int = 1000) -> Optional[Tuple]:\n    \"\"\"Intensive optimization with more iterations and tighter tolerances\"\"\"\n    x0 = np.concatenate([centers.flatten(), radii])\n    \n    bounds = [(0, 1)] * (2 * n_circles) + [(0.001, 0.5)] * n_circles\n    \n    def objective(x):\n        return -np.sum(x[2*n_circles:])\n    \n    constraints = create_constraints(n_circles)\n    \n    try:\n        result = minimize(\n            objective,\n            x0,\n            method='SLSQP',\n            bounds=bounds,\n            constraints=constraints,\n            options={'maxiter': max_iter, 'ftol': 1e-8, 'disp': False}\n        )\n        \n        if result.fun < 0:\n            centers_opt = result.x[:2*n_circles].reshape(n_circles, 2)\n            radii_opt = result.x[2*n_circles:]\n            sum_radii = np.sum(radii_opt)\n            \n            if verify_packing(centers_opt, radii_opt, tol=1e-4):\n                return centers_opt, radii_opt, sum_radii\n    except:\n        pass\n    \n    return None\n\n\ndef create_constraints(n_circles: int):\n    \"\"\"Create constraint functions for optimization\"\"\"\n    def constraints_func(x):\n        centers = x[:2*n_circles].reshape(n_circles, 2)\n        radii = x[2*n_circles:]\n        \n        constraints = []\n        \n        # Boundary constraints\n        for i in range(n_circles):\n            constraints.append(centers[i, 0] - radii[i])  # left\n            constraints.append(1 - centers[i, 0] - radii[i])  # right\n            constraints.append(centers[i, 1] - radii[i])  # bottom\n            constraints.append(1 - centers[i, 1] - radii[i])  # top\n        \n        # Non-overlap constraints\n        for i in range(n_circles):\n            for j in range(i+1, n_circles):\n                dist = np.sqrt((centers[i, 0] - centers[j, 0])**2 + \n                              (centers[i, 1] - centers[j, 1])**2)\n                constraints.append(dist - radii[i] - radii[j])\n        \n        # Positive radii\n        constraints.extend(radii)\n        \n        return np.array(constraints)\n    \n    return {'type': 'ineq', 'fun': constraints_func}\n\n\ndef compute_initial_radii(centers: np.ndarray, n_circles: int) -> np.ndarray:\n    \"\"\"Compute initial radii based on nearest neighbor distances and boundaries\"\"\"\n    radii = np.zeros(n_circles)\n    \n    for i in range(n_circles):\n        # Distance to boundaries\n        dist_to_boundary = min(\n            centers[i, 0], 1 - centers[i, 0],\n            centers[i, 1], 1 - centers[i, 1]\n        )\n        \n        # Distance to nearest neighbor\n        min_dist_to_neighbor = float('inf')\n        for j in range(n_circles):\n            if i != j:\n                dist = np.sqrt((centers[i, 0] - centers[j, 0])**2 + \n                              (centers[i, 1] - centers[j, 1])**2)\n                min_dist_to_neighbor = min(min_dist_to_neighbor, dist)\n        \n        # Conservative radius estimate\n        radii[i] = min(dist_to_boundary, min_dist_to_neighbor / 2.5) * 0.9\n    \n    return np.clip(radii, 0.01, 0.5)\n\n\ndef create_grid_centers(n_circles: int) -> np.ndarray:\n    \"\"\"Create grid-based initial centers\"\"\"\n    grid_size = int(np.ceil(np.sqrt(n_circles)))\n    centers = []\n    \n    for i in range(n_circles):\n        row = i // grid_size\n        col = i % grid_size\n        x = (col + 0.5) / grid_size\n        y = (row + 0.5) / grid_size\n        centers.append([x, y])\n    \n    return np.array(centers)\n\n\ndef create_hex_centers(n_circles: int) -> np.ndarray:\n    \"\"\"Create hexagonal packing initial centers\"\"\"\n    centers = []\n    rows = int(np.ceil(np.sqrt(n_circles)))\n    \n    for row in range(rows):\n        cols = int(np.ceil(n_circles / rows))\n        offset = 0.5 if row % 2 == 1 else 0\n        \n        for col in range(cols):\n            if len(centers) >= n_circles:\n                break\n            \n            x = (col + offset + 0.5) / (cols + 0.5)\n            y = (row + 0.5) / (rows + 0.5)\n            centers.append([x, y])\n    \n    return np.array(centers[:n_circles])\n\n\ndef verify_packing(centers: np.ndarray, radii: np.ndarray, tol: float = 1e-4) -> bool:\n    \"\"\"Verify that a packing is valid\"\"\"\n    n_circles = len(centers)\n    \n    # Check boundaries\n    for i in range(n_circles):\n        if (centers[i, 0] - radii[i] < -tol or \n            centers[i, 0] + radii[i] > 1 + tol or\n            centers[i, 1] - radii[i] < -tol or \n            centers[i, 1] + radii[i] > 1 + tol):\n            return False\n    \n    # Check overlaps\n    for i in range(n_circles):\n        for j in range(i+1, n_circles):\n            dist = np.sqrt((centers[i, 0] - centers[j, 0])**2 + \n                          (centers[i, 1] - centers[j, 1])**2)\n            if dist < radii[i] + radii[j] - tol:\n                return False\n    \n    # Check positive radii\n    if np.any(radii <= 0):\n        return False\n    \n    return True\n\n\ndef create_grid_packing(n_circles: int) -> Tuple[np.ndarray, np.ndarray]:\n    \"\"\"Fallback grid packing\"\"\"\n    grid_size = int(np.ceil(np.sqrt(n_circles)))\n    spacing = 1.0 / grid_size\n    radius = spacing / 2.5\n    \n    centers = []\n    for i in range(n_circles):\n        row = i // grid_size\n        col = i % grid_size\n        x = (col + 0.5) * spacing\n        y = (row + 0.5) * spacing\n        centers.append([x, y])\n    \n    centers = np.array(centers)\n    radii = np.full(n_circles, radius)\n    \n    return centers, radii\n\n\ndef run_packing():\n    return construct_packing()\n\n\nif __name__ == \"__main__\":\n    centers, radii, sum_radii = run_packing()\n    print(f\"\\n{'='*50}\")\n    print(f\"FINAL RESULTS:\")\n    print(f\"Sum of radii: {sum_radii:.6f}\")\n    print(f\"Average radius: {np.mean(radii):.6f}\")\n    print(f\"Min radius: {np.min(radii):.6f}\")\n    print(f\"Max radius: {np.max(radii):.6f}\")\n    print(f\"Valid packing: {verify_packing(centers, radii)}\")\n    print(f\"{'='*50}\")\n\nMake these enhancements:\n1. Increase random search trials from 20 to 40 for even better exploration\n2. Add more diverse initialization strategies (Fibonacci spiral, sunflower, Sobol sequences)\n3. Use multiple optimization methods in parallel for each candidate (SLSQP, trust-constr, L-BFGS-B)\n4. Implement adaptive perturbation strategy based on convergence rate\n5. Add multi-scale optimization: coarse then fine adjustments\n\nFocus on pushing closer to the benchmark of 2.635.",
  "response": "Here's a significantly enhanced version with all the requested improvements:\n\n```python\nimport numpy as np\nfrom scipy.optimize import minimize\nfrom scipy.stats import qmc\nfrom typing import Tuple, List, Optional\nfrom concurrent.futures import ProcessPoolExecutor, as_completed\nimport multiprocessing as mp\n\ndef construct_packing() -> Tuple[np.ndarray, np.ndarray, float]:\n    \"\"\"\n    Enhanced hybrid approach with diverse initialization and multi-method optimization\n    \n    Returns:\n        centers: np.array of shape (26, 2)\n        radii: np.array of shape (26,)\n        sum_radii: float\n    \"\"\"\n    n_circles = 26\n    \n    # Phase 1: Diverse random search with 40 trials\n    print(\"Phase 1: Enhanced random search with diverse initialization strategies...\")\n    initial_candidates = enhanced_random_search_phase(n_circles, n_trials=40)\n    \n    # Phase 2: Multi-method local optimization\n    print(\"\\nPhase 2: Multi-method optimization of top candidates...\")\n    best_result = multi_method_optimization_phase(initial_candidates, n_circles, top_k=8)\n    \n    # Phase 3: Multi-scale refinement\n    if best_result is not None:\n        print(\"\\nPhase 3: Multi-scale refinement...\")\n        best_result = multi_scale_refinement(best_result, n_circles)\n    \n    # Phase 4: Adaptive perturbation and re-optimization\n    if best_result is not None:\n        print(\"\\nPhase 4: Adaptive perturbation strategy...\")\n        best_result = adaptive_perturbation_optimization(best_result, n_circles)\n    \n    if best_result is None:\n        print(\"Optimization failed, using fallback grid packing\")\n        centers, radii = create_grid_packing(n_circles)\n        sum_radii = np.sum(radii)\n        best_result = (centers, radii, sum_radii)\n    \n    centers, radii, sum_radii = best_result\n    print(f\"\\nFinal result: Sum of radii = {sum_radii:.6f}\")\n    print(f\"Average radius: {np.mean(radii):.6f}\")\n    print(f\"Valid packing: {verify_packing(centers, radii)}\")\n    \n    return centers, radii, sum_radii\n\n\ndef enhanced_random_search_phase(n_circles: int, n_trials: int = 40) -> List[Tuple[np.ndarray, np.ndarray, float]]:\n    \"\"\"\n    Enhanced Phase 1: Generate multiple random configurations with diverse strategies\n    \"\"\"\n    candidates = []\n    strategies = []\n    \n    # Define diverse initialization strategies\n    for trial in range(n_trials):\n        strategy_idx = trial % 8\n        \n        if strategy_idx == 0:\n            # Pure random\n            centers = np.random.rand(n_circles, 2)\n            strategy = \"random\"\n        elif strategy_idx == 1:\n            # Grid with noise\n            centers = create_grid_centers(n_circles)\n            centers += np.random.normal(0, 0.05, centers.shape)\n            centers = np.clip(centers, 0.05, 0.95)\n            strategy = \"grid+noise\"\n        elif strategy_idx == 2:\n            # Hexagonal pattern with noise\n            centers = create_hex_centers(n_circles)\n            centers += np.random.normal(0, 0.03, centers.shape)\n            centers = np.clip(centers, 0.05, 0.95)\n            strategy = \"hex+noise\"\n        elif strategy_idx == 3:\n            # Fibonacci spiral\n            centers = create_fibonacci_spiral_centers(n_circles)\n            centers += np.random.normal(0, 0.02, centers.shape)\n            centers = np.clip(centers, 0.05, 0.95)\n            strategy = \"fibonacci\"\n        elif strategy_idx == 4:\n            # Sunflower pattern\n            centers = create_sunflower_centers(n_circles)\n            centers += np.random.normal(0, 0.02, centers.shape)\n            centers = np.clip(centers, 0.05, 0.95)\n            strategy = \"sunflower\"\n        elif strategy_idx == 5:\n            # Sobol sequence\n            centers = create_sobol_centers(n_circles)\n            centers += np.random.normal(0, 0.01, centers.shape)\n            centers = np.clip(centers, 0.05, 0.95)\n            strategy = \"sobol\"\n        elif strategy_idx == 6:\n            # Concentric circles\n            centers = create_concentric_centers(n_circles)\n            centers += np.random.normal(0, 0.03, centers.shape)\n            centers = np.clip(centers, 0.05, 0.95)\n            strategy = \"concentric\"\n        else:\n            # Poisson disk sampling approximation\n            centers = create_poisson_disk_centers(n_circles)\n            centers += np.random.normal(0, 0.01, centers.shape)\n            centers = np.clip(centers, 0.05, 0.95)\n            strategy = \"poisson\"\n        \n        # Compute initial radii\n        radii = compute_initial_radii(centers, n_circles)\n        \n        # Quick local optimization\n        result = quick_optimize(centers, radii, max_iter=150)\n        \n        if result is not None:\n            candidates.append(result)\n            print(f\"  Trial {trial+1}/{n_trials} ({strategy}): sum_radii = {result[2]:.6f}\")\n    \n    # Sort by sum of radii (descending)\n    candidates.sort(key=lambda x: x[2], reverse=True)\n    \n    print(f\"\\nGenerated {len(candidates)} valid candidates from {n_trials} trials\")\n    if candidates:\n        print(f\"Best initial candidate: {candidates[0][2]:.6f}\")\n    \n    return candidates\n\n\ndef multi_method_optimization_phase(candidates: List[Tuple], n_circles: int, top_k: int = 8) -> Optional[Tuple]:\n    \"\"\"\n    Phase 2: Use multiple optimization methods in parallel for each candidate\n    \"\"\"\n    best_result = None\n    best_sum_radii = 0\n    \n    top_candidates = candidates[:min(top_k, len(candidates))]\n    \n    for idx, (centers, radii, sum_radii) in enumerate(top_candidates):\n        print(f\"\\n  Candidate {idx+1}/{len(top_candidates)} (initial: {sum_radii:.6f})...\")\n        \n        # Try multiple optimization methods\n        methods = ['SLSQP', 'trust-constr']\n        results = []\n        \n        for method in methods:\n            result = optimize_with_method(centers.copy(), radii.copy(), n_circles, \n                                         method=method, max_iter=1000)\n            if result is not None:\n                results.append(result)\n                print(f\"    {method}: {result[2]:.6f}\")\n        \n        # Also try L-BFGS-B with penalty method\n        result_lbfgs = optimize_with_penalty(centers.copy(), radii.copy(), n_circles, max_iter=1000)\n        if result_lbfgs is not None:\n            results.append(result_lbfgs)\n            print(f\"    L-BFGS-B (penalty): {result_lbfgs[2]:.6f}\")\n        \n        # Take best result from all methods\n        if results:\n            best_method_result = max(results, key=lambda x: x[2])\n            if best_method_result[2] > best_sum_radii:\n                best_sum_radii = best_method_result[2]\n                best_result = best_method_result\n                print(f\"    *** New best: {best_sum_radii:.6f}\")\n    \n    return best_result\n\n\ndef multi_scale_refinement(result: Tuple, n_circles: int, n_scales: int = 3) -> Tuple:\n    \"\"\"\n    Phase 3: Multi-scale optimization - coarse to fine adjustments\n    \"\"\"\n    centers, radii, sum_radii = result\n    print(f\"  Starting multi-scale refinement from {sum_radii:.6f}\")\n    \n    best_centers, best_radii, best_sum = centers.copy(), radii.copy(), sum_radii\n    \n    # Scale 1: Coarse adjustment (larger perturbations, fewer iterations)\n    print(\"  Scale 1: Coarse adjustment...\")\n    for attempt in range(3):\n        centers_pert = best_centers + np.random.normal(0, 0.02, best_centers.shape)\n        centers_pert = np.clip(centers_pert, 0, 1)\n        radii_pert = best_radii * (1 + np.random.normal(0, 0.1, best_radii.shape))\n        radii_pert = np.clip(radii_pert, 0.001, 0.5)\n        \n        result = optimize_with_method(centers_pert, radii_pert, n_circles, \n                                     method='SLSQP', max_iter=300)\n        if result is not None and result[2] > best_sum:\n            best_centers, best_radii, best_sum = result\n            print(f\"    Improved to {best_sum:.6f}\")\n    \n    # Scale 2: Medium adjustment\n    print(\"  Scale 2: Medium adjustment...\")\n    for attempt in range(3):\n        centers_pert = best_centers + np.random.normal(0, 0.01, best_centers.shape)\n        centers_pert = np.clip(centers_pert, 0, 1)\n        radii_pert = best_radii * (1 + np.random.normal(0, 0.05, best_radii.shape))\n        radii_pert = np.clip(radii_pert, 0.001, 0.5)\n        \n        result = optimize_with_method(centers_pert, radii_pert, n_circles, \n                                     method='SLSQP', max_iter=500)\n        if result is not None and result[2] > best_sum:\n            best_centers, best_radii, best_sum = result\n            print(f\"    Improved to {best_sum:.6f}\")\n    \n    # Scale 3: Fine adjustment (smaller perturbations, more iterations)\n    print(\"  Scale 3: Fine adjustment...\")\n    for attempt in range(3):\n        centers_pert = best_centers + np.random.normal(0, 0.005, best_centers.shape)\n        centers_pert = np.clip(centers_pert, 0, 1)\n        radii_pert = best_radii * (1 + np.random.normal(0, 0.02, best_radii.shape))\n        radii_pert = np.clip(radii_pert, 0.001, 0.5)\n        \n        result = optimize_with_method(centers_pert, radii_pert, n_circles, \n                                     method='trust-constr', max_iter=800)\n        if result is not None and result[2] > best_sum:\n            best_centers, best_radii, best_sum = result\n            print(f\"    Improved to {best_sum:.6f}\")\n    \n    print(f\"  Multi-scale refinement: {sum_radii:.6f} -> {best_sum:.6f}\")\n    return best_centers, best_radii, best_sum\n\n\ndef adaptive_perturbation_optimization(result: Tuple, n_circles: int, max_attempts: int = 15) -> Tuple:\n    \"\"\"\n    Phase 4: Adaptive perturbation based on convergence rate\n    \"\"\"\n    centers, radii, sum_radii = result\n    print(f\"  Starting adaptive perturbation from {sum_radii:.6f}\")\n    \n    best_centers, best_radii, best_sum = centers.copy(), radii.copy(), sum_radii\n    \n    # Initial perturbation scale\n    perturb_scale = 0.02\n    no_improvement_count = 0\n    \n    for attempt in range(max_attempts):\n        # Adaptive perturbation\n        centers_pert = best_centers + np.random.normal(0, perturb_scale, best_centers.shape)\n        centers_pert = np.clip(centers_pert, 0, 1)\n        \n        radii_scale = perturb_scale * 3\n        radii_pert = best_radii * (1 + np.random.normal(0, radii_scale, best_radii.shape))\n        radii_pert = np.clip(radii_pert, 0.001, 0.5)\n        \n        # Try both methods\n        result1 = optimize_with_method(centers_pert, radii_pert, n_circles, \n                                      method='SLSQP', max_iter=600)\n        result2 = optimize_with_method(centers_pert, radii_pert, n_circles, \n                                      method='trust-constr', max_iter=600)\n        \n        results = [r for r in [result1, result2] if r is not None]\n        \n        if results:\n            best_attempt = max(results, key=lambda x: x[2])\n            \n            if best_attempt[2] > best_sum:\n                improvement = best_attempt[2] - best_sum\n                best_centers, best_radii, best_sum = best_attempt\n                print(f\"    Attempt {attempt+1}: Improved to {best_sum:.6f} (+{improvement:.6f})\")\n                \n                # Reduce perturbation scale on improvement (exploit)\n                perturb_scale *= 0.8\n                perturb_scale = max(perturb_scale, 0.002)\n                no_improvement_count = 0\n            else:\n                no_improvement_count += 1\n                \n                # Increase perturbation scale if stuck (explore)\n                if no_improvement_count >= 3:\n                    perturb_scale *= 1.5\n                    perturb_scale = min(perturb_scale, 0.05)\n                    no_improvement_count = 0\n                    print(f\"    Increasing perturbation scale to {perturb_scale:.4f}\")\n        \n        # Early stopping if perturbation is too small\n        if perturb_scale < 0.001 and no_improvement_count > 2:\n            print(f\"    Converged after {attempt+1} attempts\")\n            break\n    \n    print(f\"  Adaptive perturbation: {sum_radii:.6f} -> {best_sum:.6f}\")\n    return best_centers, best_radii, best_sum\n\n\ndef optimize_with_method(centers: np.ndarray, radii: np.ndarray, n_circles: int, \n                        method: str = 'SLSQP', max_iter: int = 1000) -> Optional[Tuple]:\n    \"\"\"Optimize using specified method\"\"\"\n    x0 = np.concatenate([centers.flatten(), radii])\n    bounds = [(0, 1)] * (2 * n_circles) + [(0.001, 0.5)] * n_circles\n    \n    def objective(x):\n        return -np.sum(x[2*n_circles:])\n    \n    constraints = create_constraints(n_circles)\n    \n    try:\n        if method == 'trust-constr':\n            result = minimize(\n                objective,\n                x0,\n                method='trust-constr',\n                bounds=bounds,\n                constraints=constraints,\n                options={'maxiter': max_iter, 'verbose': 0}\n            )\n        else:  # SLSQP\n            result = minimize(\n                objective,\n                x0,\n                method='SLSQP',\n                bounds=bounds,\n                constraints=constraints,\n                options={'maxiter': max_iter, 'ftol': 1e-9, 'disp': False}\n            )\n        \n        if result.fun < 0:\n            centers_opt = result.x[:2*n_circles].reshape(n_circles, 2)\n            radii",
  "reasoning": "Here's a significantly enhanced version with all the requested improvements:\n\n```python\nimport numpy as np\nfrom scipy.optimize import minimize\nfrom scipy.stats import qmc\nfrom typing import Tuple, List, Optional\nfrom concurrent.futures import ProcessPoolExecutor, as_completed\nimport multiprocessing as mp\n\ndef construct_packing() -> Tuple[np.ndarray, np.ndarray, float]:\n    \"\"\"\n    Enhanced hybrid approach with diverse initialization and multi-method optimization\n    \n    Returns:\n        centers: np.array of shape (26, 2)\n        radii: np.array of shape (26,)\n        sum_radii: float\n    \"\"\"\n    n_circles = 26\n    \n    # Phase 1: Diverse random search with 40 trials\n    print(\"Phase 1: Enhanced random search with diverse initialization strategies...\")\n    initial_candidates = enhanced_random_search_phase(n_circles, n_trials=40)\n    \n    # Phase 2: Multi-method local optimization\n    print(\"\\nPhase 2: Multi-method optimization of top candidates...\")\n    best_result = multi_method_optimization_phase(initial_candidates, n_circles, top_k=8)\n    \n    # Phase 3: Multi-scale refinement\n    if best_result is not None:\n        print(\"\\nPhase 3: Multi-scale refinement...\")\n        best_result = multi_scale_refinement(best_result, n_circles)\n    \n    # Phase 4: Adaptive perturbation and re-optimization\n    if best_result is not None:\n        print(\"\\nPhase 4: Adaptive perturbation strategy...\")\n        best_result = adaptive_perturbation_optimization(best_result, n_circles)\n    \n    if best_result is None:\n        print(\"Optimization failed, using fallback grid packing\")\n        centers, radii = create_grid_packing(n_circles)\n        sum_radii = np.sum(radii)\n        best_result = (centers, radii, sum_radii)\n    \n    centers, radii, sum_radii = best_result\n    print(f\"\\nFinal result: Sum of radii = {sum_radii:.6f}\")\n    print(f\"Average radius: {np.mean(radii):.6f}\")\n    print(f\"Valid packing: {verify_packing(centers, radii)}\")\n    \n    return centers, radii, sum_radii\n\ndef enhanced_random_search_phase(n_circles: int, n_trials: int = 40) -> List[Tuple[np.ndarray, np.ndarray, float]]:\n    \"\"\"\n    Enhanced Phase 1: Generate multiple random configurations with diverse strategies\n    \"\"\"\n    candidates = []\n    strategies = []\n    \n    # Define diverse initialization strategies\n    for trial in range(n_trials):\n        strategy_idx = trial % 8\n        \n        if strategy_idx == 0:\n            # Pure random\n            centers = np.random.rand(n_circles, 2)\n            strategy = \"random\"\n        elif strategy_idx == 1:\n            # Grid with noise\n            centers = create_grid_centers(n_circles)\n            centers += np.random.normal(0, 0.05, centers.shape)\n            centers = np.clip(centers, 0.05, 0.95)\n            strategy = \"grid+noise\"\n        elif strategy_idx == 2:\n            # Hexagonal pattern with noise\n            centers = create_hex_centers(n_circles)\n            centers += np.random.normal(0, 0.03, centers.shape)\n            centers = np.clip(centers, 0.05, 0.95)\n            strategy = \"hex+noise\"\n        elif strategy_idx == 3:\n            # Fibonacci spiral\n            centers = create_fibonacci_spiral_centers(n_circles)\n            centers += np.random.normal(0, 0.02, centers.shape)\n            centers = np.clip(centers, 0.05, 0.95)\n            strategy = \"fibonacci\"\n        elif strategy_idx == 4:\n            # Sunflower pattern\n            centers = create_sunflower_centers(n_circles)\n            centers += np.random.normal(0, 0.02, centers.shape)\n            centers = np.clip(centers, 0.05, 0.95)\n            strategy = \"sunflower\"\n        elif strategy_idx == 5:\n            # Sobol sequence\n            centers = create_sobol_centers(n_circles)\n            centers += np.random.normal(0, 0.01, centers.shape)\n            centers = np.clip(centers, 0.05, 0.95)\n            strategy = \"sobol\"\n        elif strategy_idx == 6:\n            # Concentric circles\n            centers = create_concentric_centers(n_circles)\n            centers += np.random.normal(0, 0.03, centers.shape)\n            centers = np.clip(centers, 0.05, 0.95)\n            strategy = \"concentric\"\n        else:\n            # Poisson disk sampling approximation\n            centers = create_poisson_disk_centers(n_circles)\n            centers += np.random.normal(0, 0.01, centers.shape)\n            centers = np.clip(centers, 0.05, 0.95)\n            strategy = \"poisson\"\n        \n        # Compute initial radii\n        radii = compute_initial_radii(centers, n_circles)\n        \n        # Quick local optimization\n        result = quick_optimize(centers, radii, max_iter=150)\n        \n        if result is not None:\n            candidates.append(result)\n            print(f\"  Trial {trial+1}/{n_trials} ({strategy}): sum_radii = {result[2]:.6f}\")\n    \n    # Sort by sum of radii (descending)\n    candidates.sort(key=lambda x: x[2], reverse=True)\n    \n    print(f\"\\nGenerated {len(candidates)} valid candidates from {n_trials} trials\")\n    if candidates:\n        print(f\"Best initial candidate: {candidates[0][2]:.6f}\")\n    \n    return candidates\n\ndef multi_method_optimization_phase(candidates: List[Tuple], n_circles: int, top_k: int = 8) -> Optional[Tuple]:\n    \"\"\"\n    Phase 2: Use multiple optimization methods in parallel for each candidate\n    \"\"\"\n    best_result = None\n    best_sum_radii = 0\n    \n    top_candidates = candidates[:min(top_k, len(candidates))]\n    \n    for idx, (centers, radii, sum_radii) in enumerate(top_candidates):\n        print(f\"\\n  Candidate {idx+1}/{len(top_candidates)} (initial: {sum_radii:.6f})...\")\n        \n        # Try multiple optimization methods\n        methods = ['SLSQP', 'trust-constr']\n        results = []\n        \n        for method in methods:\n            result = optimize_with_method(centers.copy(), radii.copy(), n_circles, \n                                         method=method, max_iter=1000)\n            if result is not None:\n                results.append(result)\n                print(f\"    {method}: {result[2]:.6f}\")\n        \n        # Also try L-BFGS-B with penalty method\n        result_lbfgs = optimize_with_penalty(centers.copy(), radii.copy(), n_circles, max_iter=1000)\n        if result_lbfgs is not None:\n            results.append(result_lbfgs)\n            print(f\"    L-BFGS-B (penalty): {result_lbfgs[2]:.6f}\")\n        \n        # Take best result from all methods\n        if results:\n            best_method_result = max(results, key=lambda x: x[2])\n            if best_method_result[2] > best_sum_radii:\n                best_sum_radii = best_method_result[2]\n                best_result = best_method_result\n                print(f\"    *** New best: {best_sum_radii:.6f}\")\n    \n    return best_result\n\ndef multi_scale_refinement(result: Tuple, n_circles: int, n_scales: int = 3) -> Tuple:\n    \"\"\"\n    Phase 3: Multi-scale optimization - coarse to fine adjustments\n    \"\"\"\n    centers, radii, sum_radii = result\n    print(f\"  Starting multi-scale refinement from {sum_radii:.6f}\")\n    \n    best_centers, best_radii, best_sum = centers.copy(), radii.copy(), sum_radii\n    \n    # Scale 1: Coarse adjustment (larger perturbations, fewer iterations)\n    print(\"  Scale 1: Coarse adjustment...\")\n    for attempt in range(3):\n        centers_pert = best_centers + np.random.normal(0, 0.02, best_centers.shape)\n        centers_pert = np.clip(centers_pert, 0, 1)\n        radii_pert = best_radii * (1 + np.random.normal(0, 0.1, best_radii.shape))\n        radii_pert = np.clip(radii_pert, 0.001, 0.5)\n        \n        result = optimize_with_method(centers_pert, radii_pert, n_circles, \n                                     method='SLSQP', max_iter=300)\n        if result is not None and result[2] > best_sum:\n            best_centers, best_radii, best_sum = result\n            print(f\"    Improved to {best_sum:.6f}\")\n    \n    # Scale 2: Medium adjustment\n    print(\"  Scale 2: Medium adjustment...\")\n    for attempt in range(3):\n        centers_pert = best_centers + np.random.normal(0, 0.01, best_centers.shape)\n        centers_pert = np.clip(centers_pert, 0, 1)\n        radii_pert = best_radii * (1 + np.random.normal(0, 0.05, best_radii.shape))\n        radii_pert = np.clip(radii_pert, 0.001, 0.5)\n        \n        result = optimize_with_method(centers_pert, radii_pert, n_circles, \n                                     method='SLSQP', max_iter=500)\n        if result is not None and result[2] > best_sum:\n            best_centers, best_radii, best_sum = result\n            print(f\"    Improved to {best_sum:.6f}\")\n    \n    # Scale 3: Fine adjustment (smaller perturbations, more iterations)\n    print(\"  Scale 3: Fine adjustment...\")\n    for attempt in range(3):\n        centers_pert = best_centers + np.random.normal(0, 0.005, best_centers.shape)\n        centers_pert = np.clip(centers_pert, 0, 1)\n        radii_pert = best_radii * (1 + np.random.normal(0, 0.02, best_radii.shape))\n        radii_pert = np.clip(radii_pert, 0.001, 0.5)\n        \n        result = optimize_with_method(centers_pert, radii_pert, n_circles, \n                                     method='trust-constr', max_iter=800)\n        if result is not None and result[2] > best_sum:\n            best_centers, best_radii, best_sum = result\n            print(f\"    Improved to {best_sum:.6f}\")\n    \n    print(f\"  Multi-scale refinement: {sum_radii:.6f} -> {best_sum:.6f}\")\n    return best_centers, best_radii, best_sum\n\ndef adaptive_perturbation_optimization(result: Tuple, n_circles: int, max_attempts: int = 15) -> Tuple:\n    \"\"\"\n    Phase 4: Adaptive perturbation based on convergence rate\n    \"\"\"\n    centers, radii, sum_radii = result\n    print(f\"  Starting adaptive perturbation from {sum_radii:.6f}\")\n    \n    best_centers, best_radii, best_sum = centers.copy(), radii.copy(), sum_radii\n    \n    # Initial perturbation scale\n    perturb_scale = 0.02\n    no_improvement_count = 0\n    \n    for attempt in range(max_attempts):\n        # Adaptive perturbation\n        centers_pert = best_centers + np.random.normal(0, perturb_scale, best_centers.shape)\n        centers_pert = np.clip(centers_pert, 0, 1)\n        \n        radii_scale = perturb_scale * 3\n        radii_pert = best_radii * (1 + np.random.normal(0, radii_scale, best_radii.shape))\n        radii_pert = np.clip(radii_pert, 0.001, 0.5)\n        \n        # Try both methods\n        result1 = optimize_with_method(centers_pert, radii_pert, n_circles, \n                                      method='SLSQP', max_iter=600)\n        result2 = optimize_with_method(centers_pert, radii_pert, n_circles, \n                                      method='trust-constr', max_iter=600)\n        \n        results = [r for r in [result1, result2] if r is not None]\n        \n        if results:\n            best_attempt = max(results, key=lambda x: x[2])\n            \n            if best_attempt[2] > best_sum:\n                improvement = best_attempt[2] - best_sum\n                best_centers, best_radii, best_sum = best_attempt\n                print(f\"    Attempt {attempt+1}: Improved to {best_sum:.6f} (+{improvement:.6f})\")\n                \n                # Reduce perturbation scale on improvement (exploit)\n                perturb_scale *= 0.8\n                perturb_scale = max(perturb_scale, 0.002)\n                no_improvement_count = 0\n            else:\n                no_improvement_count += 1\n                \n                # Increase perturbation scale if stuck (explore)\n                if no_improvement_count >= 3:\n                    perturb_scale *= 1.5\n                    perturb_scale = min(perturb_scale, 0.05)\n                    no_improvement_count = 0\n                    print(f\"    Increasing perturbation scale to {perturb_scale:.4f}\")\n        \n        # Early stopping if perturbation is too small\n        if perturb_scale < 0.001 and no_improvement_count > 2:\n            print(f\"    Converged after {attempt+1} attempts\")\n            break\n    \n    print(f\"  Adaptive perturbation: {sum_radii:.6f} -> {best_sum:.6f}\")\n    return best_centers, best_radii, best_sum\n\ndef optimize_with_method(centers: np.ndarray, radii: np.ndarray, n_circles: int, \n                        method: str = 'SLSQP', max_iter: int = 1000) -> Optional[Tuple]:\n    \"\"\"Optimize using specified method\"\"\"\n    x0 = np.concatenate([centers.flatten(), radii])\n    bounds = [(0, 1)] * (2 * n_circles) + [(0.001, 0.5)] * n_circles\n    \n    def objective(x):\n        return -np.sum(x[2*n_circles:])\n    \n    constraints = create_constraints(n_circles)\n    \n    try:\n        if method == 'trust-constr':\n            result = minimize(\n                objective,\n                x0,\n                method='trust-constr',\n                bounds=bounds,\n                constraints=constraints,\n                options={'maxiter': max_iter, 'verbose': 0}\n            )\n        else:  # SLSQP\n            result = minimize(\n                objective,\n                x0,\n                method='SLSQP',\n                bounds=bounds,\n                constraints=constraints,\n                options={'maxiter': max_iter, 'ftol': 1e-9, 'disp': False}\n            )\n        \n        if result.fun < 0:\n            centers_opt = result.x[:2*n_circles].reshape(n_circles, 2)\n            radii",
  "timestamp": "2025-12-08T12:40:38.018100",
  "cost_data": null
}