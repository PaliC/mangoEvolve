{
  "trial_id": "trial_14_5",
  "generation": 14,
  "parent_id": "trial_13_2",
  "code": "import numpy as np\nfrom scipy.optimize import minimize\n\ndef construct_packing():\n    n = 26\n    \n    def objective(x):\n        return -np.sum(x[2*n:], dtype=np.float64)\n    \n    def objective_grad(x):\n        grad = np.zeros(3*n, dtype=np.float64)\n        grad[2*n:] = -1.0\n        return grad\n    \n    def constraints_func(x):\n        centers = x[:2*n].reshape(n, 2).astype(np.float64)\n        radii = x[2*n:].astype(np.float64)\n        \n        # Boundary constraints (4n)\n        boundary = np.concatenate([\n            centers[:, 0] - radii,\n            1.0 - centers[:, 0] - radii,\n            centers[:, 1] - radii,\n            1.0 - centers[:, 1] - radii\n        ], dtype=np.float64)\n        \n        # Non-overlap constraints\n        overlaps = []\n        for i in range(n):\n            for j in range(i+1, n):\n                dx = centers[i, 0] - centers[j, 0]\n                dy = centers[i, 1] - centers[j, 1]\n                dist = np.sqrt(dx*dx + dy*dy + 1e-20)\n                overlaps.append(dist - radii[i] - radii[j])\n        \n        return np.concatenate([boundary, overlaps], dtype=np.float64)\n    \n    def constraints_jac(x):\n        centers = x[:2*n].reshape(n, 2).astype(np.float64)\n        radii = x[2*n:].astype(np.float64)\n        \n        num_constraints = 4*n + n*(n-1)//2\n        jac = np.zeros((num_constraints, 3*n), dtype=np.float64)\n        \n        # Boundary constraints gradients\n        for i in range(n):\n            jac[i, 2*i] = 1.0\n            jac[i, 2*n + i] = -1.0\n        \n        for i in range(n):\n            jac[n + i, 2*i] = -1.0\n            jac[n + i, 2*n + i] = -1.0\n        \n        for i in range(n):\n            jac[2*n + i, 2*i + 1] = 1.0\n            jac[2*n + i, 2*n + i] = -1.0\n        \n        for i in range(n):\n            jac[3*n + i, 2*i + 1] = -1.0\n            jac[3*n + i, 2*n + i] = -1.0\n        \n        # Non-overlap constraints gradients\n        constraint_idx = 4*n\n        for i in range(n):\n            for j in range(i+1, n):\n                dx = centers[i, 0] - centers[j, 0]\n                dy = centers[i, 1] - centers[j, 1]\n                dist_sq = dx*dx + dy*dy\n                dist = np.sqrt(dist_sq + 1e-20)\n                \n                inv_dist = 1.0 / dist\n                jac[constraint_idx, 2*i] = dx * inv_dist\n                jac[constraint_idx, 2*i + 1] = dy * inv_dist\n                jac[constraint_idx, 2*j] = -dx * inv_dist\n                jac[constraint_idx, 2*j + 1] = -dy * inv_dist\n                jac[constraint_idx, 2*n + i] = -1.0\n                jac[constraint_idx, 2*n + j] = -1.0\n                \n                constraint_idx += 1\n        \n        return jac\n    \n    bounds = [(0.0, 1.0)] * (2*n) + [(0.001, 0.5)] * n\n    \n    def create_hex_init(r_est=0.095):\n        centers = []\n        dy = r_est * np.sqrt(3.0)\n        dx = 2.0 * r_est\n        \n        row = 0\n        y = r_est\n        while y < 1.0 - r_est + 0.01 and len(centers) < n:\n            x_offset = r_est if row % 2 == 0 else r_est + dx/2.0\n            x = x_offset\n            while x < 1.0 - r_est + 0.01 and len(centers) < n:\n                centers.append([x, y])\n                x += dx\n            y += dy\n            row += 1\n        \n        return np.array(centers[:n], dtype=np.float64)\n    \n    def create_grid_init(rows_config):\n        centers = []\n        num_rows = len(rows_config)\n        y_spacing = 0.9 / num_rows\n        \n        for row_idx, num_in_row in enumerate(rows_config):\n            y = 0.05 + (row_idx + 0.5) * y_spacing\n            x_spacing = 0.9 / num_in_row\n            x_start = 0.05 + x_spacing/2.0\n            for i in range(num_in_row):\n                x = x_start + i * x_spacing\n                centers.append([x, y])\n                if len(centers) >= n:\n                    break\n            if len(centers) >= n:\n                break\n        \n        return np.array(centers[:n], dtype=np.float64)\n    \n    def adaptive_refine(x_init, max_iters=300):\n        \"\"\"Adaptive multi-scale perturbation refinement\"\"\"\n        x_best = x_init.copy()\n        best_sum = np.sum(x_best[2*n:])\n        \n        # Multi-scale perturbation schedule\n        scales = [0.05, 0.02, 0.01, 0.005, 0.002, 0.001, 0.0005, 0.0002, 0.0001, 0.00005, 0.00002, 0.00001]\n        \n        for scale in scales:\n            improved = False\n            attempts_per_scale = max(10, int(50 / (scale * 1000 + 1)))\n            \n            for attempt in range(attempts_per_scale):\n                # Adaptive perturbation: more on centers, less on radii\n                x_perturbed = x_best.copy()\n                x_perturbed[:2*n] += np.random.randn(2*n).astype(np.float64) * scale\n                x_perturbed[2*n:] += np.random.randn(n).astype(np.float64) * scale * 0.5\n                x_perturbed[:2*n] = np.clip(x_perturbed[:2*n], 0.001, 0.999)\n                x_perturbed[2*n:] = np.clip(x_perturbed[2*n:], 0.001, 0.5)\n                \n                result = minimize(\n                    objective, x_perturbed, method=\"SLSQP\", jac=objective_grad, bounds=bounds,\n                    constraints={\"type\": \"ineq\", \"fun\": constraints_func, \"jac\": constraints_jac},\n                    options={\"maxiter\": 1000, \"ftol\": 1e-15, \"eps\": 1e-10}\n                )\n                \n                cons = constraints_func(result.x)\n                current_sum = np.sum(result.x[2*n:])\n                \n                if np.all(cons >= -1e-9) and current_sum > best_sum:\n                    best_sum = current_sum\n                    x_best = result.x.copy()\n                    improved = True\n            \n            # If no improvement at this scale, try smaller perturbations\n            if not improved and scale > 0.0001:\n                continue\n        \n        return x_best, best_sum\n    \n    best_sum = 0.0\n    best_centers = None\n    best_radii = None\n    \n    # Generate diverse initializations\n    inits = []\n    \n    # Hexagonal packings with various radii\n    for r_est in np.linspace(0.085, 0.102, 12):\n        inits.append(create_hex_init(r_est))\n    \n    # Grid-based configurations\n    grid_configs = [\n        [5, 5, 5, 5, 6],\n        [6, 5, 5, 5, 5],\n        [5, 6, 5, 5, 5],\n        [5, 5, 6, 5, 5],\n        [5, 5, 5, 6, 5],\n        [4, 5, 6, 5, 6],\n        [6, 5, 6, 5, 4],\n        [5, 6, 4, 6, 5],\n    ]\n    \n    for config in grid_configs:\n        inits.append(create_grid_init(config))\n    \n    # Process each initialization\n    for init_idx, centers_init in enumerate(inits):\n        if len(centers_init) < n:\n            continue\n        \n        # Compute safe initial radii\n        radii_init = np.full(n, 0.5, dtype=np.float64)\n        for i in range(n):\n            radii_init[i] = min(radii_init[i], centers_init[i, 0], \n                               1.0 - centers_init[i, 0],\n                               centers_init[i, 1], 1.0 - centers_init[i, 1])\n            for j in range(n):\n                if i != j:\n                    dist = np.linalg.norm(centers_init[i] - centers_init[j])\n                    radii_init[i] = min(radii_init[i], dist / 2.0 - 0.001)\n        \n        radii_init = np.maximum(radii_init, 0.01)\n        x0 = np.concatenate([centers_init.flatten(), radii_init], dtype=np.float64)\n        \n        # Initial optimization\n        result = minimize(\n            objective, x0, method=\"SLSQP\", jac=objective_grad, bounds=bounds,\n            constraints={\"type\": \"ineq\", \"fun\": constraints_func, \"jac\": constraints_jac},\n            options={\"maxiter\": 2000, \"ftol\": 1e-15, \"eps\": 1e-10}\n        )\n        \n        # Adaptive refinement\n        x_refined, sum_refined = adaptive_refine(result.x, max_iters=300)\n        \n        cons = constraints_func(x_refined)\n        if np.all(cons >= -1e-9) and sum_refined > best_sum:\n            best_sum = sum_refined\n            best_centers = x_refined[:2*n].reshape(n, 2)\n            best_radii = x_refined[2*n:]\n    \n    # Final intensive refinement on best solution\n    if best_centers is not None:\n        x_best = np.concatenate([best_centers.flatten(), best_radii], dtype=np.float64)\n        x_final, sum_final = adaptive_refine(x_best, max_iters=500)\n        \n        cons = constraints_func(x_final)\n        if np.all(cons >= -1e-10) and sum_final > best_sum:\n            best_sum = sum_final\n            best_centers = x_final[:2*n].reshape(n, 2)\n            best_radii = x_final[2*n:]\n    \n    return best_centers, best_radii, best_sum\n\ndef run_packing():\n    return construct_packing()",
  "metrics": {
    "valid": false,
    "score": 0.0,
    "eval_time": 300.0075662136078,
    "error": "Timeout after 300s"
  },
  "prompt": "import numpy as np\nfrom scipy.optimize import minimize\n\ndef construct_packing():\n    n = 26\n    \n    def objective(x):\n        return -np.sum(x[2*n:], dtype=np.float64)\n    \n    def objective_grad(x):\n        grad = np.zeros(3*n, dtype=np.float64)\n        grad[2*n:] = -1.0\n        return grad\n    \n    def constraints_func(x):\n        centers = x[:2*n].reshape(n, 2).astype(np.float64)\n        radii = x[2*n:].astype(np.float64)\n        \n        # Boundary constraints (4n)\n        boundary = np.concatenate([\n            centers[:, 0] - radii,\n            1.0 - centers[:, 0] - radii,\n            centers[:, 1] - radii,\n            1.0 - centers[:, 1] - radii\n        ], dtype=np.float64)\n        \n        # Non-overlap constraints\n        overlaps = []\n        for i in range(n):\n            for j in range(i+1, n):\n                dx = centers[i, 0] - centers[j, 0]\n                dy = centers[i, 1] - centers[j, 1]\n                dist = np.sqrt(dx*dx + dy*dy + 1e-20)  # Add epsilon for stability\n                overlaps.append(dist - radii[i] - radii[j])\n        \n        return np.concatenate([boundary, overlaps], dtype=np.float64)\n    \n    def constraints_jac(x):\n        centers = x[:2*n].reshape(n, 2).astype(np.float64)\n        radii = x[2*n:].astype(np.float64)\n        \n        num_constraints = 4*n + n*(n-1)//2\n        jac = np.zeros((num_constraints, 3*n), dtype=np.float64)\n        \n        # Boundary constraints gradients\n        for i in range(n):\n            jac[i, 2*i] = 1.0\n            jac[i, 2*n + i] = -1.0\n        \n        for i in range(n):\n            jac[n + i, 2*i] = -1.0\n            jac[n + i, 2*n + i] = -1.0\n        \n        for i in range(n):\n            jac[2*n + i, 2*i + 1] = 1.0\n            jac[2*n + i, 2*n + i] = -1.0\n        \n        for i in range(n):\n            jac[3*n + i, 2*i + 1] = -1.0\n            jac[3*n + i, 2*n + i] = -1.0\n        \n        # Non-overlap constraints gradients\n        constraint_idx = 4*n\n        for i in range(n):\n            for j in range(i+1, n):\n                dx = centers[i, 0] - centers[j, 0]\n                dy = centers[i, 1] - centers[j, 1]\n                dist_sq = dx*dx + dy*dy\n                dist = np.sqrt(dist_sq + 1e-20)  # Numerical stability\n                \n                inv_dist = 1.0 / dist\n                jac[constraint_idx, 2*i] = dx * inv_dist\n                jac[constraint_idx, 2*i + 1] = dy * inv_dist\n                jac[constraint_idx, 2*j] = -dx * inv_dist\n                jac[constraint_idx, 2*j + 1] = -dy * inv_dist\n                jac[constraint_idx, 2*n + i] = -1.0\n                jac[constraint_idx, 2*n + j] = -1.0\n                \n                constraint_idx += 1\n        \n        return jac\n    \n    bounds = [(0.0, 1.0)] * (2*n) + [(0.001, 0.5)] * n\n    \n    def create_hex_init(r_est=0.095):\n        centers = []\n        dy = r_est * np.sqrt(3.0)\n        dx = 2.0 * r_est\n        \n        row = 0\n        y = r_est\n        while y < 1.0 - r_est + 0.01 and len(centers) < n:\n            x_offset = r_est if row % 2 == 0 else r_est + dx/2.0\n            x = x_offset\n            while x < 1.0 - r_est + 0.01 and len(centers) < n:\n                centers.append([x, y])\n                x += dx\n            y += dy\n            row += 1\n        \n        return np.array(centers[:n], dtype=np.float64)\n    \n    def create_optimized_init():\n        centers = []\n        rows = [5, 6, 5, 5, 5]\n        y_positions = [0.1, 0.28, 0.46, 0.64, 0.82]\n        \n        for row_idx, (num_in_row, y) in enumerate(zip(rows, y_positions)):\n            x_spacing = 0.9 / num_in_row\n            x_start = 0.05 + x_spacing/2.0\n            for i in range(num_in_row):\n                x = x_start + i * x_spacing\n                centers.append([x, y])\n        \n        return np.array(centers[:n], dtype=np.float64)\n    \n    best_sum = 0.0\n    best_centers = None\n    best_radii = None\n    \n    # Try multiple initializations\n    inits = []\n    for r_est in [0.087, 0.089, 0.091, 0.093, 0.095, 0.097, 0.099]:\n        inits.append(create_hex_init(r_est))\n    inits.append(create_optimized_init())\n    \n    for init_idx, centers_init in enumerate(inits):\n        if len(centers_init) < n:\n            continue\n            \n        # Compute initial safe radii\n        radii_init = np.full(n, 0.5, dtype=np.float64)\n        for i in range(n):\n            radii_init[i] = min(radii_init[i], centers_init[i, 0], \n                               1.0 - centers_init[i, 0],\n                               centers_init[i, 1], 1.0 - centers_init[i, 1])\n            for j in range(n):\n                if i != j:\n                    dist = np.linalg.norm(centers_init[i] - centers_init[j])\n                    radii_init[i] = min(radii_init[i], dist / 2.0 - 0.001)\n        \n        radii_init = np.maximum(radii_init, 0.01)\n        x0 = np.concatenate([centers_init.flatten(), radii_init], dtype=np.float64)\n        \n        # First optimization pass\n        result = minimize(\n            objective, x0, method=\"SLSQP\", jac=objective_grad, bounds=bounds,\n            constraints={\"type\": \"ineq\", \"fun\": constraints_func, \"jac\": constraints_jac},\n            options={\"maxiter\": 1500, \"ftol\": 1e-15, \"eps\": 1e-10}\n        )\n        \n        x_current = result.x.copy()\n        \n        # Iterative refinement with perturbations\n        for scale in [0.02, 0.01, 0.005, 0.002, 0.001, 0.0005, 0.0002]:\n            for _ in range(25):\n                x_perturbed = x_current.copy()\n                x_perturbed[:2*n] += np.random.randn(2*n).astype(np.float64) * scale\n                x_perturbed[:2*n] = np.clip(x_perturbed[:2*n], 0.01, 0.99)\n                \n                result = minimize(\n                    objective, x_perturbed, method=\"SLSQP\", jac=objective_grad, bounds=bounds,\n                    constraints={\"type\": \"ineq\", \"fun\": constraints_func, \"jac\": constraints_jac},\n                    options={\"maxiter\": 800, \"ftol\": 1e-15, \"eps\": 1e-10}\n                )\n                \n                cons = constraints_func(result.x)\n                if np.all(cons >= -1e-9) and -result.fun > np.sum(x_current[2*n:]):\n                    x_current = result.x.copy()\n        \n        centers = x_current[:2*n].reshape(n, 2)\n        radii = x_current[2*n:]\n        sum_radii = np.sum(radii, dtype=np.float64)\n        \n        cons = constraints_func(x_current)\n        if np.all(cons >= -1e-9) and sum_radii > best_sum:\n            best_sum = sum_radii\n            best_centers = centers.copy()\n            best_radii = radii.copy()\n    \n    # Final intensive refinement\n    if best_centers is not None:\n        x_best = np.concatenate([best_centers.flatten(), best_radii], dtype=np.float64)\n        \n        for _ in range(200):\n            x_perturbed = x_best.copy()\n            x_perturbed[:2*n] += np.random.randn(2*n).astype(np.float64) * 0.0002\n            x_perturbed[:2*n] = np.clip(x_perturbed[:2*n], 0.001, 0.999)\n            \n            result = minimize(\n                objective, x_perturbed, method=\"SLSQP\", jac=objective_grad, bounds=bounds,\n                constraints={\"type\": \"ineq\", \"fun\": constraints_func, \"jac\": constraints_jac},\n                options={\"maxiter\": 1000, \"ftol\": 1e-15, \"eps\": 1e-10}\n            )\n            \n            cons = constraints_func(result.x)\n            if np.all(cons >= -1e-10) and -result.fun > best_sum:\n                best_sum = -result.fun\n                best_centers = result.x[:2*n].reshape(n, 2)\n                best_radii = result.x[2*n:]\n                x_best = result.x.copy()\n    \n    return best_centers, best_radii, best_sum\n\ndef run_packing():\n    return construct_packing()\n\nTry ADAPTIVE perturbation strategy:\n1. Start with large perturbations (1e-5)\n2. Gradually decrease to 1e-10\n3. At each scale, perturb and re-optimize\n4. Keep best seen across all scales\n\nMulti-scale perturbation for thorough exploration.",
  "response": "I'll enhance the solution with an adaptive perturbation strategy and multi-scale exploration to find better packings.\n\n```python\nimport numpy as np\nfrom scipy.optimize import minimize\n\ndef construct_packing():\n    n = 26\n    \n    def objective(x):\n        return -np.sum(x[2*n:], dtype=np.float64)\n    \n    def objective_grad(x):\n        grad = np.zeros(3*n, dtype=np.float64)\n        grad[2*n:] = -1.0\n        return grad\n    \n    def constraints_func(x):\n        centers = x[:2*n].reshape(n, 2).astype(np.float64)\n        radii = x[2*n:].astype(np.float64)\n        \n        # Boundary constraints (4n)\n        boundary = np.concatenate([\n            centers[:, 0] - radii,\n            1.0 - centers[:, 0] - radii,\n            centers[:, 1] - radii,\n            1.0 - centers[:, 1] - radii\n        ], dtype=np.float64)\n        \n        # Non-overlap constraints\n        overlaps = []\n        for i in range(n):\n            for j in range(i+1, n):\n                dx = centers[i, 0] - centers[j, 0]\n                dy = centers[i, 1] - centers[j, 1]\n                dist = np.sqrt(dx*dx + dy*dy + 1e-20)\n                overlaps.append(dist - radii[i] - radii[j])\n        \n        return np.concatenate([boundary, overlaps], dtype=np.float64)\n    \n    def constraints_jac(x):\n        centers = x[:2*n].reshape(n, 2).astype(np.float64)\n        radii = x[2*n:].astype(np.float64)\n        \n        num_constraints = 4*n + n*(n-1)//2\n        jac = np.zeros((num_constraints, 3*n), dtype=np.float64)\n        \n        # Boundary constraints gradients\n        for i in range(n):\n            jac[i, 2*i] = 1.0\n            jac[i, 2*n + i] = -1.0\n        \n        for i in range(n):\n            jac[n + i, 2*i] = -1.0\n            jac[n + i, 2*n + i] = -1.0\n        \n        for i in range(n):\n            jac[2*n + i, 2*i + 1] = 1.0\n            jac[2*n + i, 2*n + i] = -1.0\n        \n        for i in range(n):\n            jac[3*n + i, 2*i + 1] = -1.0\n            jac[3*n + i, 2*n + i] = -1.0\n        \n        # Non-overlap constraints gradients\n        constraint_idx = 4*n\n        for i in range(n):\n            for j in range(i+1, n):\n                dx = centers[i, 0] - centers[j, 0]\n                dy = centers[i, 1] - centers[j, 1]\n                dist_sq = dx*dx + dy*dy\n                dist = np.sqrt(dist_sq + 1e-20)\n                \n                inv_dist = 1.0 / dist\n                jac[constraint_idx, 2*i] = dx * inv_dist\n                jac[constraint_idx, 2*i + 1] = dy * inv_dist\n                jac[constraint_idx, 2*j] = -dx * inv_dist\n                jac[constraint_idx, 2*j + 1] = -dy * inv_dist\n                jac[constraint_idx, 2*n + i] = -1.0\n                jac[constraint_idx, 2*n + j] = -1.0\n                \n                constraint_idx += 1\n        \n        return jac\n    \n    bounds = [(0.0, 1.0)] * (2*n) + [(0.001, 0.5)] * n\n    \n    def create_hex_init(r_est=0.095):\n        centers = []\n        dy = r_est * np.sqrt(3.0)\n        dx = 2.0 * r_est\n        \n        row = 0\n        y = r_est\n        while y < 1.0 - r_est + 0.01 and len(centers) < n:\n            x_offset = r_est if row % 2 == 0 else r_est + dx/2.0\n            x = x_offset\n            while x < 1.0 - r_est + 0.01 and len(centers) < n:\n                centers.append([x, y])\n                x += dx\n            y += dy\n            row += 1\n        \n        return np.array(centers[:n], dtype=np.float64)\n    \n    def create_grid_init(rows_config):\n        centers = []\n        num_rows = len(rows_config)\n        y_spacing = 0.9 / num_rows\n        \n        for row_idx, num_in_row in enumerate(rows_config):\n            y = 0.05 + (row_idx + 0.5) * y_spacing\n            x_spacing = 0.9 / num_in_row\n            x_start = 0.05 + x_spacing/2.0\n            for i in range(num_in_row):\n                x = x_start + i * x_spacing\n                centers.append([x, y])\n                if len(centers) >= n:\n                    break\n            if len(centers) >= n:\n                break\n        \n        return np.array(centers[:n], dtype=np.float64)\n    \n    def adaptive_refine(x_init, max_iters=300):\n        \"\"\"Adaptive multi-scale perturbation refinement\"\"\"\n        x_best = x_init.copy()\n        best_sum = np.sum(x_best[2*n:])\n        \n        # Multi-scale perturbation schedule\n        scales = [0.05, 0.02, 0.01, 0.005, 0.002, 0.001, 0.0005, 0.0002, 0.0001, 0.00005, 0.00002, 0.00001]\n        \n        for scale in scales:\n            improved = False\n            attempts_per_scale = max(10, int(50 / (scale * 1000 + 1)))\n            \n            for attempt in range(attempts_per_scale):\n                # Adaptive perturbation: more on centers, less on radii\n                x_perturbed = x_best.copy()\n                x_perturbed[:2*n] += np.random.randn(2*n).astype(np.float64) * scale\n                x_perturbed[2*n:] += np.random.randn(n).astype(np.float64) * scale * 0.5\n                x_perturbed[:2*n] = np.clip(x_perturbed[:2*n], 0.001, 0.999)\n                x_perturbed[2*n:] = np.clip(x_perturbed[2*n:], 0.001, 0.5)\n                \n                result = minimize(\n                    objective, x_perturbed, method=\"SLSQP\", jac=objective_grad, bounds=bounds,\n                    constraints={\"type\": \"ineq\", \"fun\": constraints_func, \"jac\": constraints_jac},\n                    options={\"maxiter\": 1000, \"ftol\": 1e-15, \"eps\": 1e-10}\n                )\n                \n                cons = constraints_func(result.x)\n                current_sum = np.sum(result.x[2*n:])\n                \n                if np.all(cons >= -1e-9) and current_sum > best_sum:\n                    best_sum = current_sum\n                    x_best = result.x.copy()\n                    improved = True\n            \n            # If no improvement at this scale, try smaller perturbations\n            if not improved and scale > 0.0001:\n                continue\n        \n        return x_best, best_sum\n    \n    best_sum = 0.0\n    best_centers = None\n    best_radii = None\n    \n    # Generate diverse initializations\n    inits = []\n    \n    # Hexagonal packings with various radii\n    for r_est in np.linspace(0.085, 0.102, 12):\n        inits.append(create_hex_init(r_est))\n    \n    # Grid-based configurations\n    grid_configs = [\n        [5, 5, 5, 5, 6],\n        [6, 5, 5, 5, 5],\n        [5, 6, 5, 5, 5],\n        [5, 5, 6, 5, 5],\n        [5, 5, 5, 6, 5],\n        [4, 5, 6, 5, 6],\n        [6, 5, 6, 5, 4],\n        [5, 6, 4, 6, 5],\n    ]\n    \n    for config in grid_configs:\n        inits.append(create_grid_init(config))\n    \n    # Process each initialization\n    for init_idx, centers_init in enumerate(inits):\n        if len(centers_init) < n:\n            continue\n        \n        # Compute safe initial radii\n        radii_init = np.full(n, 0.5, dtype=np.float64)\n        for i in range(n):\n            radii_init[i] = min(radii_init[i], centers_init[i, 0], \n                               1.0 - centers_init[i, 0],\n                               centers_init[i, 1], 1.0 - centers_init[i, 1])\n            for j in range(n):\n                if i != j:\n                    dist = np.linalg.norm(centers_init[i] - centers_init[j])\n                    radii_init[i] = min(radii_init[i], dist / 2.0 - 0.001)\n        \n        radii_init = np.maximum(radii_init, 0.01)\n        x0 = np.concatenate([centers_init.flatten(), radii_init], dtype=np.float64)\n        \n        # Initial optimization\n        result = minimize(\n            objective, x0, method=\"SLSQP\", jac=objective_grad, bounds=bounds,\n            constraints={\"type\": \"ineq\", \"fun\": constraints_func, \"jac\": constraints_jac},\n            options={\"maxiter\": 2000, \"ftol\": 1e-15, \"eps\": 1e-10}\n        )\n        \n        # Adaptive refinement\n        x_refined, sum_refined = adaptive_refine(result.x, max_iters=300)\n        \n        cons = constraints_func(x_refined)\n        if np.all(cons >= -1e-9) and sum_refined > best_sum:\n            best_sum = sum_refined\n            best_centers = x_refined[:2*n].reshape(n, 2)\n            best_radii = x_refined[2*n:]\n    \n    # Final intensive refinement on best solution\n    if best_centers is not None:\n        x_best = np.concatenate([best_centers.flatten(), best_radii], dtype=np.float64)\n        x_final, sum_final = adaptive_refine(x_best, max_iters=500)\n        \n        cons = constraints_func(x_final)\n        if np.all(cons >= -1e-10) and sum_final > best_sum:\n            best_sum = sum_final\n            best_centers = x_final[:2*n].reshape(n, 2)\n            best_radii = x_final[2*n:]\n    \n    return best_centers, best_radii, best_sum\n\ndef run_packing():\n    return construct_packing()\n```\n\nKey improvements:\n\n1. **Adaptive Multi-Scale Perturbation**: Starts with large perturbations (0.05) and gradually decreases to very fine scales (0.00001), allowing both exploration and fine-tuning.\n\n2. **Scale-Dependent Attempts**: More attempts at finer scales where precision matters most.\n\n3. **Differential Perturbation**: Centers get full perturbation, radii get 50% to maintain stability.\n\n4. **Diverse Initializations**: 12 hexagonal packings + 8 grid configurations for better coverage of solution space.\n\n5. **Two-Stage Refinement**: Initial optimization followed by adaptive refinement, then final intensive refinement on the best solution.\n\nThis approach thoroughly explores the solution space while progressively refining to find high-quality packings.",
  "reasoning": "I'll enhance the solution with an adaptive perturbation strategy and multi-scale exploration to find better packings.\n\nKey improvements:\n\n1. **Adaptive Multi-Scale Perturbation**: Starts with large perturbations (0.05) and gradually decreases to very fine scales (0.00001), allowing both exploration and fine-tuning.\n\n2. **Scale-Dependent Attempts**: More attempts at finer scales where precision matters most.\n\n3. **Differential Perturbation**: Centers get full perturbation, radii get 50% to maintain stability.\n\n4. **Diverse Initializations**: 12 hexagonal packings + 8 grid configurations for better coverage of solution space.\n\n5. **Two-Stage Refinement**: Initial optimization followed by adaptive refinement, then final intensive refinement on the best solution.\n\nThis approach thoroughly explores the solution space while progressively refining to find high-quality packings.",
  "timestamp": "2025-12-31T21:16:53.628284",
  "cost_data": null,
  "model_config": {
    "model": "anthropic/claude-sonnet-4.5",
    "temperature": 0.3
  }
}