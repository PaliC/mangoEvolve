{
  "trial_id": "trial_13_1",
  "generation": 13,
  "parent_id": "trial_12_1",
  "code": "import numpy as np\nfrom scipy.optimize import minimize, minimize_scalar\n\ndef construct_packing():\n    n = 26\n    \n    def objective(x):\n        return -np.sum(x[2*n:])\n    \n    def objective_grad(x):\n        grad = np.zeros(3*n)\n        grad[2*n:] = -1.0\n        return grad\n    \n    def constraints_func(x):\n        centers = x[:2*n].reshape(n, 2)\n        radii = x[2*n:]\n        \n        # Boundary constraints (4n)\n        boundary = np.concatenate([\n            centers[:, 0] - radii,\n            1 - centers[:, 0] - radii,\n            centers[:, 1] - radii,\n            1 - centers[:, 1] - radii\n        ])\n        \n        # Non-overlap constraints\n        overlaps = []\n        for i in range(n):\n            for j in range(i+1, n):\n                dist = np.sqrt((centers[i, 0] - centers[j, 0])**2 + \n                              (centers[i, 1] - centers[j, 1])**2)\n                overlaps.append(dist - radii[i] - radii[j])\n        \n        return np.concatenate([boundary, overlaps])\n    \n    def constraints_jac(x):\n        centers = x[:2*n].reshape(n, 2)\n        radii = x[2*n:]\n        \n        num_constraints = 4*n + n*(n-1)//2\n        jac = np.zeros((num_constraints, 3*n))\n        \n        # Boundary constraints gradients\n        for i in range(n):\n            jac[i, 2*i] = 1.0\n            jac[i, 2*n + i] = -1.0\n        \n        for i in range(n):\n            jac[n + i, 2*i] = -1.0\n            jac[n + i, 2*n + i] = -1.0\n        \n        for i in range(n):\n            jac[2*n + i, 2*i + 1] = 1.0\n            jac[2*n + i, 2*n + i] = -1.0\n        \n        for i in range(n):\n            jac[3*n + i, 2*i + 1] = -1.0\n            jac[3*n + i, 2*n + i] = -1.0\n        \n        # Non-overlap constraints gradients\n        constraint_idx = 4*n\n        for i in range(n):\n            for j in range(i+1, n):\n                dx = centers[i, 0] - centers[j, 0]\n                dy = centers[i, 1] - centers[j, 1]\n                dist = np.sqrt(dx**2 + dy**2)\n                \n                if dist > 1e-10:\n                    jac[constraint_idx, 2*i] = dx / dist\n                    jac[constraint_idx, 2*i + 1] = dy / dist\n                    jac[constraint_idx, 2*j] = -dx / dist\n                    jac[constraint_idx, 2*j + 1] = -dy / dist\n                    jac[constraint_idx, 2*n + i] = -1.0\n                    jac[constraint_idx, 2*n + j] = -1.0\n                \n                constraint_idx += 1\n        \n        return jac\n    \n    def coordinate_descent_refinement(x, num_cycles=3):\n        \"\"\"Refine solution using coordinate descent with analytical gradients\"\"\"\n        x_current = x.copy()\n        current_sum = np.sum(x_current[2*n:])\n        \n        for cycle in range(num_cycles):\n            improved = False\n            # Iterate over all variables\n            for var_idx in range(3*n):\n                # Create objective function for this single variable\n                def single_var_obj(val):\n                    x_temp = x_current.copy()\n                    x_temp[var_idx] = val\n                    cons = constraints_func(x_temp)\n                    if np.any(cons < -1e-9):\n                        return 1e10  # Penalty for constraint violation\n                    return -np.sum(x_temp[2*n:])\n                \n                def single_var_grad(val):\n                    x_temp = x_current.copy()\n                    x_temp[var_idx] = val\n                    grad = objective_grad(x_temp)\n                    return grad[var_idx]\n                \n                # Determine bounds for this variable\n                if var_idx < 2*n:\n                    bounds = (0.0, 1.0)\n                else:\n                    bounds = (0.001, 0.5)\n                \n                # Optimize this single variable\n                result = minimize_scalar(\n                    single_var_obj,\n                    bounds=bounds,\n                    method='bounded',\n                    options={'xatol': 1e-10}\n                )\n                \n                # Check if improvement and constraints satisfied\n                x_test = x_current.copy()\n                x_test[var_idx] = result.x\n                cons = constraints_func(x_test)\n                new_sum = np.sum(x_test[2*n:])\n                \n                if np.all(cons >= -1e-9) and new_sum > current_sum:\n                    x_current = x_test\n                    current_sum = new_sum\n                    improved = True\n            \n            if not improved:\n                break\n        \n        return x_current\n    \n    bounds = [(0, 1)] * (2*n) + [(0.001, 0.5)] * n\n    \n    def create_hex_init(r_est=0.095):\n        centers = []\n        dy = r_est * np.sqrt(3)\n        dx = 2 * r_est\n        \n        row = 0\n        y = r_est\n        while y < 1 - r_est + 0.01 and len(centers) < n:\n            x_offset = r_est if row % 2 == 0 else r_est + dx/2\n            x = x_offset\n            while x < 1 - r_est + 0.01 and len(centers) < n:\n                centers.append([x, y])\n                x += dx\n            y += dy\n            row += 1\n        \n        return np.array(centers[:n])\n    \n    def create_optimized_init():\n        centers = []\n        rows = [5, 6, 5, 5, 5]\n        y_positions = [0.1, 0.28, 0.46, 0.64, 0.82]\n        \n        for row_idx, (num_in_row, y) in enumerate(zip(rows, y_positions)):\n            x_spacing = 0.9 / num_in_row\n            x_start = 0.05 + x_spacing/2\n            for i in range(num_in_row):\n                x = x_start + i * x_spacing\n                centers.append([x, y])\n        \n        return np.array(centers[:n])\n    \n    best_sum = 0\n    best_centers = None\n    best_radii = None\n    \n    # Try multiple initializations\n    inits = []\n    for r_est in [0.088, 0.090, 0.092, 0.094, 0.096, 0.098]:\n        inits.append(create_hex_init(r_est))\n    inits.append(create_optimized_init())\n    \n    for init_idx, centers_init in enumerate(inits):\n        if len(centers_init) < n:\n            continue\n            \n        # Compute initial safe radii\n        radii_init = np.full(n, 0.5)\n        for i in range(n):\n            radii_init[i] = min(radii_init[i], centers_init[i, 0], \n                               1 - centers_init[i, 0],\n                               centers_init[i, 1], 1 - centers_init[i, 1])\n            for j in range(n):\n                if i != j:\n                    dist = np.linalg.norm(centers_init[i] - centers_init[j])\n                    radii_init[i] = min(radii_init[i], dist / 2 - 0.001)\n        \n        radii_init = np.maximum(radii_init, 0.01)\n        x0 = np.concatenate([centers_init.flatten(), radii_init])\n        \n        # First optimization pass with analytical gradients\n        result = minimize(\n            objective, x0, method=\"SLSQP\", jac=objective_grad, bounds=bounds,\n            constraints={\"type\": \"ineq\", \"fun\": constraints_func, \"jac\": constraints_jac},\n            options={\"maxiter\": 1000, \"ftol\": 1e-12}\n        )\n        \n        x_current = result.x.copy()\n        \n        # Coordinate descent refinement\n        x_current = coordinate_descent_refinement(x_current, num_cycles=3)\n        \n        # Iterative refinement with perturbations\n        for scale in [0.02, 0.01, 0.005, 0.002, 0.001, 0.0005]:\n            for _ in range(20):\n                x_perturbed = x_current.copy()\n                x_perturbed[:2*n] += np.random.randn(2*n) * scale\n                x_perturbed[:2*n] = np.clip(x_perturbed[:2*n], 0.01, 0.99)\n                \n                result = minimize(\n                    objective, x_perturbed, method=\"SLSQP\", jac=objective_grad, bounds=bounds,\n                    constraints={\"type\": \"ineq\", \"fun\": constraints_func, \"jac\": constraints_jac},\n                    options={\"maxiter\": 500, \"ftol\": 1e-12}\n                )\n                \n                cons = constraints_func(result.x)\n                if np.all(cons >= -1e-8) and -result.fun > np.sum(x_current[2*n:]):\n                    x_current = result.x.copy()\n                    # Apply coordinate descent after each successful perturbation\n                    x_current = coordinate_descent_refinement(x_current, num_cycles=2)\n        \n        centers = x_current[:2*n].reshape(n, 2)\n        radii = x_current[2*n:]\n        sum_radii = np.sum(radii)\n        \n        cons = constraints_func(x_current)\n        if np.all(cons >= -1e-8) and sum_radii > best_sum:\n            best_sum = sum_radii\n            best_centers = centers.copy()\n            best_radii = radii.copy()\n    \n    # Final intensive refinement on best solution\n    if best_centers is not None:\n        x_best = np.concatenate([best_centers.flatten(), best_radii])\n        \n        # Apply coordinate descent\n        x_best = coordinate_descent_refinement(x_best, num_cycles=5)\n        \n        for _ in range(150):\n            x_perturbed = x_best.copy()\n            x_perturbed[:2*n] += np.random.randn(2*n) * 0.0003\n            x_perturbed[:2*n] = np.clip(x_perturbed[:2*n], 0.001, 0.999)\n            \n            result = minimize(\n                objective, x_perturbed, method=\"SLSQP\", jac=objective_grad, bounds=bounds,\n                constraints={\"type\": \"ineq\", \"fun\": constraints_func, \"jac\": constraints_jac},\n                options={\"maxiter\": 600, \"ftol\": 1e-13}\n            )\n            \n            cons = constraints_func(result.x)\n            if np.all(cons >= -1e-9) and -result.fun > best_sum:\n                best_sum = -result.fun\n                best_centers = result.x[:2*n].reshape(n, 2)\n                best_radii = result.x[2*n:]\n                x_best = result.x.copy()\n                # Apply coordinate descent after improvement\n                x_best = coordinate_descent_refinement(x_best, num_cycles=3)\n                best_sum = np.sum(x_best[2*n:])\n                best_centers = x_best[:2*n].reshape(n, 2)\n                best_radii = x_best[2*n:]\n    \n    return best_centers, best_radii, best_sum\n\ndef run_packing():\n    return construct_packing()",
  "metrics": {
    "valid": true,
    "score": 2.6359830850269796,
    "eval_time": 72.389732837677,
    "error": null
  },
  "prompt": "import numpy as np\nfrom scipy.optimize import minimize\n\ndef construct_packing():\n    n = 26\n    \n    def objective(x):\n        return -np.sum(x[2*n:])\n    \n    def objective_grad(x):\n        grad = np.zeros(3*n)\n        grad[2*n:] = -1.0\n        return grad\n    \n    def constraints_func(x):\n        centers = x[:2*n].reshape(n, 2)\n        radii = x[2*n:]\n        \n        # Boundary constraints (4n)\n        boundary = np.concatenate([\n            centers[:, 0] - radii,\n            1 - centers[:, 0] - radii,\n            centers[:, 1] - radii,\n            1 - centers[:, 1] - radii\n        ])\n        \n        # Non-overlap constraints\n        overlaps = []\n        for i in range(n):\n            for j in range(i+1, n):\n                dist = np.sqrt((centers[i, 0] - centers[j, 0])**2 + \n                              (centers[i, 1] - centers[j, 1])**2)\n                overlaps.append(dist - radii[i] - radii[j])\n        \n        return np.concatenate([boundary, overlaps])\n    \n    def constraints_jac(x):\n        centers = x[:2*n].reshape(n, 2)\n        radii = x[2*n:]\n        \n        num_constraints = 4*n + n*(n-1)//2\n        jac = np.zeros((num_constraints, 3*n))\n        \n        # Boundary constraints gradients\n        # centers[:, 0] - radii >= 0\n        for i in range(n):\n            jac[i, 2*i] = 1.0      # d/dx_i\n            jac[i, 2*n + i] = -1.0  # d/dr_i\n        \n        # 1 - centers[:, 0] - radii >= 0\n        for i in range(n):\n            jac[n + i, 2*i] = -1.0\n            jac[n + i, 2*n + i] = -1.0\n        \n        # centers[:, 1] - radii >= 0\n        for i in range(n):\n            jac[2*n + i, 2*i + 1] = 1.0\n            jac[2*n + i, 2*n + i] = -1.0\n        \n        # 1 - centers[:, 1] - radii >= 0\n        for i in range(n):\n            jac[3*n + i, 2*i + 1] = -1.0\n            jac[3*n + i, 2*n + i] = -1.0\n        \n        # Non-overlap constraints gradients\n        constraint_idx = 4*n\n        for i in range(n):\n            for j in range(i+1, n):\n                dx = centers[i, 0] - centers[j, 0]\n                dy = centers[i, 1] - centers[j, 1]\n                dist = np.sqrt(dx**2 + dy**2)\n                \n                if dist > 1e-10:\n                    # Gradient w.r.t. x_i\n                    jac[constraint_idx, 2*i] = dx / dist\n                    # Gradient w.r.t. y_i\n                    jac[constraint_idx, 2*i + 1] = dy / dist\n                    # Gradient w.r.t. x_j\n                    jac[constraint_idx, 2*j] = -dx / dist\n                    # Gradient w.r.t. y_j\n                    jac[constraint_idx, 2*j + 1] = -dy / dist\n                    # Gradient w.r.t. r_i\n                    jac[constraint_idx, 2*n + i] = -1.0\n                    # Gradient w.r.t. r_j\n                    jac[constraint_idx, 2*n + j] = -1.0\n                \n                constraint_idx += 1\n        \n        return jac\n    \n    bounds = [(0, 1)] * (2*n) + [(0.001, 0.5)] * n\n    \n    def create_hex_init(r_est=0.095):\n        centers = []\n        dy = r_est * np.sqrt(3)\n        dx = 2 * r_est\n        \n        row = 0\n        y = r_est\n        while y < 1 - r_est + 0.01 and len(centers) < n:\n            x_offset = r_est if row % 2 == 0 else r_est + dx/2\n            x = x_offset\n            while x < 1 - r_est + 0.01 and len(centers) < n:\n                centers.append([x, y])\n                x += dx\n            y += dy\n            row += 1\n        \n        return np.array(centers[:n])\n    \n    def create_optimized_init():\n        centers = []\n        rows = [5, 6, 5, 5, 5]\n        y_positions = [0.1, 0.28, 0.46, 0.64, 0.82]\n        \n        for row_idx, (num_in_row, y) in enumerate(zip(rows, y_positions)):\n            x_spacing = 0.9 / num_in_row\n            x_start = 0.05 + x_spacing/2\n            for i in range(num_in_row):\n                x = x_start + i * x_spacing\n                centers.append([x, y])\n        \n        return np.array(centers[:n])\n    \n    best_sum = 0\n    best_centers = None\n    best_radii = None\n    \n    # Try multiple initializations\n    inits = []\n    for r_est in [0.088, 0.090, 0.092, 0.094, 0.096, 0.098]:\n        inits.append(create_hex_init(r_est))\n    inits.append(create_optimized_init())\n    \n    for init_idx, centers_init in enumerate(inits):\n        if len(centers_init) < n:\n            continue\n            \n        # Compute initial safe radii\n        radii_init = np.full(n, 0.5)\n        for i in range(n):\n            radii_init[i] = min(radii_init[i], centers_init[i, 0], \n                               1 - centers_init[i, 0],\n                               centers_init[i, 1], 1 - centers_init[i, 1])\n            for j in range(n):\n                if i != j:\n                    dist = np.linalg.norm(centers_init[i] - centers_init[j])\n                    radii_init[i] = min(radii_init[i], dist / 2 - 0.001)\n        \n        radii_init = np.maximum(radii_init, 0.01)\n        x0 = np.concatenate([centers_init.flatten(), radii_init])\n        \n        # First optimization pass with analytical gradients\n        result = minimize(\n            objective, x0, method=\"SLSQP\", jac=objective_grad, bounds=bounds,\n            constraints={\"type\": \"ineq\", \"fun\": constraints_func, \"jac\": constraints_jac},\n            options={\"maxiter\": 1000, \"ftol\": 1e-12}\n        )\n        \n        x_current = result.x.copy()\n        \n        # Iterative refinement with perturbations\n        for scale in [0.02, 0.01, 0.005, 0.002, 0.001, 0.0005]:\n            for _ in range(20):\n                x_perturbed = x_current.copy()\n                x_perturbed[:2*n] += np.random.randn(2*n) * scale\n                x_perturbed[:2*n] = np.clip(x_perturbed[:2*n], 0.01, 0.99)\n                \n                result = minimize(\n                    objective, x_perturbed, method=\"SLSQP\", jac=objective_grad, bounds=bounds,\n                    constraints={\"type\": \"ineq\", \"fun\": constraints_func, \"jac\": constraints_jac},\n                    options={\"maxiter\": 500, \"ftol\": 1e-12}\n                )\n                \n                cons = constraints_func(result.x)\n                if np.all(cons >= -1e-8) and -result.fun > np.sum(x_current[2*n:]):\n                    x_current = result.x.copy()\n        \n        centers = x_current[:2*n].reshape(n, 2)\n        radii = x_current[2*n:]\n        sum_radii = np.sum(radii)\n        \n        cons = constraints_func(x_current)\n        if np.all(cons >= -1e-8) and sum_radii > best_sum:\n            best_sum = sum_radii\n            best_centers = centers.copy()\n            best_radii = radii.copy()\n    \n    # Final intensive refinement on best solution\n    if best_centers is not None:\n        x_best = np.concatenate([best_centers.flatten(), best_radii])\n        \n        for _ in range(150):\n            x_perturbed = x_best.copy()\n            x_perturbed[:2*n] += np.random.randn(2*n) * 0.0003\n            x_perturbed[:2*n] = np.clip(x_perturbed[:2*n], 0.001, 0.999)\n            \n            result = minimize(\n                objective, x_perturbed, method=\"SLSQP\", jac=objective_grad, bounds=bounds,\n                constraints={\"type\": \"ineq\", \"fun\": constraints_func, \"jac\": constraints_jac},\n                options={\"maxiter\": 600, \"ftol\": 1e-13}\n            )\n            \n            cons = constraints_func(result.x)\n            if np.all(cons >= -1e-9) and -result.fun > best_sum:\n                best_sum = -result.fun\n                best_centers = result.x[:2*n].reshape(n, 2)\n                best_radii = result.x[2*n:]\n                x_best = result.x.copy()\n    \n    return best_centers, best_radii, best_sum\n\ndef run_packing():\n    return construct_packing()\n\nThis is our best solution with analytical gradients!\n\nAdd COORDINATE DESCENT refinement after SLSQP:\nFor each of 78 variables (26*3):\n  - Use scipy.optimize.minimize_scalar with analytical gradient\n  - Optimize just that one variable\n  - Keep if improved\nRepeat 3 full cycles.\n\nAnalytical gradients + coordinate descent may reach closer to optimum.",
  "response": "```python\nimport numpy as np\nfrom scipy.optimize import minimize, minimize_scalar\n\ndef construct_packing():\n    n = 26\n    \n    def objective(x):\n        return -np.sum(x[2*n:])\n    \n    def objective_grad(x):\n        grad = np.zeros(3*n)\n        grad[2*n:] = -1.0\n        return grad\n    \n    def constraints_func(x):\n        centers = x[:2*n].reshape(n, 2)\n        radii = x[2*n:]\n        \n        # Boundary constraints (4n)\n        boundary = np.concatenate([\n            centers[:, 0] - radii,\n            1 - centers[:, 0] - radii,\n            centers[:, 1] - radii,\n            1 - centers[:, 1] - radii\n        ])\n        \n        # Non-overlap constraints\n        overlaps = []\n        for i in range(n):\n            for j in range(i+1, n):\n                dist = np.sqrt((centers[i, 0] - centers[j, 0])**2 + \n                              (centers[i, 1] - centers[j, 1])**2)\n                overlaps.append(dist - radii[i] - radii[j])\n        \n        return np.concatenate([boundary, overlaps])\n    \n    def constraints_jac(x):\n        centers = x[:2*n].reshape(n, 2)\n        radii = x[2*n:]\n        \n        num_constraints = 4*n + n*(n-1)//2\n        jac = np.zeros((num_constraints, 3*n))\n        \n        # Boundary constraints gradients\n        for i in range(n):\n            jac[i, 2*i] = 1.0\n            jac[i, 2*n + i] = -1.0\n        \n        for i in range(n):\n            jac[n + i, 2*i] = -1.0\n            jac[n + i, 2*n + i] = -1.0\n        \n        for i in range(n):\n            jac[2*n + i, 2*i + 1] = 1.0\n            jac[2*n + i, 2*n + i] = -1.0\n        \n        for i in range(n):\n            jac[3*n + i, 2*i + 1] = -1.0\n            jac[3*n + i, 2*n + i] = -1.0\n        \n        # Non-overlap constraints gradients\n        constraint_idx = 4*n\n        for i in range(n):\n            for j in range(i+1, n):\n                dx = centers[i, 0] - centers[j, 0]\n                dy = centers[i, 1] - centers[j, 1]\n                dist = np.sqrt(dx**2 + dy**2)\n                \n                if dist > 1e-10:\n                    jac[constraint_idx, 2*i] = dx / dist\n                    jac[constraint_idx, 2*i + 1] = dy / dist\n                    jac[constraint_idx, 2*j] = -dx / dist\n                    jac[constraint_idx, 2*j + 1] = -dy / dist\n                    jac[constraint_idx, 2*n + i] = -1.0\n                    jac[constraint_idx, 2*n + j] = -1.0\n                \n                constraint_idx += 1\n        \n        return jac\n    \n    def coordinate_descent_refinement(x, num_cycles=3):\n        \"\"\"Refine solution using coordinate descent with analytical gradients\"\"\"\n        x_current = x.copy()\n        current_sum = np.sum(x_current[2*n:])\n        \n        for cycle in range(num_cycles):\n            improved = False\n            # Iterate over all variables\n            for var_idx in range(3*n):\n                # Create objective function for this single variable\n                def single_var_obj(val):\n                    x_temp = x_current.copy()\n                    x_temp[var_idx] = val\n                    cons = constraints_func(x_temp)\n                    if np.any(cons < -1e-9):\n                        return 1e10  # Penalty for constraint violation\n                    return -np.sum(x_temp[2*n:])\n                \n                def single_var_grad(val):\n                    x_temp = x_current.copy()\n                    x_temp[var_idx] = val\n                    grad = objective_grad(x_temp)\n                    return grad[var_idx]\n                \n                # Determine bounds for this variable\n                if var_idx < 2*n:\n                    bounds = (0.0, 1.0)\n                else:\n                    bounds = (0.001, 0.5)\n                \n                # Optimize this single variable\n                result = minimize_scalar(\n                    single_var_obj,\n                    bounds=bounds,\n                    method='bounded',\n                    options={'xatol': 1e-10}\n                )\n                \n                # Check if improvement and constraints satisfied\n                x_test = x_current.copy()\n                x_test[var_idx] = result.x\n                cons = constraints_func(x_test)\n                new_sum = np.sum(x_test[2*n:])\n                \n                if np.all(cons >= -1e-9) and new_sum > current_sum:\n                    x_current = x_test\n                    current_sum = new_sum\n                    improved = True\n            \n            if not improved:\n                break\n        \n        return x_current\n    \n    bounds = [(0, 1)] * (2*n) + [(0.001, 0.5)] * n\n    \n    def create_hex_init(r_est=0.095):\n        centers = []\n        dy = r_est * np.sqrt(3)\n        dx = 2 * r_est\n        \n        row = 0\n        y = r_est\n        while y < 1 - r_est + 0.01 and len(centers) < n:\n            x_offset = r_est if row % 2 == 0 else r_est + dx/2\n            x = x_offset\n            while x < 1 - r_est + 0.01 and len(centers) < n:\n                centers.append([x, y])\n                x += dx\n            y += dy\n            row += 1\n        \n        return np.array(centers[:n])\n    \n    def create_optimized_init():\n        centers = []\n        rows = [5, 6, 5, 5, 5]\n        y_positions = [0.1, 0.28, 0.46, 0.64, 0.82]\n        \n        for row_idx, (num_in_row, y) in enumerate(zip(rows, y_positions)):\n            x_spacing = 0.9 / num_in_row\n            x_start = 0.05 + x_spacing/2\n            for i in range(num_in_row):\n                x = x_start + i * x_spacing\n                centers.append([x, y])\n        \n        return np.array(centers[:n])\n    \n    best_sum = 0\n    best_centers = None\n    best_radii = None\n    \n    # Try multiple initializations\n    inits = []\n    for r_est in [0.088, 0.090, 0.092, 0.094, 0.096, 0.098]:\n        inits.append(create_hex_init(r_est))\n    inits.append(create_optimized_init())\n    \n    for init_idx, centers_init in enumerate(inits):\n        if len(centers_init) < n:\n            continue\n            \n        # Compute initial safe radii\n        radii_init = np.full(n, 0.5)\n        for i in range(n):\n            radii_init[i] = min(radii_init[i], centers_init[i, 0], \n                               1 - centers_init[i, 0],\n                               centers_init[i, 1], 1 - centers_init[i, 1])\n            for j in range(n):\n                if i != j:\n                    dist = np.linalg.norm(centers_init[i] - centers_init[j])\n                    radii_init[i] = min(radii_init[i], dist / 2 - 0.001)\n        \n        radii_init = np.maximum(radii_init, 0.01)\n        x0 = np.concatenate([centers_init.flatten(), radii_init])\n        \n        # First optimization pass with analytical gradients\n        result = minimize(\n            objective, x0, method=\"SLSQP\", jac=objective_grad, bounds=bounds,\n            constraints={\"type\": \"ineq\", \"fun\": constraints_func, \"jac\": constraints_jac},\n            options={\"maxiter\": 1000, \"ftol\": 1e-12}\n        )\n        \n        x_current = result.x.copy()\n        \n        # Coordinate descent refinement\n        x_current = coordinate_descent_refinement(x_current, num_cycles=3)\n        \n        # Iterative refinement with perturbations\n        for scale in [0.02, 0.01, 0.005, 0.002, 0.001, 0.0005]:\n            for _ in range(20):\n                x_perturbed = x_current.copy()\n                x_perturbed[:2*n] += np.random.randn(2*n) * scale\n                x_perturbed[:2*n] = np.clip(x_perturbed[:2*n], 0.01, 0.99)\n                \n                result = minimize(\n                    objective, x_perturbed, method=\"SLSQP\", jac=objective_grad, bounds=bounds,\n                    constraints={\"type\": \"ineq\", \"fun\": constraints_func, \"jac\": constraints_jac},\n                    options={\"maxiter\": 500, \"ftol\": 1e-12}\n                )\n                \n                cons = constraints_func(result.x)\n                if np.all(cons >= -1e-8) and -result.fun > np.sum(x_current[2*n:]):\n                    x_current = result.x.copy()\n                    # Apply coordinate descent after each successful perturbation\n                    x_current = coordinate_descent_refinement(x_current, num_cycles=2)\n        \n        centers = x_current[:2*n].reshape(n, 2)\n        radii = x_current[2*n:]\n        sum_radii = np.sum(radii)\n        \n        cons = constraints_func(x_current)\n        if np.all(cons >= -1e-8) and sum_radii > best_sum:\n            best_sum = sum_radii\n            best_centers = centers.copy()\n            best_radii = radii.copy()\n    \n    # Final intensive refinement on best solution\n    if best_centers is not None:\n        x_best = np.concatenate([best_centers.flatten(), best_radii])\n        \n        # Apply coordinate descent\n        x_best = coordinate_descent_refinement(x_best, num_cycles=5)\n        \n        for _ in range(150):\n            x_perturbed = x_best.copy()\n            x_perturbed[:2*n] += np.random.randn(2*n) * 0.0003\n            x_perturbed[:2*n] = np.clip(x_perturbed[:2*n], 0.001, 0.999)\n            \n            result = minimize(\n                objective, x_perturbed, method=\"SLSQP\", jac=objective_grad, bounds=bounds,\n                constraints={\"type\": \"ineq\", \"fun\": constraints_func, \"jac\": constraints_jac},\n                options={\"maxiter\": 600, \"ftol\": 1e-13}\n            )\n            \n            cons = constraints_func(result.x)\n            if np.all(cons >= -1e-9) and -result.fun > best_sum:\n                best_sum = -result.fun\n                best_centers = result.x[:2*n].reshape(n, 2)\n                best_radii = result.x[2*n:]\n                x_best = result.x.copy()\n                # Apply coordinate descent after improvement\n                x_best = coordinate_descent_refinement(x_best, num_cycles=3)\n                best_sum = np.sum(x_best[2*n:])\n                best_centers = x_best[:2*n].reshape(n, 2)\n                best_radii = x_best[2*n:]\n    \n    return best_centers, best_radii, best_sum\n\ndef run_packing():\n    return construct_packing()\n```",
  "reasoning": "",
  "timestamp": "2025-12-31T21:08:54.858640",
  "cost_data": null,
  "model_config": {
    "model": "anthropic/claude-sonnet-4.5",
    "temperature": 0.3
  }
}