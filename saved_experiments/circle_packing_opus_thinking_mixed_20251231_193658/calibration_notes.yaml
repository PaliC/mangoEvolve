# MangoEvolve Calibration Notes
# The root LLM only sees the 'notes' section during evolution.
# Metadata is stored for validation purposes.

notes: '

  # CALIBRATION OBSERVATIONS


  ## Model Capabilities


  ### opus (anthropic/claude-opus-4.5)

  - **Cost**: $5.00/$25.00 per M tokens (EXPENSIVE)

  - **Tested**: temp=0.3 with reasoning question

  - **Strengths**: Excellent theoretical knowledge, well-organized explanations

  - **Best for**: Complex reasoning, strategic decisions, explaining optimization
  theory

  - **Use when**: Need deep insight or explaining why an approach should work


  ### sonnet (anthropic/claude-sonnet-4.5)

  - **Cost**: $3.00/$15.00 per M tokens (moderate)

  - **Tested**: temp=0.5 (general) and temp=0.2 (specific task)

  - **Strengths**: Clean, well-documented code; thorough implementations; proper constraint
  handling

  - **Code style**: Uses closures properly (make_constraint pattern), good variable
  naming

  - **Approach**: Grid-based initialization + SLSQP refinement

  - **Best for**: Production-quality code generation, well-structured solutions


  ### gemini-flash (google/gemini-3-flash-preview)

  - **Cost**: $0.50/$3.00 per M tokens (CHEAP)

  - **Tested**: temp=0.7

  - **Strengths**: Multi-start optimization strategy, good scipy usage

  - **Approach**: L-BFGS-B with multiple seeds, clean get_max_radius helper

  - **Best for**: Quick iterations, exploring many variations cheaply


  ### grok-fast (x-ai/grok-4.1-fast)

  - **Cost**: $0.20/$0.50 per M tokens (CHEAPEST)

  - **Tested**: temp=0.9

  - **Strengths**: Sophisticated two-stage approach (greedy placement + global polish)

  - **Approach**: 100 random starts per circle, then SLSQP refinement on full 78D
  problem

  - **Best for**: Quick creative explorations, generating diverse starting points


  ## Temperature Observations

  - temp=0.2-0.3: More focused, follows instructions closely

  - temp=0.5: Good balance of structure and creativity

  - temp=0.7-0.9: More creative approaches (multi-start, two-stage methods)


  ## Strategic Recommendations for Evolution


  1. **Initial exploration**: Use grok-fast/gemini-flash (cheap) at temp=0.7-0.9 for
  diverse approaches

  2. **Refinement**: Use sonnet at temp=0.2-0.5 to polish promising solutions

  3. **Strategic decisions**: Use opus sparingly for analyzing why solutions work/fail

  4. **High-value improvements**: Use sonnet/opus when close to optimum


  ## Code Patterns That Work Well

  - SLSQP with inequality constraints for circle packing

  - Multi-start optimization to avoid local minima

  - Greedy sequential placement as initialization

  - Global polish after initial placement

  - Lambda capture with default args for constraints (i=i pattern)

  '
metadata:
  child_llms:
  - alias: opus
    model: anthropic/claude-opus-4.5
    provider: openrouter
    cost_per_million_input_tokens: 5.0
    cost_per_million_output_tokens: 25.0
  - alias: sonnet
    model: anthropic/claude-sonnet-4.5
    provider: openrouter
    cost_per_million_input_tokens: 3.0
    cost_per_million_output_tokens: 15.0
  - alias: gemini-flash
    model: google/gemini-3-flash-preview
    provider: openrouter
    cost_per_million_input_tokens: 0.5
    cost_per_million_output_tokens: 3.0
  - alias: grok-fast
    model: x-ai/grok-4.1-fast
    provider: openrouter
    cost_per_million_input_tokens: 0.2
    cost_per_million_output_tokens: 0.5
  created_at: '2026-01-01T03:40:46.096417+00:00'
  experiment_name: circle_packing_opus_thinking_mixed
