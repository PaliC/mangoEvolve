{
  "trial_id": "trial_9_12",
  "generation": 9,
  "parent_id": "trial_8_0",
  "code": "import numpy as np\nfrom scipy.optimize import minimize, basinhopping\n\ndef min_max_dist_dim3_14():\n    \"\"\"\n    Places 14 points in 3D space to maximize the squared ratio (min pairwise distance / max pairwise distance)^2.\n    Refines the solution using Basin-hopping with a very low temperature and tiny step size,\n    incorporating an analytical Jacobian for precision.\n    \"\"\"\n    N = 14\n    \n    def get_grad(x, p):\n        \"\"\"\n        Calculates the soft min/max ratio and its analytical gradient.\n        Objective: Minimize - (soft_min_distance^2 / soft_max_distance^2).\n        \"\"\"\n        pts = x.reshape((N, 3))\n        # Vectorized pairwise differences and squared distances\n        diffs = pts[:, np.newaxis, :] - pts[np.newaxis, :, :]\n        d2_matrix = np.sum(diffs**2, axis=2)\n        \n        # Extract upper triangle for unique pairwise distances\n        iu = np.triu_indices(N, k=1)\n        d2 = d2_matrix[iu]\n        \n        min_d2 = np.min(d2)\n        max_d2 = np.max(d2)\n        \n        # Numerically stable LogSumExp for soft-min and soft-max\n        exp_min = np.exp(-p * (d2 - min_d2))\n        sum_exp_min = np.sum(exp_min)\n        s_min = - (1.0 / p) * np.log(sum_exp_min) + min_d2\n        \n        exp_max = np.exp(p * (d2 - max_d2))\n        sum_exp_max = np.sum(exp_max)\n        s_max = (1.0 / p) * np.log(sum_exp_max) + max_d2\n        \n        # Partial derivatives of soft_min and soft_max with respect to squared distances\n        ds_min_dd2 = exp_min / sum_exp_min\n        ds_max_dd2 = exp_max / sum_exp_max\n        \n        # Map derivatives back to N x N matrices\n        W_min = np.zeros((N, N))\n        W_min[iu] = ds_min_dd2\n        W_min = W_min + W_min.T\n        \n        W_max = np.zeros((N, N))\n        W_max[iu] = ds_max_dd2\n        W_max = W_max + W_max.T\n        \n        # Gradients with respect to coordinates\n        grad_s_min = np.sum(W_min[:, :, np.newaxis] * (2 * diffs), axis=1)\n        grad_s_max = np.sum(W_max[:, :, np.newaxis] * (2 * diffs), axis=1)\n        \n        # Objective F = -s_min / s_max\n        # dF/dx = - ( (1/s_max) * d(s_min)/dx - (s_min / s_max^2) * d(s_max)/dx )\n        grad_F = - (grad_s_min / s_max - (s_min / (s_max**2)) * grad_s_max)\n        \n        return -s_min / s_max, grad_F.flatten()\n\n    def final_obj(x):\n        \"\"\"Strict objective function for final refinement.\"\"\"\n        pts_ = x.reshape((N, 3))\n        d2_matrix = np.sum((pts_[:, np.newaxis, :] - pts_[np.newaxis, :, :])**2, axis=2)\n        d2 = d2_matrix[np.triu_indices(N, k=1)]\n        return -np.min(d2) / np.max(d2)\n\n    best_pts = None\n    best_val = -1.0\n    \n    # Initialization: One structured (capped hexagonal antiprism) and several random starts\n    pts_struct = []\n    pts_struct.append([0, 0, 1.0])\n    pts_struct.append([0, 0, -1.0])\n    for i in range(6):\n        theta = i * 2 * np.pi / 6\n        pts_struct.append([np.cos(theta), np.sin(theta), 0.5])\n        pts_struct.append([np.cos(theta + np.pi/6), np.sin(theta + np.pi/6), -0.5])\n    pts_struct = np.array(pts_struct)\n    \n    starts = [pts_struct] + [np.random.normal(0, 1, (N, 3)) for _ in range(5)]\n    \n    for pts in starts:\n        # Scale to unit sphere for a consistent initial range\n        pts /= np.linalg.norm(pts, axis=1)[:, np.newaxis]\n        \n        # Initial local optimization to find a local basin\n        res_local = minimize(get_grad, pts.flatten(), args=(60,), jac=True, method='L-BFGS-B')\n        \n        # Basin-hopping with low temperature and small step size for fine-grained exploration\n        res_bh = basinhopping(\n            get_grad, \n            res_local.x, \n            minimizer_kwargs={\"method\": \"L-BFGS-B\", \"jac\": True, \"args\": (120,)},\n            niter=25, \n            T=0.001, \n            stepsize=0.005\n        )\n        \n        # Final refinement using SLSQP to maximize the non-smooth min/max ratio directly\n        res_final = minimize(final_obj, res_bh.x, method='SLSQP', options={'maxiter': 150})\n        \n        val = -res_final.fun\n        if val > best_val:\n            best_val = val\n            best_pts = res_final.x.reshape((N, 3))\n            \n    return best_pts",
  "metrics": {
    "valid": true,
    "score": 0.9451689398756307,
    "min_max_ratio": 0.22688502772299582,
    "min_distance": 32.95051135653323,
    "max_distance": 69.17660433394784,
    "eval_time": 0.986954927444458,
    "error": null
  },
  "prompt": "Refine the best known solution trial_8_0 using Basin-hopping with a very low temperature and tiny step size. Focus on the analytical Jacobian. Variation 3",
  "response": "```python\nimport numpy as np\nfrom scipy.optimize import minimize, basinhopping\n\ndef min_max_dist_dim3_14():\n    \"\"\"\n    Places 14 points in 3D space to maximize the squared ratio (min pairwise distance / max pairwise distance)^2.\n    Refines the solution using Basin-hopping with a very low temperature and tiny step size,\n    incorporating an analytical Jacobian for precision.\n    \"\"\"\n    N = 14\n    \n    def get_grad(x, p):\n        \"\"\"\n        Calculates the soft min/max ratio and its analytical gradient.\n        Objective: Minimize - (soft_min_distance^2 / soft_max_distance^2).\n        \"\"\"\n        pts = x.reshape((N, 3))\n        # Vectorized pairwise differences and squared distances\n        diffs = pts[:, np.newaxis, :] - pts[np.newaxis, :, :]\n        d2_matrix = np.sum(diffs**2, axis=2)\n        \n        # Extract upper triangle for unique pairwise distances\n        iu = np.triu_indices(N, k=1)\n        d2 = d2_matrix[iu]\n        \n        min_d2 = np.min(d2)\n        max_d2 = np.max(d2)\n        \n        # Numerically stable LogSumExp for soft-min and soft-max\n        exp_min = np.exp(-p * (d2 - min_d2))\n        sum_exp_min = np.sum(exp_min)\n        s_min = - (1.0 / p) * np.log(sum_exp_min) + min_d2\n        \n        exp_max = np.exp(p * (d2 - max_d2))\n        sum_exp_max = np.sum(exp_max)\n        s_max = (1.0 / p) * np.log(sum_exp_max) + max_d2\n        \n        # Partial derivatives of soft_min and soft_max with respect to squared distances\n        ds_min_dd2 = exp_min / sum_exp_min\n        ds_max_dd2 = exp_max / sum_exp_max\n        \n        # Map derivatives back to N x N matrices\n        W_min = np.zeros((N, N))\n        W_min[iu] = ds_min_dd2\n        W_min = W_min + W_min.T\n        \n        W_max = np.zeros((N, N))\n        W_max[iu] = ds_max_dd2\n        W_max = W_max + W_max.T\n        \n        # Gradients with respect to coordinates\n        grad_s_min = np.sum(W_min[:, :, np.newaxis] * (2 * diffs), axis=1)\n        grad_s_max = np.sum(W_max[:, :, np.newaxis] * (2 * diffs), axis=1)\n        \n        # Objective F = -s_min / s_max\n        # dF/dx = - ( (1/s_max) * d(s_min)/dx - (s_min / s_max^2) * d(s_max)/dx )\n        grad_F = - (grad_s_min / s_max - (s_min / (s_max**2)) * grad_s_max)\n        \n        return -s_min / s_max, grad_F.flatten()\n\n    def final_obj(x):\n        \"\"\"Strict objective function for final refinement.\"\"\"\n        pts_ = x.reshape((N, 3))\n        d2_matrix = np.sum((pts_[:, np.newaxis, :] - pts_[np.newaxis, :, :])**2, axis=2)\n        d2 = d2_matrix[np.triu_indices(N, k=1)]\n        return -np.min(d2) / np.max(d2)\n\n    best_pts = None\n    best_val = -1.0\n    \n    # Initialization: One structured (capped hexagonal antiprism) and several random starts\n    pts_struct = []\n    pts_struct.append([0, 0, 1.0])\n    pts_struct.append([0, 0, -1.0])\n    for i in range(6):\n        theta = i * 2 * np.pi / 6\n        pts_struct.append([np.cos(theta), np.sin(theta), 0.5])\n        pts_struct.append([np.cos(theta + np.pi/6), np.sin(theta + np.pi/6), -0.5])\n    pts_struct = np.array(pts_struct)\n    \n    starts = [pts_struct] + [np.random.normal(0, 1, (N, 3)) for _ in range(5)]\n    \n    for pts in starts:\n        # Scale to unit sphere for a consistent initial range\n        pts /= np.linalg.norm(pts, axis=1)[:, np.newaxis]\n        \n        # Initial local optimization to find a local basin\n        res_local = minimize(get_grad, pts.flatten(), args=(60,), jac=True, method='L-BFGS-B')\n        \n        # Basin-hopping with low temperature and small step size for fine-grained exploration\n        res_bh = basinhopping(\n            get_grad, \n            res_local.x, \n            minimizer_kwargs={\"method\": \"L-BFGS-B\", \"jac\": True, \"args\": (120,)},\n            niter=25, \n            T=0.001, \n            stepsize=0.005\n        )\n        \n        # Final refinement using SLSQP to maximize the non-smooth min/max ratio directly\n        res_final = minimize(final_obj, res_bh.x, method='SLSQP', options={'maxiter': 150})\n        \n        val = -res_final.fun\n        if val > best_val:\n            best_val = val\n            best_pts = res_final.x.reshape((N, 3))\n            \n    return best_pts\n\n```",
  "reasoning": "",
  "timestamp": "2026-01-21T18:00:00.553693",
  "cost_data": null,
  "model_config": {
    "model": "gemini-3-flash-preview",
    "temperature": 0.7,
    "provider_debug": {
      "finish_reason": "STOP",
      "usage_metadata": {
        "prompt_token_count": 206,
        "candidates_token_count": 1447,
        "thoughts_token_count": 19753
      },
      "response_text_len": 4156
    }
  }
}