{
  "trial_id": "trial_10_4",
  "generation": 10,
  "parent_id": null,
  "code": "import numpy as np\nfrom scipy.optimize import minimize, NonlinearConstraint, Bounds, BFGS\n\ndef min_max_dist_dim3_14():\n    \"\"\"\n    Finds the coordinates of 14 points in 3D space that maximize the \n    squared ratio of minimum pairwise distance to maximum pairwise distance.\n    \n    Method:\n    1. Initialize with generalized spiral points on a sphere.\n    2. Pre-optimize using a soft repulsion potential (Riesz energy) with L-BFGS-B.\n    3. Refine using trust-constr algorithm to strictly maximize min_dist^2 \n       subject to max_dist^2 <= 1.\n    \"\"\"\n    N = 14\n    \n    # Generate indices for all unique pairs\n    pairs = np.array([(i, j) for i in range(N) for j in range(i + 1, N)])\n    idx_i = pairs[:, 0]\n    idx_j = pairs[:, 1]\n    n_pairs = len(pairs)\n    \n    # --- 1. Initialization ---\n    # Generalized Spiral Points on Sphere\n    indices = np.arange(0, N, dtype=float) + 0.5\n    phi = np.arccos(1 - 2*indices/N)\n    theta = np.pi * (1 + 5**0.5) * indices\n    \n    x = np.cos(theta) * np.sin(phi)\n    y = np.sin(theta) * np.sin(phi)\n    z = np.cos(phi)\n    points = np.column_stack((x, y, z))\n    \n    # --- 2. Pre-optimization (Soft Potential) ---\n    # Minimize sum(1/d^8) to get a good approximate spread\n    def pre_obj(flat_p):\n        p = flat_p.reshape((N, 3))\n        diff = p[idx_i] - p[idx_j]\n        d2 = np.sum(diff**2, axis=1)\n        d2 = np.maximum(d2, 1e-10) # Avoid division by zero\n        return np.sum(d2**(-4)) # 1/d^8\n\n    def pre_jac(flat_p):\n        p = flat_p.reshape((N, 3))\n        diff = p[idx_i] - p[idx_j]\n        d2 = np.sum(diff**2, axis=1)\n        d2 = np.maximum(d2, 1e-10)\n        \n        # Gradient of d^(-8) is -4 * d^(-10) * grad(d^2)\n        coeffs = -8.0 * (d2**(-5))\n        weighted_diff = diff * coeffs[:, None]\n        \n        grad = np.zeros((N, 3))\n        np.add.at(grad, idx_i, weighted_diff)\n        np.add.at(grad, idx_j, -weighted_diff)\n        return grad.flatten()\n\n    # Normalize to unit sphere for pre-optimization\n    points /= np.linalg.norm(points, axis=1, keepdims=True)\n    res_pre = minimize(pre_obj, points.flatten(), method='L-BFGS-B', jac=pre_jac, \n                       options={'maxiter': 500, 'ftol': 1e-6})\n    points = res_pre.x.reshape((N, 3))\n    \n    # --- 3. Refinement (Trust-Constr) ---\n    # Scale points so max dist is roughly 1\n    diff = points[idx_i] - points[idx_j]\n    max_d = np.max(np.linalg.norm(diff, axis=1))\n    points /= max_d\n    \n    # Optimization Variables: [x1, y1, z1, ..., x14, y14, z14, s]\n    # s is the squared minimum distance (slack variable)\n    \n    # Calculate initial s (slightly reduced to ensure feasibility)\n    diff = points[idx_i] - points[idx_j]\n    d2 = np.sum(diff**2, axis=1)\n    s_init = np.min(d2) * 0.99\n    \n    x0 = np.concatenate([points.flatten(), [s_init]])\n    \n    # Constraints:\n    # 1. d_ij^2 - s >= 0  (Min distance constraint)\n    # 2. d_ij^2 <= 1      (Max distance constraint, normalized)\n    \n    def cons_fun(x):\n        p = x[:-1].reshape((N, 3))\n        s = x[-1]\n        diff = p[idx_i] - p[idx_j]\n        current_d2 = np.sum(diff**2, axis=1)\n        # Return vector of all constraint values\n        return np.concatenate([current_d2 - s, current_d2])\n    \n    def cons_jac(x):\n        p = x[:-1].reshape((N, 3))\n        # s = x[-1]\n        diff = p[idx_i] - p[idx_j]\n        \n        jac = np.zeros((2 * n_pairs, 3 * N + 1))\n        \n        # Precompute derivatives: d(d^2)/dP = 2 * diff\n        derivs = 2 * diff # Shape (n_pairs, 3)\n        \n        # Fill Jacobian\n        # We perform a loop over pairs; for N=14, n_pairs=91, this is very fast.\n        for k in range(n_pairs):\n            i, j = idx_i[k], idx_j[k]\n            \n            # Row k: Constraint d_ij^2 - s\n            # d/dPi = 2(Pi-Pj), d/dPj = -2(Pi-Pj), d/ds = -1\n            jac[k, 3*i:3*i+3] = derivs[k]\n            jac[k, 3*j:3*j+3] = -derivs[k]\n            jac[k, -1] = -1.0\n            \n            # Row n_pairs + k: Constraint d_ij^2\n            # d/dPi = 2(Pi-Pj), d/dPj = -2(Pi-Pj), d/ds = 0\n            jac[n_pairs + k, 3*i:3*i+3] = derivs[k]\n            jac[n_pairs + k, 3*j:3*j+3] = -derivs[k]\n            \n        return jac\n    \n    # Constraint bounds\n    # First 91: [0, inf]\n    # Next 91: [-inf, 1]\n    lb_cons = np.concatenate([np.zeros(n_pairs), np.full(n_pairs, -np.inf)])\n    ub_cons = np.concatenate([np.full(n_pairs, np.inf), np.ones(n_pairs)])\n    \n    constraints = NonlinearConstraint(cons_fun, lb_cons, ub_cons, jac=cons_jac)\n    \n    # Variable bounds: s must be in [0, 1]\n    lb_vars = np.full(3*N + 1, -np.inf)\n    ub_vars = np.full(3*N + 1, np.inf)\n    lb_vars[-1] = 0.0\n    ub_vars[-1] = 1.0\n    bounds = Bounds(lb_vars, ub_vars)\n    \n    # Objective: Minimize -s (Maximize min squared distance)\n    def obj(x):\n        return -x[-1]\n    \n    def obj_jac(x):\n        g = np.zeros_like(x)\n        g[-1] = -1.0\n        return g\n    \n    # Solve\n    res = minimize(obj, x0, method='trust-constr', jac=obj_jac, hess=BFGS(),\n                   constraints=[constraints], bounds=bounds,\n                   options={'gtol': 1e-15, 'xtol': 1e-15, 'maxiter': 3000})\n    \n    final_points = res.x[:-1].reshape((N, 3))\n    \n    return final_points",
  "metrics": {
    "valid": true,
    "score": 0.9387382476696813,
    "min_max_ratio": 0.22534135894816615,
    "min_distance": 0.4747013350652458,
    "max_distance": 0.9999999968149669,
    "eval_time": 0.451887845993042,
    "error": null
  },
  "prompt": "Refine the solution from trial_8_0 using scipy.optimize.minimize with method='trust-constr'.\nThis method is often more robust than SLSQP for high-precision constraints.\nUse the slack variable formulation and provide the analytical Jacobian and Hessian (if possible).\nSet xtol and gtol to 1e-15.",
  "response": "Here is the refined solution using `scipy.optimize.minimize` with `method='trust-constr'`.\n\nIt employs a two-stage approach:\n1.  **Initialization & Pre-optimization**: Starts with generalized spiral points on a sphere and performs a quick energy minimization (using a soft potential) to distribute points evenly. This provides a high-quality initial guess.\n2.  **Refinement**: Uses `trust-constr` with a slack variable formulation. We introduce a variable $s$ representing the squared minimum distance and maximize it subject to constraints on all pairwise distances ($d_{ij}^2 \\ge s$ and $d_{ij}^2 \\le 1$). Analytical Jacobians are provided for performance and precision, and `BFGS` is used for Hessian approximation.\n\n```python\nimport numpy as np\nfrom scipy.optimize import minimize, NonlinearConstraint, Bounds, BFGS\n\ndef min_max_dist_dim3_14():\n    \"\"\"\n    Finds the coordinates of 14 points in 3D space that maximize the \n    squared ratio of minimum pairwise distance to maximum pairwise distance.\n    \n    Method:\n    1. Initialize with generalized spiral points on a sphere.\n    2. Pre-optimize using a soft repulsion potential (Riesz energy) with L-BFGS-B.\n    3. Refine using trust-constr algorithm to strictly maximize min_dist^2 \n       subject to max_dist^2 <= 1.\n    \"\"\"\n    N = 14\n    \n    # Generate indices for all unique pairs\n    pairs = np.array([(i, j) for i in range(N) for j in range(i + 1, N)])\n    idx_i = pairs[:, 0]\n    idx_j = pairs[:, 1]\n    n_pairs = len(pairs)\n    \n    # --- 1. Initialization ---\n    # Generalized Spiral Points on Sphere\n    indices = np.arange(0, N, dtype=float) + 0.5\n    phi = np.arccos(1 - 2*indices/N)\n    theta = np.pi * (1 + 5**0.5) * indices\n    \n    x = np.cos(theta) * np.sin(phi)\n    y = np.sin(theta) * np.sin(phi)\n    z = np.cos(phi)\n    points = np.column_stack((x, y, z))\n    \n    # --- 2. Pre-optimization (Soft Potential) ---\n    # Minimize sum(1/d^8) to get a good approximate spread\n    def pre_obj(flat_p):\n        p = flat_p.reshape((N, 3))\n        diff = p[idx_i] - p[idx_j]\n        d2 = np.sum(diff**2, axis=1)\n        d2 = np.maximum(d2, 1e-10) # Avoid division by zero\n        return np.sum(d2**(-4)) # 1/d^8\n\n    def pre_jac(flat_p):\n        p = flat_p.reshape((N, 3))\n        diff = p[idx_i] - p[idx_j]\n        d2 = np.sum(diff**2, axis=1)\n        d2 = np.maximum(d2, 1e-10)\n        \n        # Gradient of d^(-8) is -4 * d^(-10) * grad(d^2)\n        coeffs = -8.0 * (d2**(-5))\n        weighted_diff = diff * coeffs[:, None]\n        \n        grad = np.zeros((N, 3))\n        np.add.at(grad, idx_i, weighted_diff)\n        np.add.at(grad, idx_j, -weighted_diff)\n        return grad.flatten()\n\n    # Normalize to unit sphere for pre-optimization\n    points /= np.linalg.norm(points, axis=1, keepdims=True)\n    res_pre = minimize(pre_obj, points.flatten(), method='L-BFGS-B', jac=pre_jac, \n                       options={'maxiter': 500, 'ftol': 1e-6})\n    points = res_pre.x.reshape((N, 3))\n    \n    # --- 3. Refinement (Trust-Constr) ---\n    # Scale points so max dist is roughly 1\n    diff = points[idx_i] - points[idx_j]\n    max_d = np.max(np.linalg.norm(diff, axis=1))\n    points /= max_d\n    \n    # Optimization Variables: [x1, y1, z1, ..., x14, y14, z14, s]\n    # s is the squared minimum distance (slack variable)\n    \n    # Calculate initial s (slightly reduced to ensure feasibility)\n    diff = points[idx_i] - points[idx_j]\n    d2 = np.sum(diff**2, axis=1)\n    s_init = np.min(d2) * 0.99\n    \n    x0 = np.concatenate([points.flatten(), [s_init]])\n    \n    # Constraints:\n    # 1. d_ij^2 - s >= 0  (Min distance constraint)\n    # 2. d_ij^2 <= 1      (Max distance constraint, normalized)\n    \n    def cons_fun(x):\n        p = x[:-1].reshape((N, 3))\n        s = x[-1]\n        diff = p[idx_i] - p[idx_j]\n        current_d2 = np.sum(diff**2, axis=1)\n        # Return vector of all constraint values\n        return np.concatenate([current_d2 - s, current_d2])\n    \n    def cons_jac(x):\n        p = x[:-1].reshape((N, 3))\n        # s = x[-1]\n        diff = p[idx_i] - p[idx_j]\n        \n        jac = np.zeros((2 * n_pairs, 3 * N + 1))\n        \n        # Precompute derivatives: d(d^2)/dP = 2 * diff\n        derivs = 2 * diff # Shape (n_pairs, 3)\n        \n        # Fill Jacobian\n        # We perform a loop over pairs; for N=14, n_pairs=91, this is very fast.\n        for k in range(n_pairs):\n            i, j = idx_i[k], idx_j[k]\n            \n            # Row k: Constraint d_ij^2 - s\n            # d/dPi = 2(Pi-Pj), d/dPj = -2(Pi-Pj), d/ds = -1\n            jac[k, 3*i:3*i+3] = derivs[k]\n            jac[k, 3*j:3*j+3] = -derivs[k]\n            jac[k, -1] = -1.0\n            \n            # Row n_pairs + k: Constraint d_ij^2\n            # d/dPi = 2(Pi-Pj), d/dPj = -2(Pi-Pj), d/ds = 0\n            jac[n_pairs + k, 3*i:3*i+3] = derivs[k]\n            jac[n_pairs + k, 3*j:3*j+3] = -derivs[k]\n            \n        return jac\n    \n    # Constraint bounds\n    # First 91: [0, inf]\n    # Next 91: [-inf, 1]\n    lb_cons = np.concatenate([np.zeros(n_pairs), np.full(n_pairs, -np.inf)])\n    ub_cons = np.concatenate([np.full(n_pairs, np.inf), np.ones(n_pairs)])\n    \n    constraints = NonlinearConstraint(cons_fun, lb_cons, ub_cons, jac=cons_jac)\n    \n    # Variable bounds: s must be in [0, 1]\n    lb_vars = np.full(3*N + 1, -np.inf)\n    ub_vars = np.full(3*N + 1, np.inf)\n    lb_vars[-1] = 0.0\n    ub_vars[-1] = 1.0\n    bounds = Bounds(lb_vars, ub_vars)\n    \n    # Objective: Minimize -s (Maximize min squared distance)\n    def obj(x):\n        return -x[-1]\n    \n    def obj_jac(x):\n        g = np.zeros_like(x)\n        g[-1] = -1.0\n        return g\n    \n    # Solve\n    res = minimize(obj, x0, method='trust-constr', jac=obj_jac, hess=BFGS(),\n                   constraints=[constraints], bounds=bounds,\n                   options={'gtol': 1e-15, 'xtol': 1e-15, 'maxiter': 3000})\n    \n    final_points = res.x[:-1].reshape((N, 3))\n    \n    return final_points\n```",
  "reasoning": "Here is the refined solution using `scipy.optimize.minimize` with `method='trust-constr'`.\n\nIt employs a two-stage approach:\n1.  **Initialization & Pre-optimization**: Starts with generalized spiral points on a sphere and performs a quick energy minimization (using a soft potential) to distribute points evenly. This provides a high-quality initial guess.\n2.  **Refinement**: Uses `trust-constr` with a slack variable formulation. We introduce a variable $s$ representing the squared minimum distance and maximize it subject to constraints on all pairwise distances ($d_{ij}^2 \\ge s$ and $d_{ij}^2 \\le 1$). Analytical Jacobians are provided for performance and precision, and `BFGS` is used for Hessian approximation.",
  "timestamp": "2026-01-21T18:03:38.955425",
  "cost_data": null,
  "model_config": {
    "model": "gemini-3-pro-preview",
    "temperature": 0.7,
    "provider_debug": {
      "finish_reason": "STOP",
      "usage_metadata": {
        "prompt_token_count": 243,
        "candidates_token_count": 2134,
        "thoughts_token_count": 11932
      },
      "response_text_len": 5932
    }
  }
}