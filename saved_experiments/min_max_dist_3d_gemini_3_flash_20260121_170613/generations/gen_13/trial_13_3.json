{
  "trial_id": "trial_13_3",
  "generation": 13,
  "parent_id": "trial_8_0",
  "code": "import numpy as np\nfrom scipy.optimize import minimize\nimport time\n\ndef get_score_sq(pts):\n    \"\"\"\n    Calculates the squared ratio (min pairwise distance / max pairwise distance)^2.\n    pts: numpy array of shape (N, 3)\n    \"\"\"\n    # Vectorized distance squared calculation\n    dist_sq = np.sum((pts[:, np.newaxis, :] - pts[np.newaxis, :, :])**2, axis=-1)\n    n = pts.shape[0]\n    \n    # Get indices for the upper triangle to avoid diagonal and redundant pairs\n    idx = np.triu_indices(n, k=1)\n    dists_sq = dist_sq[idx]\n    \n    d_min_sq = np.min(dists_sq)\n    d_max_sq = np.max(dists_sq)\n    \n    return d_min_sq / d_max_sq\n\ndef min_max_dist_dim3_14():\n    \"\"\"\n    Place 14 points in 3D space to maximize the squared ratio (min distance / max distance)^2.\n    Uses a combination of SLSQP optimization and coordinate descent refinement.\n    \"\"\"\n    start_time = time.time()\n    n_pts = 14\n    dim = 3\n\n    # Objective function for SLSQP: maximize min distance squared\n    def obj(x):\n        pts = x.reshape((n_pts, dim))\n        dist_sq = np.sum((pts[:, np.newaxis, :] - pts[np.newaxis, :, :])**2, axis=-1)\n        dists = dist_sq[np.triu_indices(n_pts, k=1)]\n        return -np.min(dists)\n\n    # Constraints for SLSQP: all pairwise distances must be <= 1 (sets max distance <= 1)\n    def constr(x):\n        pts = x.reshape((n_pts, dim))\n        dist_sq = np.sum((pts[:, np.newaxis, :] - pts[None, :, :])**2, axis=-1)\n        dists = dist_sq[np.triu_indices(n_pts, k=1)]\n        return 1.0 - dists\n\n    best_pts = np.random.uniform(-1, 1, (n_pts, dim))\n    best_score = get_score_sq(best_pts)\n\n    # Initial candidate configurations\n    starts = []\n    \n    # 1. Rhombic dodecahedron-like (Cube + Face centers)\n    a = 1.5\n    cube = np.array([[i, j, k] for i in [-1, 1] for j in [-1, 1] for k in [-1, 1]])\n    faces = np.array([[a, 0, 0], [-a, 0, 0], [0, a, 0], [0, -a, 0], [0, 0, a], [0, 0, -a]])\n    rd_start = np.vstack([cube, faces]).flatten()\n    starts.append(rd_start)\n    \n    # 2. Points on a sphere (Fibonacci lattice / Tammes-like)\n    phi = np.pi * (3. - np.sqrt(5.))\n    y = 1 - (np.arange(n_pts) / float(n_pts - 1)) * 2\n    radius = np.sqrt(1 - y * y)\n    theta = phi * np.arange(n_pts)\n    sphere_pts = np.stack([np.cos(theta) * radius, y, np.sin(theta) * radius], axis=1).flatten()\n    starts.append(sphere_pts)\n    \n    # 3. Random starts\n    for _ in range(3):\n        starts.append(np.random.uniform(-1, 1, (n_pts, dim)).flatten())\n\n    # Initial high-level optimization stage (first 10 seconds)\n    for x0 in starts:\n        if time.time() - start_time > 10:\n            break\n        res = minimize(obj, x0, method='SLSQP', \n                       constraints={'type': 'ineq', 'fun': constr}, \n                       options={'maxiter': 250, 'ftol': 1e-12})\n        pts = res.x.reshape((n_pts, dim))\n        score = get_score_sq(pts)\n        if score > best_score:\n            best_score = score\n            best_pts = pts.copy()\n\n    # Refinement stage: Coordinate Descent and Pattern Search (until 58 seconds)\n    curr_pts = best_pts.copy()\n    curr_score = best_score\n    \n    while time.time() - start_time < 58:\n        # Coordinate Descent: perturb one coordinate at a time\n        for i in range(n_pts):\n            if time.time() - start_time > 58:\n                break\n            # Randomize coordinate order for better exploration\n            coord_indices = [0, 1, 2]\n            np.random.shuffle(coord_indices)\n            for j in coord_indices:\n                old_val = curr_pts[i, j]\n                # Small perturbations as requested (1e-9 to 1e-12, expanded slightly for robustness)\n                scale = 10**np.random.uniform(-12, -7)\n                \n                # Try both directions\n                for direction in [-1, 1]:\n                    curr_pts[i, j] = old_val + direction * scale\n                    new_score = get_score_sq(curr_pts)\n                    if new_score > curr_score:\n                        curr_score = new_score\n                        break # Keep the improvement and move to next coordinate\n                    else:\n                        curr_pts[i, j] = old_val\n        \n        # Pattern Search: small random jump for all points simultaneously\n        scale = 10**np.random.uniform(-12, -9)\n        old_pts = curr_pts.copy()\n        curr_pts += np.random.normal(0, scale, size=(n_pts, dim))\n        new_score = get_score_sq(curr_pts)\n        if new_score > curr_score:\n            curr_score = new_score\n        else:\n            curr_pts = old_pts\n\n    return curr_pts",
  "metrics": {
    "valid": true,
    "score": 0.8920522595602673,
    "min_max_ratio": 0.21413452463569538,
    "min_distance": 0.4625092237449782,
    "max_distance": 0.9994867735826087,
    "eval_time": 58.34501600265503,
    "error": null
  },
  "prompt": "Take the best result from trial_8_0 and apply a 'Coordinate Descent' or 'Pattern Search' refinement.\nSince we are at the limit of gradient-based optimizers, try small random perturbations (1e-9 to 1e-12) and only keep moves that improve the score.\nRun this for 55 seconds to squeeze out every bit of precision.",
  "response": "```python\nimport numpy as np\nfrom scipy.optimize import minimize\nimport time\n\ndef get_score_sq(pts):\n    \"\"\"\n    Calculates the squared ratio (min pairwise distance / max pairwise distance)^2.\n    pts: numpy array of shape (N, 3)\n    \"\"\"\n    # Vectorized distance squared calculation\n    dist_sq = np.sum((pts[:, np.newaxis, :] - pts[np.newaxis, :, :])**2, axis=-1)\n    n = pts.shape[0]\n    \n    # Get indices for the upper triangle to avoid diagonal and redundant pairs\n    idx = np.triu_indices(n, k=1)\n    dists_sq = dist_sq[idx]\n    \n    d_min_sq = np.min(dists_sq)\n    d_max_sq = np.max(dists_sq)\n    \n    return d_min_sq / d_max_sq\n\ndef min_max_dist_dim3_14():\n    \"\"\"\n    Place 14 points in 3D space to maximize the squared ratio (min distance / max distance)^2.\n    Uses a combination of SLSQP optimization and coordinate descent refinement.\n    \"\"\"\n    start_time = time.time()\n    n_pts = 14\n    dim = 3\n\n    # Objective function for SLSQP: maximize min distance squared\n    def obj(x):\n        pts = x.reshape((n_pts, dim))\n        dist_sq = np.sum((pts[:, np.newaxis, :] - pts[np.newaxis, :, :])**2, axis=-1)\n        dists = dist_sq[np.triu_indices(n_pts, k=1)]\n        return -np.min(dists)\n\n    # Constraints for SLSQP: all pairwise distances must be <= 1 (sets max distance <= 1)\n    def constr(x):\n        pts = x.reshape((n_pts, dim))\n        dist_sq = np.sum((pts[:, np.newaxis, :] - pts[None, :, :])**2, axis=-1)\n        dists = dist_sq[np.triu_indices(n_pts, k=1)]\n        return 1.0 - dists\n\n    best_pts = np.random.uniform(-1, 1, (n_pts, dim))\n    best_score = get_score_sq(best_pts)\n\n    # Initial candidate configurations\n    starts = []\n    \n    # 1. Rhombic dodecahedron-like (Cube + Face centers)\n    a = 1.5\n    cube = np.array([[i, j, k] for i in [-1, 1] for j in [-1, 1] for k in [-1, 1]])\n    faces = np.array([[a, 0, 0], [-a, 0, 0], [0, a, 0], [0, -a, 0], [0, 0, a], [0, 0, -a]])\n    rd_start = np.vstack([cube, faces]).flatten()\n    starts.append(rd_start)\n    \n    # 2. Points on a sphere (Fibonacci lattice / Tammes-like)\n    phi = np.pi * (3. - np.sqrt(5.))\n    y = 1 - (np.arange(n_pts) / float(n_pts - 1)) * 2\n    radius = np.sqrt(1 - y * y)\n    theta = phi * np.arange(n_pts)\n    sphere_pts = np.stack([np.cos(theta) * radius, y, np.sin(theta) * radius], axis=1).flatten()\n    starts.append(sphere_pts)\n    \n    # 3. Random starts\n    for _ in range(3):\n        starts.append(np.random.uniform(-1, 1, (n_pts, dim)).flatten())\n\n    # Initial high-level optimization stage (first 10 seconds)\n    for x0 in starts:\n        if time.time() - start_time > 10:\n            break\n        res = minimize(obj, x0, method='SLSQP', \n                       constraints={'type': 'ineq', 'fun': constr}, \n                       options={'maxiter': 250, 'ftol': 1e-12})\n        pts = res.x.reshape((n_pts, dim))\n        score = get_score_sq(pts)\n        if score > best_score:\n            best_score = score\n            best_pts = pts.copy()\n\n    # Refinement stage: Coordinate Descent and Pattern Search (until 58 seconds)\n    curr_pts = best_pts.copy()\n    curr_score = best_score\n    \n    while time.time() - start_time < 58:\n        # Coordinate Descent: perturb one coordinate at a time\n        for i in range(n_pts):\n            if time.time() - start_time > 58:\n                break\n            # Randomize coordinate order for better exploration\n            coord_indices = [0, 1, 2]\n            np.random.shuffle(coord_indices)\n            for j in coord_indices:\n                old_val = curr_pts[i, j]\n                # Small perturbations as requested (1e-9 to 1e-12, expanded slightly for robustness)\n                scale = 10**np.random.uniform(-12, -7)\n                \n                # Try both directions\n                for direction in [-1, 1]:\n                    curr_pts[i, j] = old_val + direction * scale\n                    new_score = get_score_sq(curr_pts)\n                    if new_score > curr_score:\n                        curr_score = new_score\n                        break # Keep the improvement and move to next coordinate\n                    else:\n                        curr_pts[i, j] = old_val\n        \n        # Pattern Search: small random jump for all points simultaneously\n        scale = 10**np.random.uniform(-12, -9)\n        old_pts = curr_pts.copy()\n        curr_pts += np.random.normal(0, scale, size=(n_pts, dim))\n        new_score = get_score_sq(curr_pts)\n        if new_score > curr_score:\n            curr_score = new_score\n        else:\n            curr_pts = old_pts\n\n    return curr_pts\n```",
  "reasoning": "",
  "timestamp": "2026-01-21T18:24:00.828551",
  "cost_data": null,
  "model_config": {
    "model": "gemini-3-flash-preview",
    "temperature": 0.7,
    "provider_debug": {
      "finish_reason": "STOP",
      "usage_metadata": {
        "prompt_token_count": 252,
        "candidates_token_count": 1507,
        "thoughts_token_count": 23190
      },
      "response_text_len": 4574
    }
  }
}