{
  "trial_id": "trial_13_4",
  "generation": 13,
  "parent_id": null,
  "code": "import numpy as np\nfrom scipy.optimize import minimize\n\ndef min_max_dist_dim3_14():\n    \"\"\"\n    Places 14 points in 3D space to maximize the squared ratio (min distance / max distance)^2.\n    Uses a penalty-based optimization with a sequence of increasing stiffness k.\n    \"\"\"\n    N = 14\n    dim = 3\n    \n    def obj_grad(coords, k):\n        # Reshape flat coordinates into (N, 3)\n        pts = coords.reshape((N, dim))\n        \n        # Calculate pairwise differences and squared distances\n        # diff[i, j] = pts[i] - pts[j]\n        diff = pts[:, np.newaxis, :] - pts[np.newaxis, :, :]\n        dist_sq = np.sum(diff**2, axis=-1)\n        \n        # Mask for the upper triangle (unique pairs i < j)\n        mask = np.triu(np.ones((N, N), dtype=bool), k=1)\n        \n        # Penalty terms:\n        # sum(exp(-k * dist_ij^2)) pushes the minimum distance to be as large as possible.\n        # sum(exp(k * (dist_ij^2 - 1))) pushes the maximum distance to be at most 1.\n        neg_exp_arg = -k * dist_sq\n        pos_exp_arg = k * (dist_sq - 1.0)\n        \n        # Use clipping to prevent numerical overflow in the exponential function.\n        # float64 can handle up to exp(709).\n        exp_neg = np.exp(np.clip(neg_exp_arg, -500, 500))\n        exp_pos = np.exp(np.clip(pos_exp_arg, -500, 500))\n        \n        # Total objective (sum of upper triangular elements)\n        obj = np.sum(exp_neg[mask]) + np.sum(exp_pos[mask])\n        \n        # Gradient calculation:\n        # d/dx_i Obj = sum_{j != i} [ 2 * k * (exp(k(d_ij^2 - 1)) - exp(-k * d_ij^2)) * (x_i - x_j) ]\n        grad_factor = 2 * k * (exp_pos - exp_neg)\n        grad = np.sum(grad_factor[:, :, np.newaxis] * diff, axis=1)\n        \n        return obj, grad.flatten()\n\n    best_pts = None\n    best_score = -1\n    \n    # 1. Initialization using a Fibonacci sphere (radius 0.5, diameter 1.0)\n    # This provides a well-distributed starting point on a spherical surface.\n    phi_const = np.pi * (3. - np.sqrt(5.))\n    pts_fib = []\n    for i in range(N):\n        y = (1 - (i / float(N - 1)) * 2) * 0.5\n        radius = np.sqrt(max(0, 0.25 - y * y))\n        theta = phi_const * i\n        x = np.cos(theta) * radius\n        z = np.sin(theta) * radius\n        pts_fib.append([x, y, z])\n    pts_fib = np.array(pts_fib)\n    \n    # Run optimization from multiple starting configurations to avoid local minima\n    seeds = [None, 42, 123]\n    for seed in seeds:\n        if seed is None:\n            curr_pts = pts_fib.flatten()\n        else:\n            np.random.seed(seed)\n            # Random starting points in a small volume\n            curr_pts = (np.random.rand(N * dim) - 0.5)\n        \n        # Gradually increase k (simulated annealing style) to refine the configuration.\n        # This sharpens the objective towards maximizing min distance and bounding max distance.\n        for k in [15, 40, 100, 250]:\n            res = minimize(obj_grad, curr_pts, args=(k,), jac=True, method='L-BFGS-B', \n                           options={'maxiter': 2000, 'ftol': 1e-11})\n            curr_pts = res.x\n        \n        final_pts = curr_pts.reshape((N, dim))\n        \n        # Calculate the objective squared ratio: (min_dist / max_dist)^2\n        diff = final_pts[:, np.newaxis, :] - final_pts[np.newaxis, :, :]\n        dist_sq = np.sum(diff**2, axis=-1)\n        mask = np.triu(np.ones((N, N), dtype=bool), k=1)\n        d_sq_triu = dist_sq[mask]\n        \n        score = np.min(d_sq_triu) / np.max(d_sq_triu)\n        \n        if score > best_score:\n            best_score = score\n            best_pts = final_pts\n            \n    return best_pts",
  "metrics": {
    "valid": true,
    "score": 0.9593145410402554,
    "min_max_ratio": 0.23028063773195,
    "min_distance": 0.43159955974302033,
    "max_distance": 0.8993987533335838,
    "eval_time": 0.251025915145874,
    "error": null
  },
  "prompt": "Implement a 'penalty-based' optimization for 14 points.\nObjective: minimize sum(exp(-k * dist_ij^2)) + sum(exp(k * (dist_ij^2 - 1)))\nGradually increase k (simulated annealing style) to force the points into a configuration where min distance is maximized and max distance is 1.\nStart with a Fibonacci sphere and use L-BFGS-B.",
  "response": "```python\nimport numpy as np\nfrom scipy.optimize import minimize\n\ndef min_max_dist_dim3_14():\n    \"\"\"\n    Places 14 points in 3D space to maximize the squared ratio (min distance / max distance)^2.\n    Uses a penalty-based optimization with a sequence of increasing stiffness k.\n    \"\"\"\n    N = 14\n    dim = 3\n    \n    def obj_grad(coords, k):\n        # Reshape flat coordinates into (N, 3)\n        pts = coords.reshape((N, dim))\n        \n        # Calculate pairwise differences and squared distances\n        # diff[i, j] = pts[i] - pts[j]\n        diff = pts[:, np.newaxis, :] - pts[np.newaxis, :, :]\n        dist_sq = np.sum(diff**2, axis=-1)\n        \n        # Mask for the upper triangle (unique pairs i < j)\n        mask = np.triu(np.ones((N, N), dtype=bool), k=1)\n        \n        # Penalty terms:\n        # sum(exp(-k * dist_ij^2)) pushes the minimum distance to be as large as possible.\n        # sum(exp(k * (dist_ij^2 - 1))) pushes the maximum distance to be at most 1.\n        neg_exp_arg = -k * dist_sq\n        pos_exp_arg = k * (dist_sq - 1.0)\n        \n        # Use clipping to prevent numerical overflow in the exponential function.\n        # float64 can handle up to exp(709).\n        exp_neg = np.exp(np.clip(neg_exp_arg, -500, 500))\n        exp_pos = np.exp(np.clip(pos_exp_arg, -500, 500))\n        \n        # Total objective (sum of upper triangular elements)\n        obj = np.sum(exp_neg[mask]) + np.sum(exp_pos[mask])\n        \n        # Gradient calculation:\n        # d/dx_i Obj = sum_{j != i} [ 2 * k * (exp(k(d_ij^2 - 1)) - exp(-k * d_ij^2)) * (x_i - x_j) ]\n        grad_factor = 2 * k * (exp_pos - exp_neg)\n        grad = np.sum(grad_factor[:, :, np.newaxis] * diff, axis=1)\n        \n        return obj, grad.flatten()\n\n    best_pts = None\n    best_score = -1\n    \n    # 1. Initialization using a Fibonacci sphere (radius 0.5, diameter 1.0)\n    # This provides a well-distributed starting point on a spherical surface.\n    phi_const = np.pi * (3. - np.sqrt(5.))\n    pts_fib = []\n    for i in range(N):\n        y = (1 - (i / float(N - 1)) * 2) * 0.5\n        radius = np.sqrt(max(0, 0.25 - y * y))\n        theta = phi_const * i\n        x = np.cos(theta) * radius\n        z = np.sin(theta) * radius\n        pts_fib.append([x, y, z])\n    pts_fib = np.array(pts_fib)\n    \n    # Run optimization from multiple starting configurations to avoid local minima\n    seeds = [None, 42, 123]\n    for seed in seeds:\n        if seed is None:\n            curr_pts = pts_fib.flatten()\n        else:\n            np.random.seed(seed)\n            # Random starting points in a small volume\n            curr_pts = (np.random.rand(N * dim) - 0.5)\n        \n        # Gradually increase k (simulated annealing style) to refine the configuration.\n        # This sharpens the objective towards maximizing min distance and bounding max distance.\n        for k in [15, 40, 100, 250]:\n            res = minimize(obj_grad, curr_pts, args=(k,), jac=True, method='L-BFGS-B', \n                           options={'maxiter': 2000, 'ftol': 1e-11})\n            curr_pts = res.x\n        \n        final_pts = curr_pts.reshape((N, dim))\n        \n        # Calculate the objective squared ratio: (min_dist / max_dist)^2\n        diff = final_pts[:, np.newaxis, :] - final_pts[np.newaxis, :, :]\n        dist_sq = np.sum(diff**2, axis=-1)\n        mask = np.triu(np.ones((N, N), dtype=bool), k=1)\n        d_sq_triu = dist_sq[mask]\n        \n        score = np.min(d_sq_triu) / np.max(d_sq_triu)\n        \n        if score > best_score:\n            best_score = score\n            best_pts = final_pts\n            \n    return best_pts\n\n```",
  "reasoning": "",
  "timestamp": "2026-01-21T18:22:23.947546",
  "cost_data": null,
  "model_config": {
    "model": "gemini-3-flash-preview",
    "temperature": 0.7,
    "provider_debug": {
      "finish_reason": "STOP",
      "usage_metadata": {
        "prompt_token_count": 264,
        "candidates_token_count": 1211,
        "thoughts_token_count": 17490
      },
      "response_text_len": 3615
    }
  }
}