{
  "trial_id": "trial_7_2",
  "generation": 7,
  "parent_id": "trial_6_0",
  "code": "import numpy as np\nfrom scipy.optimize import minimize\nfrom scipy.spatial.distance import pdist\n\ndef min_max_dist_dim3_14():\n    \"\"\"\n    Places 14 points in 3D space to maximize the squared ratio (min distance / max distance)^2.\n    The approach uses SLSQP with analytical Jacobians followed by a Nelder-Mead refinement.\n    \"\"\"\n    n = 14\n    \n    def get_score(pts_flat):\n        pts = pts_flat.reshape((-1, 3))\n        dists_sq = pdist(pts, 'sqeuclidean')\n        if len(dists_sq) == 0:\n            return 0\n        max_d = np.max(dists_sq)\n        if max_d == 0:\n            return 0\n        return np.min(dists_sq) / max_d\n\n    # Objective function for SLSQP: Maximize t (the minimum distance squared)\n    def obj(x):\n        return -x[-1]\n\n    def obj_grad(x):\n        g = np.zeros_like(x)\n        g[-1] = -1\n        return g\n\n    # Constraints for SLSQP\n    def cons_min(x):\n        pts = x[:-1].reshape((n, 3))\n        t = x[-1]\n        dists_sq = pdist(pts, 'sqeuclidean')\n        return dists_sq - t\n\n    def cons_min_jac(x):\n        pts = x[:-1].reshape((n, 3))\n        # Jacobian for n*(n-1)//2 distance constraints\n        jac = np.zeros((n * (n - 1) // 2, n * 3 + 1))\n        idx = 0\n        for i in range(n):\n            for j in range(i + 1, n):\n                diff2 = 2 * (pts[i] - pts[j])\n                jac[idx, i * 3 : i * 3 + 3] = diff2\n                jac[idx, j * 3 : j * 3 + 3] = -diff2\n                jac[idx, -1] = -1\n                idx += 1\n        return jac\n\n    def cons_max(x):\n        pts = x[:-1].reshape((n, 3))\n        dists_sq = pdist(pts, 'sqeuclidean')\n        # Maximize the ratio by fixing the maximum distance squared to 1.0\n        return 1.0 - dists_sq\n\n    def cons_max_jac(x):\n        pts = x[:-1].reshape((n, 3))\n        jac = np.zeros((n * (n - 1) // 2, n * 3 + 1))\n        idx = 0\n        for i in range(n):\n            for j in range(i + 1, n):\n                diff2 = 2 * (pts[i] - pts[j])\n                jac[idx, i * 3 : i * 3 + 3] = -diff2\n                jac[idx, j * 3 : j * 3 + 3] = diff2\n                idx += 1\n        return jac\n\n    # Generate various starting points to avoid local optima\n    starts = []\n    \n    # 1. Cube + Octahedron configuration\n    c = 0.5 / np.sqrt(3)\n    cube = np.array([[i, j, k] for i in [-c, c] for j in [-c, c] for k in [-c, c]])\n    s3 = 0.5\n    octa = np.array([[s3, 0, 0], [-s3, 0, 0], [0, s3, 0], [0, -s3, 0], [0, 0, s3], [0, 0, -s3]])\n    starts.append(np.vstack([cube, octa]))\n    \n    # 2. Golden Spiral distribution on a sphere\n    phi = np.pi * (3.0 - np.sqrt(5.0))\n    pts_spiral = []\n    for i in range(n):\n        y = 1 - (i / float(n - 1)) * 2\n        radius = np.sqrt(max(0, 1 - y * y))\n        theta = phi * i\n        pts_spiral.append([0.5 * np.cos(theta) * radius, 0.5 * y, 0.5 * np.sin(theta) * radius])\n    starts.append(np.array(pts_spiral))\n    \n    # 3. Random starts\n    np.random.seed(42)\n    for _ in range(4):\n        starts.append(np.random.rand(n, 3) - 0.5)\n\n    best_pts = starts[0]\n    best_val = get_score(best_pts)\n\n    # Optimization Loop\n    for start_pts in starts:\n        # Initial guess: coordinates + t (minimum distance squared)\n        x0 = np.zeros(n * 3 + 1)\n        x0[:-1] = start_pts.flatten()\n        x0[-1] = 0.01\n        \n        # Run SLSQP with analytical Jacobians\n        res = minimize(obj, x0, jac=obj_grad, method='SLSQP',\n                       constraints=[{'type': 'ineq', 'fun': cons_min, 'jac': cons_min_jac},\n                                    {'type': 'ineq', 'fun': cons_max, 'jac': cons_max_jac}],\n                       options={'maxiter': 200, 'ftol': 1e-12})\n        \n        pts = res.x[:-1].reshape((n, 3))\n        val = get_score(pts)\n        if val > best_val:\n            best_val = val\n            best_pts = pts\n    \n    # Final Refinement with Nelder-Mead using extremely tight tolerances\n    res_nm = minimize(lambda x: -get_score(x), best_pts.flatten(), method='Nelder-Mead',\n                      options={'fatol': 1e-15, 'xatol': 1e-15, 'maxiter': 1500})\n    \n    final_pts = res_nm.x.reshape((n, 3))\n    return final_pts",
  "metrics": {
    "valid": true,
    "score": 0.9974937358553562,
    "min_max_ratio": 0.23944544130156967,
    "min_distance": 0.4893316271216993,
    "max_distance": 1.0000000000000002,
    "eval_time": 0.3994729518890381,
    "error": null
  },
  "prompt": "Improve upon trial trial_6_0. \n        Use a hybrid optimization approach:\n        1. Start with the coordinates from trial_6_0.\n        2. Run SLSQP with analytical Jacobians to reach a local optimum.\n        3. Use the resulting points as a starting point for a Nelder-Mead search with \n           extremely tight tolerances (fatol=1e-15, xatol=1e-15) to see if the \n           non-gradient-based method can find a better point on the sharp peak.",
  "response": "```python\nimport numpy as np\nfrom scipy.optimize import minimize\nfrom scipy.spatial.distance import pdist\n\ndef min_max_dist_dim3_14():\n    \"\"\"\n    Places 14 points in 3D space to maximize the squared ratio (min distance / max distance)^2.\n    The approach uses SLSQP with analytical Jacobians followed by a Nelder-Mead refinement.\n    \"\"\"\n    n = 14\n    \n    def get_score(pts_flat):\n        pts = pts_flat.reshape((-1, 3))\n        dists_sq = pdist(pts, 'sqeuclidean')\n        if len(dists_sq) == 0:\n            return 0\n        max_d = np.max(dists_sq)\n        if max_d == 0:\n            return 0\n        return np.min(dists_sq) / max_d\n\n    # Objective function for SLSQP: Maximize t (the minimum distance squared)\n    def obj(x):\n        return -x[-1]\n\n    def obj_grad(x):\n        g = np.zeros_like(x)\n        g[-1] = -1\n        return g\n\n    # Constraints for SLSQP\n    def cons_min(x):\n        pts = x[:-1].reshape((n, 3))\n        t = x[-1]\n        dists_sq = pdist(pts, 'sqeuclidean')\n        return dists_sq - t\n\n    def cons_min_jac(x):\n        pts = x[:-1].reshape((n, 3))\n        # Jacobian for n*(n-1)//2 distance constraints\n        jac = np.zeros((n * (n - 1) // 2, n * 3 + 1))\n        idx = 0\n        for i in range(n):\n            for j in range(i + 1, n):\n                diff2 = 2 * (pts[i] - pts[j])\n                jac[idx, i * 3 : i * 3 + 3] = diff2\n                jac[idx, j * 3 : j * 3 + 3] = -diff2\n                jac[idx, -1] = -1\n                idx += 1\n        return jac\n\n    def cons_max(x):\n        pts = x[:-1].reshape((n, 3))\n        dists_sq = pdist(pts, 'sqeuclidean')\n        # Maximize the ratio by fixing the maximum distance squared to 1.0\n        return 1.0 - dists_sq\n\n    def cons_max_jac(x):\n        pts = x[:-1].reshape((n, 3))\n        jac = np.zeros((n * (n - 1) // 2, n * 3 + 1))\n        idx = 0\n        for i in range(n):\n            for j in range(i + 1, n):\n                diff2 = 2 * (pts[i] - pts[j])\n                jac[idx, i * 3 : i * 3 + 3] = -diff2\n                jac[idx, j * 3 : j * 3 + 3] = diff2\n                idx += 1\n        return jac\n\n    # Generate various starting points to avoid local optima\n    starts = []\n    \n    # 1. Cube + Octahedron configuration\n    c = 0.5 / np.sqrt(3)\n    cube = np.array([[i, j, k] for i in [-c, c] for j in [-c, c] for k in [-c, c]])\n    s3 = 0.5\n    octa = np.array([[s3, 0, 0], [-s3, 0, 0], [0, s3, 0], [0, -s3, 0], [0, 0, s3], [0, 0, -s3]])\n    starts.append(np.vstack([cube, octa]))\n    \n    # 2. Golden Spiral distribution on a sphere\n    phi = np.pi * (3.0 - np.sqrt(5.0))\n    pts_spiral = []\n    for i in range(n):\n        y = 1 - (i / float(n - 1)) * 2\n        radius = np.sqrt(max(0, 1 - y * y))\n        theta = phi * i\n        pts_spiral.append([0.5 * np.cos(theta) * radius, 0.5 * y, 0.5 * np.sin(theta) * radius])\n    starts.append(np.array(pts_spiral))\n    \n    # 3. Random starts\n    np.random.seed(42)\n    for _ in range(4):\n        starts.append(np.random.rand(n, 3) - 0.5)\n\n    best_pts = starts[0]\n    best_val = get_score(best_pts)\n\n    # Optimization Loop\n    for start_pts in starts:\n        # Initial guess: coordinates + t (minimum distance squared)\n        x0 = np.zeros(n * 3 + 1)\n        x0[:-1] = start_pts.flatten()\n        x0[-1] = 0.01\n        \n        # Run SLSQP with analytical Jacobians\n        res = minimize(obj, x0, jac=obj_grad, method='SLSQP',\n                       constraints=[{'type': 'ineq', 'fun': cons_min, 'jac': cons_min_jac},\n                                    {'type': 'ineq', 'fun': cons_max, 'jac': cons_max_jac}],\n                       options={'maxiter': 200, 'ftol': 1e-12})\n        \n        pts = res.x[:-1].reshape((n, 3))\n        val = get_score(pts)\n        if val > best_val:\n            best_val = val\n            best_pts = pts\n    \n    # Final Refinement with Nelder-Mead using extremely tight tolerances\n    res_nm = minimize(lambda x: -get_score(x), best_pts.flatten(), method='Nelder-Mead',\n                      options={'fatol': 1e-15, 'xatol': 1e-15, 'maxiter': 1500})\n    \n    final_pts = res_nm.x.reshape((n, 3))\n    return final_pts\n\n```",
  "reasoning": "",
  "timestamp": "2026-01-21T17:47:46.444129",
  "cost_data": null,
  "model_config": {
    "model": "gemini-3-flash-preview",
    "temperature": 0.7,
    "provider_debug": {
      "finish_reason": "STOP",
      "usage_metadata": {
        "prompt_token_count": 290,
        "candidates_token_count": 1497,
        "thoughts_token_count": 16811
      },
      "response_text_len": 4114
    }
  }
}