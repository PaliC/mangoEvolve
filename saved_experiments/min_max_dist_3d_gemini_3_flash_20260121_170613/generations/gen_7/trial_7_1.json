{
  "trial_id": "trial_7_1",
  "generation": 7,
  "parent_id": "trial_6_0",
  "code": "import numpy as np\nfrom scipy.optimize import minimize, NonlinearConstraint\n\ndef min_max_dist_dim3_14():\n    \"\"\"\n    Finds 14 points in 3D to maximize the squared ratio (min_dist / max_dist)^2.\n    Refines a best-guess solution using trust-constr with analytical Jacobian and perturbations.\n    \"\"\"\n    N = 14\n    n_pairs = N * (N - 1) // 2\n    \n    # Precompute pair indices\n    idx_i = np.empty(n_pairs, dtype=int)\n    idx_j = np.empty(n_pairs, dtype=int)\n    k = 0\n    for i in range(N):\n        for j in range(i + 1, N):\n            idx_i[k] = i\n            idx_j[k] = j\n            k += 1\n            \n    # --- 1. Generate Initial Guess ---\n    # Since we don't have the memory of trial_6_0, we generate a high-quality candidate\n    # by minimizing a repulsive potential (Riesz energy) on the sphere/ball.\n    def get_initial_guess():\n        best_pts = None\n        best_s = -1.0\n        \n        # Run 3 random starts to ensure a good basin of attraction\n        for _ in range(3):\n            # Random points\n            pts = np.random.randn(N, 3)\n            # Project to sphere initially to separate\n            pts /= np.linalg.norm(pts, axis=1, keepdims=True)\n            \n            # Minimize soft repulsive potential (1/r^6)\n            def energy(x):\n                p = x.reshape((N, 3))\n                d = p[idx_i] - p[idx_j]\n                d2 = np.sum(d**2, axis=1)\n                return np.sum(1.0 / (d2 + 1e-9)**3)\n            \n            # Fast preliminary optimization\n            res = minimize(energy, pts.flatten(), method='L-BFGS-B', options={'maxiter': 150})\n            pts = res.x.reshape((N, 3))\n            \n            # Normalize to max_dist = 1\n            d = pts[idx_i] - pts[idx_j]\n            d2 = np.sum(d**2, axis=1)\n            max_d2 = np.max(d2)\n            pts /= np.sqrt(max_d2)\n            \n            # Calculate current s (min squared distance)\n            current_s = np.min(d2) / max_d2\n            \n            if current_s > best_s:\n                best_s = current_s\n                best_pts = pts\n        \n        return best_pts, best_s\n\n    pts_base, s_base = get_initial_guess()\n    # x vector contains flattened points and the variable s\n    x0_base = np.hstack([pts_base.flatten(), s_base])\n    \n    # --- 2. Define Trust-Constr Problem ---\n    # Variables: [x1, y1, z1, ..., xN, yN, zN, s] (Size 3N + 1)\n    # Objective: Maximize s => Minimize -s\n    \n    def obj_fun(x):\n        return -x[-1]\n    \n    def obj_jac(x):\n        g = np.zeros_like(x)\n        g[-1] = -1.0\n        return g\n    \n    # Constraints: \n    # 1. d_ij^2 >= s  =>  d_ij^2 - s >= 0\n    # 2. d_ij^2 <= 1\n    # Concatenated vector of length 2*n_pairs\n    def cons_fun(x):\n        p = x[:-1].reshape((N, 3))\n        s = x[-1]\n        diff = p[idx_i] - p[idx_j]\n        d2 = np.sum(diff**2, axis=1)\n        return np.concatenate([d2 - s, d2])\n    \n    # Analytical Jacobian for constraints\n    def cons_jac(x):\n        p = x[:-1].reshape((N, 3))\n        diff = p[idx_i] - p[idx_j] # Shape (n_pairs, 3)\n        \n        # Jacobian matrix size: (2*M, 3N+1)\n        J = np.zeros((2 * n_pairs, 3 * N + 1))\n        \n        # Gradient of d^2 w.r.t p_i is 2(p_i - p_j)\n        grads = 2 * diff\n        \n        for k in range(n_pairs):\n            i = idx_i[k]\n            j = idx_j[k]\n            g = grads[k]\n            \n            ix, jx = 3*i, 3*j\n            \n            # Row k: d^2 - s\n            J[k, ix:ix+3] = g\n            J[k, jx:jx+3] = -g\n            J[k, -1] = -1.0\n            \n            # Row k+M: d^2\n            J[k + n_pairs, ix:ix+3] = g\n            J[k + n_pairs, jx:jx+3] = -g\n            # J[k+M, -1] is 0\n            \n        return J\n\n    # Bounds for the constraints\n    # [0, inf] for d^2 - s\n    # [-inf, 1] for d^2\n    lb = np.concatenate([np.zeros(n_pairs), np.full(n_pairs, -np.inf)])\n    ub = np.concatenate([np.full(n_pairs, np.inf), np.ones(n_pairs)])\n    \n    nlc = NonlinearConstraint(cons_fun, lb, ub, jac=cons_jac)\n    \n    # --- 3. Multi-start Refinement with Perturbations ---\n    \n    best_x_final = None\n    best_loss = np.inf\n    \n    # Start with base, then add small perturbations\n    starts = [x0_base]\n    for _ in range(2):\n        pert = np.random.uniform(-1e-7, 1e-7, size=x0_base.shape)\n        starts.append(x0_base + pert)\n        \n    for x0 in starts:\n        res = minimize(\n            obj_fun, \n            x0, \n            jac=obj_jac, \n            method='trust-constr',\n            constraints=[nlc],\n            options={'gtol': 1e-12, 'xtol': 1e-12, 'maxiter': 1000}\n        )\n        \n        if res.fun < best_loss:\n            best_loss = res.fun\n            best_x_final = res.x\n\n    return best_x_final[:-1].reshape((N, 3))",
  "metrics": {
    "valid": true,
    "score": 0.9983375578621241,
    "min_max_ratio": 0.2396479982956918,
    "min_distance": 0.48953846122078226,
    "max_distance": 0.999999805378534,
    "eval_time": 1.5822818279266357,
    "error": null
  },
  "prompt": "Refine the best solution found in trial_6_0. \n        Use the 'trust-constr' method in scipy with high precision (gtol=1e-12, xtol=1e-12). \n        Implement the problem as: maximize s subject to d_ij^2 >= s and d_ij^2 <= 1. \n        Provide the analytical Jacobian for the constraints. \n        Try a multi-start where each start is a tiny perturbation (1e-7) of the best known coordinates.",
  "response": "```python\nimport numpy as np\nfrom scipy.optimize import minimize, NonlinearConstraint\n\ndef min_max_dist_dim3_14():\n    \"\"\"\n    Finds 14 points in 3D to maximize the squared ratio (min_dist / max_dist)^2.\n    Refines a best-guess solution using trust-constr with analytical Jacobian and perturbations.\n    \"\"\"\n    N = 14\n    n_pairs = N * (N - 1) // 2\n    \n    # Precompute pair indices\n    idx_i = np.empty(n_pairs, dtype=int)\n    idx_j = np.empty(n_pairs, dtype=int)\n    k = 0\n    for i in range(N):\n        for j in range(i + 1, N):\n            idx_i[k] = i\n            idx_j[k] = j\n            k += 1\n            \n    # --- 1. Generate Initial Guess ---\n    # Since we don't have the memory of trial_6_0, we generate a high-quality candidate\n    # by minimizing a repulsive potential (Riesz energy) on the sphere/ball.\n    def get_initial_guess():\n        best_pts = None\n        best_s = -1.0\n        \n        # Run 3 random starts to ensure a good basin of attraction\n        for _ in range(3):\n            # Random points\n            pts = np.random.randn(N, 3)\n            # Project to sphere initially to separate\n            pts /= np.linalg.norm(pts, axis=1, keepdims=True)\n            \n            # Minimize soft repulsive potential (1/r^6)\n            def energy(x):\n                p = x.reshape((N, 3))\n                d = p[idx_i] - p[idx_j]\n                d2 = np.sum(d**2, axis=1)\n                return np.sum(1.0 / (d2 + 1e-9)**3)\n            \n            # Fast preliminary optimization\n            res = minimize(energy, pts.flatten(), method='L-BFGS-B', options={'maxiter': 150})\n            pts = res.x.reshape((N, 3))\n            \n            # Normalize to max_dist = 1\n            d = pts[idx_i] - pts[idx_j]\n            d2 = np.sum(d**2, axis=1)\n            max_d2 = np.max(d2)\n            pts /= np.sqrt(max_d2)\n            \n            # Calculate current s (min squared distance)\n            current_s = np.min(d2) / max_d2\n            \n            if current_s > best_s:\n                best_s = current_s\n                best_pts = pts\n        \n        return best_pts, best_s\n\n    pts_base, s_base = get_initial_guess()\n    # x vector contains flattened points and the variable s\n    x0_base = np.hstack([pts_base.flatten(), s_base])\n    \n    # --- 2. Define Trust-Constr Problem ---\n    # Variables: [x1, y1, z1, ..., xN, yN, zN, s] (Size 3N + 1)\n    # Objective: Maximize s => Minimize -s\n    \n    def obj_fun(x):\n        return -x[-1]\n    \n    def obj_jac(x):\n        g = np.zeros_like(x)\n        g[-1] = -1.0\n        return g\n    \n    # Constraints: \n    # 1. d_ij^2 >= s  =>  d_ij^2 - s >= 0\n    # 2. d_ij^2 <= 1\n    # Concatenated vector of length 2*n_pairs\n    def cons_fun(x):\n        p = x[:-1].reshape((N, 3))\n        s = x[-1]\n        diff = p[idx_i] - p[idx_j]\n        d2 = np.sum(diff**2, axis=1)\n        return np.concatenate([d2 - s, d2])\n    \n    # Analytical Jacobian for constraints\n    def cons_jac(x):\n        p = x[:-1].reshape((N, 3))\n        diff = p[idx_i] - p[idx_j] # Shape (n_pairs, 3)\n        \n        # Jacobian matrix size: (2*M, 3N+1)\n        J = np.zeros((2 * n_pairs, 3 * N + 1))\n        \n        # Gradient of d^2 w.r.t p_i is 2(p_i - p_j)\n        grads = 2 * diff\n        \n        for k in range(n_pairs):\n            i = idx_i[k]\n            j = idx_j[k]\n            g = grads[k]\n            \n            ix, jx = 3*i, 3*j\n            \n            # Row k: d^2 - s\n            J[k, ix:ix+3] = g\n            J[k, jx:jx+3] = -g\n            J[k, -1] = -1.0\n            \n            # Row k+M: d^2\n            J[k + n_pairs, ix:ix+3] = g\n            J[k + n_pairs, jx:jx+3] = -g\n            # J[k+M, -1] is 0\n            \n        return J\n\n    # Bounds for the constraints\n    # [0, inf] for d^2 - s\n    # [-inf, 1] for d^2\n    lb = np.concatenate([np.zeros(n_pairs), np.full(n_pairs, -np.inf)])\n    ub = np.concatenate([np.full(n_pairs, np.inf), np.ones(n_pairs)])\n    \n    nlc = NonlinearConstraint(cons_fun, lb, ub, jac=cons_jac)\n    \n    # --- 3. Multi-start Refinement with Perturbations ---\n    \n    best_x_final = None\n    best_loss = np.inf\n    \n    # Start with base, then add small perturbations\n    starts = [x0_base]\n    for _ in range(2):\n        pert = np.random.uniform(-1e-7, 1e-7, size=x0_base.shape)\n        starts.append(x0_base + pert)\n        \n    for x0 in starts:\n        res = minimize(\n            obj_fun, \n            x0, \n            jac=obj_jac, \n            method='trust-constr',\n            constraints=[nlc],\n            options={'gtol': 1e-12, 'xtol': 1e-12, 'maxiter': 1000}\n        )\n        \n        if res.fun < best_loss:\n            best_loss = res.fun\n            best_x_final = res.x\n\n    return best_x_final[:-1].reshape((N, 3))\n```",
  "reasoning": "",
  "timestamp": "2026-01-21T17:48:03.608563",
  "cost_data": null,
  "model_config": {
    "model": "gemini-3-pro-preview",
    "temperature": 0.7,
    "provider_debug": {
      "finish_reason": "STOP",
      "usage_metadata": {
        "prompt_token_count": 287,
        "candidates_token_count": 1672,
        "thoughts_token_count": 11368
      },
      "response_text_len": 4742
    }
  }
}