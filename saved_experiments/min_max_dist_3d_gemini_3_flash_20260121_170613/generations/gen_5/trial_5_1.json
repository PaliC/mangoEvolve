{
  "trial_id": "trial_5_1",
  "generation": 5,
  "parent_id": "trial_3_6",
  "code": "import numpy as np\nfrom scipy.optimize import minimize\nimport time\n\ndef min_max_dist_dim3_14():\n    \"\"\"\n    Finds 14 points in 3D space that maximize the squared ratio of \n    (min pairwise distance / max pairwise distance).\n    Uses a basin-hopping strategy with SLSQP and analytical Jacobians.\n    \"\"\"\n    N = 14\n    \n    # --- Precompute indices for vectorized operations ---\n    idx_i, idx_j = np.triu_indices(N, k=1)\n    n_pairs = len(idx_i)\n    \n    # --- Helper Functions ---\n    def get_dists_sq(X):\n        # Returns squared pairwise distances for all pairs\n        diffs = X[idx_i] - X[idx_j]\n        return np.sum(diffs**2, axis=1)\n\n    def score_ratio_sq(X):\n        # Calculates the objective: (min_dist / max_dist)^2\n        d2 = get_dists_sq(X)\n        if len(d2) == 0: return 0.0\n        min_d2 = np.min(d2)\n        max_d2 = np.max(d2)\n        if max_d2 < 1e-12: return 0.0\n        return min_d2 / max_d2\n\n    # --- Initial Candidate Generation ---\n    # We generate a few promising starting configurations:\n    # 1. FCC-like cluster (13 centered + 1 neighbor)\n    # 2. Rhombic Dodecahedron-like vertices (8 corners + 6 face centers of cube)\n    # 3. Random points on sphere (relaxed)\n    \n    candidates = []\n    \n    # Candidate 1: FCC Cluster (13+1)\n    # Center (0,0,0), 12 neighbors at dist 1, 1 neighbor at dist sqrt(2)? \n    # Standard FCC neighbors of (0,0,0) are at distance sqrt(0.5^2+0.5^2) = 0.707 in unit cell 1.\n    # We use integer coords for simplicity: (0,0,0) and permutations of (+-1, +-1, 0).\n    fcc_pts = [[0,0,0]]\n    # Add 12 neighbors\n    for x in [-1, 1]:\n        for y in [-1, 1]:\n            fcc_pts.append([x, y, 0])\n            fcc_pts.append([x, 0, y])\n            fcc_pts.append([0, x, y])\n    # Add 1 more point from next shell (e.g., (2,0,0))\n    fcc_pts.append([2, 0, 0])\n    # Filter unique just in case\n    fcc_pts = np.unique(fcc_pts, axis=0)\n    if len(fcc_pts) >= N:\n        candidates.append(fcc_pts[:N].astype(float))\n        \n    # Candidate 2: \"Cube + Face Centers\" (14 points)\n    # Vertices (+-1, +-1, +-1) [8] + Face Centers (+-1, 0, 0)... wait face centers are (+-1, 0, 0) on surface?\n    # No, face centers of [-1,1] cube are (0,0,+-1) etc.\n    cube_face_pts = []\n    for x in [-1, 1]:\n        for y in [-1, 1]:\n            for z in [-1, 1]:\n                cube_face_pts.append([x, y, z])\n    # Face centers\n    cube_face_pts.append([1, 0, 0])\n    cube_face_pts.append([-1, 0, 0])\n    cube_face_pts.append([0, 1, 0])\n    cube_face_pts.append([0, -1, 0])\n    cube_face_pts.append([0, 0, 1])\n    cube_face_pts.append([0, 0, -1])\n    candidates.append(np.array(cube_face_pts, dtype=float))\n\n    # Candidate 3: Random Sphere Relaxation\n    np.random.seed(42)\n    for _ in range(2):\n        x0 = np.random.randn(N, 3)\n        x0 /= np.linalg.norm(x0, axis=1, keepdims=True)\n        # Simple repulsion to spread them\n        for k in range(20):\n            diffs = x0[:, None, :] - x0[None, :, :]\n            dists = np.linalg.norm(diffs, axis=2)\n            np.fill_diagonal(dists, np.inf)\n            # Force ~ 1/r^2\n            force = diffs / (dists[:, :, None]**3 + 1e-9)\n            grad = np.sum(force, axis=1)\n            x0 += 0.05 * grad\n            x0 /= np.linalg.norm(x0, axis=1, keepdims=True)\n        candidates.append(x0)\n\n    # Pick best initial guess\n    best_X = candidates[0]\n    best_score = -1.0\n    \n    for cand in candidates:\n        if len(cand) != N: continue\n        # Rescale to max_dist=1 for fair comparison\n        d2 = get_dists_sq(cand)\n        max_d = np.sqrt(np.max(d2))\n        if max_d > 0:\n            cand_norm = cand / max_d\n            s = score_ratio_sq(cand_norm)\n            if s > best_score:\n                best_score = s\n                best_X = cand_norm\n\n    # --- Optimization Setup ---\n    \n    # State vector: [x1, y1, z1, ..., xN, yN, zN, t]\n    # t is the slack variable for squared min distance.\n    # Objective: Maximize t (Minimize -t)\n    # Constraints: \n    # 1. dist_sq_ij - t >= 0\n    # 2. 1 - dist_sq_ij >= 0 (Diameter constraint)\n    \n    def pack(X, t):\n        return np.hstack([X.flatten(), t])\n    \n    def unpack(state):\n        return state[:-1].reshape(N, 3), state[-1]\n\n    # Indices for Jacobian construction\n    # We have 2*n_pairs constraints.\n    # Rows 0 to n_pairs-1: Lower bounds (d^2 - t >= 0)\n    # Rows n_pairs to 2*n_pairs-1: Upper bounds (1 - d^2 >= 0)\n    row_lower = np.arange(n_pairs)\n    row_upper = np.arange(n_pairs) + n_pairs\n    \n    def objective(state):\n        return -state[-1]\n\n    def obj_jac(state):\n        g = np.zeros_like(state)\n        g[-1] = -1.0\n        return g\n\n    def constraints(state):\n        X, t = unpack(state)\n        diffs = X[idx_i] - X[idx_j]\n        d2 = np.sum(diffs**2, axis=1)\n        # c_lower >= 0, c_upper >= 0\n        return np.concatenate([d2 - t, 1.0 - d2])\n\n    def con_jac(state):\n        X, t = unpack(state)\n        diffs = X[idx_i] - X[idx_j] # (n_pairs, 3)\n        \n        # Initialize sparse-like Jacobian (dense matrix is fine for this size)\n        J = np.zeros((2 * n_pairs, 3 * N + 1))\n        \n        # Gradients of d^2_ij w.r.t x_i is 2*(xi - xj)\n        # w.r.t x_j is -2*(xi - xj)\n        grad_i = 2 * diffs\n        grad_j = -2 * diffs\n        \n        # Fill Lower Bound Rows\n        # w.r.t X\n        for k in range(3):\n            J[row_lower, 3*idx_i + k] = grad_i[:, k]\n            J[row_lower, 3*idx_j + k] = grad_j[:, k]\n        # w.r.t t\n        J[row_lower, -1] = -1.0\n        \n        # Fill Upper Bound Rows (gradients are negative of d^2 gradients)\n        for k in range(3):\n            J[row_upper, 3*idx_i + k] = -grad_i[:, k]\n            J[row_upper, 3*idx_j + k] = -grad_j[:, k]\n        # w.r.t t is 0\n        \n        return J\n\n    cons = {'type': 'ineq', 'fun': constraints, 'jac': con_jac}\n    \n    # --- Basin Hopping Loop ---\n    \n    # Prepare initial state\n    current_X = best_X.copy()\n    # Ensure d_max <= 1\n    d2 = get_dists_sq(current_X)\n    max_d = np.sqrt(np.max(d2))\n    current_X /= max_d\n    \n    # Initial t (slightly less than min dist to be feasible)\n    d2 = get_dists_sq(current_X)\n    current_t = np.min(d2) * 0.99\n    \n    current_state = pack(current_X, current_t)\n    \n    global_best_X = current_X\n    global_best_score = score_ratio_sq(current_X)\n    \n    t_start = time.time()\n    time_limit = 58.0 # seconds\n    step_size = 1e-3 # Small perturbation as requested\n    \n    iter_count = 0\n    \n    while time.time() - t_start < time_limit:\n        iter_count += 1\n        \n        # 1. Perturbation\n        # We perturb from the GLOBAL BEST to explore its peak (Greedy/Refinement strategy)\n        # rather than wandering away (Metropolis).\n        if iter_count > 1:\n            pert = np.random.uniform(-step_size, step_size, size=3*N)\n            # Create start state from best X\n            # Reset t to be compatible with perturbed X\n            x_start = global_best_X.flatten() + pert\n            \n            # Quick feasibility check/fix for t\n            X_temp = x_start.reshape(N, 3)\n            d2_temp = get_dists_sq(X_temp)\n            t_start_val = np.min(d2_temp) * 0.95\n            \n            start_state = pack(X_temp, t_start_val)\n        else:\n            start_state = current_state\n\n        # 2. Local Minimization (SLSQP)\n        try:\n            res = minimize(\n                objective,\n                start_state,\n                jac=obj_jac,\n                constraints=cons,\n                method='SLSQP',\n                options={'ftol': 1e-9, 'maxiter': 300, 'disp': False}\n            )\n            \n            # 3. Evaluation\n            cand_X, cand_t = unpack(res.x)\n            \n            # Scale invariance check:\n            # SLSQP might output d_max slightly != 1. We compute ratio directly.\n            score = score_ratio_sq(cand_X)\n            \n            if score > global_best_score:\n                global_best_score = score\n                global_best_X = cand_X.copy()\n                # If we found a better point, we continue perturbing from here\n        except Exception:\n            continue\n\n    return global_best_X",
  "metrics": {
    "valid": true,
    "score": 0.9910643587759035,
    "min_max_ratio": 0.23790208821899253,
    "min_distance": 0.48775207659116393,
    "max_distance": 1.0000000000000002,
    "eval_time": 58.237447023391724,
    "error": null
  },
  "prompt": "Take the best solution trial_3_6 and implement a 'basin-hopping' strategy where the local minimizer is SLSQP with analytical Jacobians. Use the 'slack variable' formulation. The perturbation (stepsize) should be very small (e.g., 1e-3) to explore the local peak. Focus on the precision of the result.",
  "response": "An implementation of the 'basin-hopping' strategy with SLSQP and analytical Jacobians using the slack variable formulation.\n\n```python\nimport numpy as np\nfrom scipy.optimize import minimize\nimport time\n\ndef min_max_dist_dim3_14():\n    \"\"\"\n    Finds 14 points in 3D space that maximize the squared ratio of \n    (min pairwise distance / max pairwise distance).\n    Uses a basin-hopping strategy with SLSQP and analytical Jacobians.\n    \"\"\"\n    N = 14\n    \n    # --- Precompute indices for vectorized operations ---\n    idx_i, idx_j = np.triu_indices(N, k=1)\n    n_pairs = len(idx_i)\n    \n    # --- Helper Functions ---\n    def get_dists_sq(X):\n        # Returns squared pairwise distances for all pairs\n        diffs = X[idx_i] - X[idx_j]\n        return np.sum(diffs**2, axis=1)\n\n    def score_ratio_sq(X):\n        # Calculates the objective: (min_dist / max_dist)^2\n        d2 = get_dists_sq(X)\n        if len(d2) == 0: return 0.0\n        min_d2 = np.min(d2)\n        max_d2 = np.max(d2)\n        if max_d2 < 1e-12: return 0.0\n        return min_d2 / max_d2\n\n    # --- Initial Candidate Generation ---\n    # We generate a few promising starting configurations:\n    # 1. FCC-like cluster (13 centered + 1 neighbor)\n    # 2. Rhombic Dodecahedron-like vertices (8 corners + 6 face centers of cube)\n    # 3. Random points on sphere (relaxed)\n    \n    candidates = []\n    \n    # Candidate 1: FCC Cluster (13+1)\n    # Center (0,0,0), 12 neighbors at dist 1, 1 neighbor at dist sqrt(2)? \n    # Standard FCC neighbors of (0,0,0) are at distance sqrt(0.5^2+0.5^2) = 0.707 in unit cell 1.\n    # We use integer coords for simplicity: (0,0,0) and permutations of (+-1, +-1, 0).\n    fcc_pts = [[0,0,0]]\n    # Add 12 neighbors\n    for x in [-1, 1]:\n        for y in [-1, 1]:\n            fcc_pts.append([x, y, 0])\n            fcc_pts.append([x, 0, y])\n            fcc_pts.append([0, x, y])\n    # Add 1 more point from next shell (e.g., (2,0,0))\n    fcc_pts.append([2, 0, 0])\n    # Filter unique just in case\n    fcc_pts = np.unique(fcc_pts, axis=0)\n    if len(fcc_pts) >= N:\n        candidates.append(fcc_pts[:N].astype(float))\n        \n    # Candidate 2: \"Cube + Face Centers\" (14 points)\n    # Vertices (+-1, +-1, +-1) [8] + Face Centers (+-1, 0, 0)... wait face centers are (+-1, 0, 0) on surface?\n    # No, face centers of [-1,1] cube are (0,0,+-1) etc.\n    cube_face_pts = []\n    for x in [-1, 1]:\n        for y in [-1, 1]:\n            for z in [-1, 1]:\n                cube_face_pts.append([x, y, z])\n    # Face centers\n    cube_face_pts.append([1, 0, 0])\n    cube_face_pts.append([-1, 0, 0])\n    cube_face_pts.append([0, 1, 0])\n    cube_face_pts.append([0, -1, 0])\n    cube_face_pts.append([0, 0, 1])\n    cube_face_pts.append([0, 0, -1])\n    candidates.append(np.array(cube_face_pts, dtype=float))\n\n    # Candidate 3: Random Sphere Relaxation\n    np.random.seed(42)\n    for _ in range(2):\n        x0 = np.random.randn(N, 3)\n        x0 /= np.linalg.norm(x0, axis=1, keepdims=True)\n        # Simple repulsion to spread them\n        for k in range(20):\n            diffs = x0[:, None, :] - x0[None, :, :]\n            dists = np.linalg.norm(diffs, axis=2)\n            np.fill_diagonal(dists, np.inf)\n            # Force ~ 1/r^2\n            force = diffs / (dists[:, :, None]**3 + 1e-9)\n            grad = np.sum(force, axis=1)\n            x0 += 0.05 * grad\n            x0 /= np.linalg.norm(x0, axis=1, keepdims=True)\n        candidates.append(x0)\n\n    # Pick best initial guess\n    best_X = candidates[0]\n    best_score = -1.0\n    \n    for cand in candidates:\n        if len(cand) != N: continue\n        # Rescale to max_dist=1 for fair comparison\n        d2 = get_dists_sq(cand)\n        max_d = np.sqrt(np.max(d2))\n        if max_d > 0:\n            cand_norm = cand / max_d\n            s = score_ratio_sq(cand_norm)\n            if s > best_score:\n                best_score = s\n                best_X = cand_norm\n\n    # --- Optimization Setup ---\n    \n    # State vector: [x1, y1, z1, ..., xN, yN, zN, t]\n    # t is the slack variable for squared min distance.\n    # Objective: Maximize t (Minimize -t)\n    # Constraints: \n    # 1. dist_sq_ij - t >= 0\n    # 2. 1 - dist_sq_ij >= 0 (Diameter constraint)\n    \n    def pack(X, t):\n        return np.hstack([X.flatten(), t])\n    \n    def unpack(state):\n        return state[:-1].reshape(N, 3), state[-1]\n\n    # Indices for Jacobian construction\n    # We have 2*n_pairs constraints.\n    # Rows 0 to n_pairs-1: Lower bounds (d^2 - t >= 0)\n    # Rows n_pairs to 2*n_pairs-1: Upper bounds (1 - d^2 >= 0)\n    row_lower = np.arange(n_pairs)\n    row_upper = np.arange(n_pairs) + n_pairs\n    \n    def objective(state):\n        return -state[-1]\n\n    def obj_jac(state):\n        g = np.zeros_like(state)\n        g[-1] = -1.0\n        return g\n\n    def constraints(state):\n        X, t = unpack(state)\n        diffs = X[idx_i] - X[idx_j]\n        d2 = np.sum(diffs**2, axis=1)\n        # c_lower >= 0, c_upper >= 0\n        return np.concatenate([d2 - t, 1.0 - d2])\n\n    def con_jac(state):\n        X, t = unpack(state)\n        diffs = X[idx_i] - X[idx_j] # (n_pairs, 3)\n        \n        # Initialize sparse-like Jacobian (dense matrix is fine for this size)\n        J = np.zeros((2 * n_pairs, 3 * N + 1))\n        \n        # Gradients of d^2_ij w.r.t x_i is 2*(xi - xj)\n        # w.r.t x_j is -2*(xi - xj)\n        grad_i = 2 * diffs\n        grad_j = -2 * diffs\n        \n        # Fill Lower Bound Rows\n        # w.r.t X\n        for k in range(3):\n            J[row_lower, 3*idx_i + k] = grad_i[:, k]\n            J[row_lower, 3*idx_j + k] = grad_j[:, k]\n        # w.r.t t\n        J[row_lower, -1] = -1.0\n        \n        # Fill Upper Bound Rows (gradients are negative of d^2 gradients)\n        for k in range(3):\n            J[row_upper, 3*idx_i + k] = -grad_i[:, k]\n            J[row_upper, 3*idx_j + k] = -grad_j[:, k]\n        # w.r.t t is 0\n        \n        return J\n\n    cons = {'type': 'ineq', 'fun': constraints, 'jac': con_jac}\n    \n    # --- Basin Hopping Loop ---\n    \n    # Prepare initial state\n    current_X = best_X.copy()\n    # Ensure d_max <= 1\n    d2 = get_dists_sq(current_X)\n    max_d = np.sqrt(np.max(d2))\n    current_X /= max_d\n    \n    # Initial t (slightly less than min dist to be feasible)\n    d2 = get_dists_sq(current_X)\n    current_t = np.min(d2) * 0.99\n    \n    current_state = pack(current_X, current_t)\n    \n    global_best_X = current_X\n    global_best_score = score_ratio_sq(current_X)\n    \n    t_start = time.time()\n    time_limit = 58.0 # seconds\n    step_size = 1e-3 # Small perturbation as requested\n    \n    iter_count = 0\n    \n    while time.time() - t_start < time_limit:\n        iter_count += 1\n        \n        # 1. Perturbation\n        # We perturb from the GLOBAL BEST to explore its peak (Greedy/Refinement strategy)\n        # rather than wandering away (Metropolis).\n        if iter_count > 1:\n            pert = np.random.uniform(-step_size, step_size, size=3*N)\n            # Create start state from best X\n            # Reset t to be compatible with perturbed X\n            x_start = global_best_X.flatten() + pert\n            \n            # Quick feasibility check/fix for t\n            X_temp = x_start.reshape(N, 3)\n            d2_temp = get_dists_sq(X_temp)\n            t_start_val = np.min(d2_temp) * 0.95\n            \n            start_state = pack(X_temp, t_start_val)\n        else:\n            start_state = current_state\n\n        # 2. Local Minimization (SLSQP)\n        try:\n            res = minimize(\n                objective,\n                start_state,\n                jac=obj_jac,\n                constraints=cons,\n                method='SLSQP',\n                options={'ftol': 1e-9, 'maxiter': 300, 'disp': False}\n            )\n            \n            # 3. Evaluation\n            cand_X, cand_t = unpack(res.x)\n            \n            # Scale invariance check:\n            # SLSQP might output d_max slightly != 1. We compute ratio directly.\n            score = score_ratio_sq(cand_X)\n            \n            if score > global_best_score:\n                global_best_score = score\n                global_best_X = cand_X.copy()\n                # If we found a better point, we continue perturbing from here\n        except Exception:\n            continue\n\n    return global_best_X\n```",
  "reasoning": "An implementation of the 'basin-hopping' strategy with SLSQP and analytical Jacobians using the slack variable formulation.",
  "timestamp": "2026-01-21T17:39:36.738002",
  "cost_data": null,
  "model_config": {
    "model": "gemini-3-pro-preview",
    "temperature": 0.7,
    "provider_debug": {
      "finish_reason": "STOP",
      "usage_metadata": {
        "prompt_token_count": 246,
        "candidates_token_count": 2889,
        "thoughts_token_count": 12415
      },
      "response_text_len": 8271
    }
  }
}