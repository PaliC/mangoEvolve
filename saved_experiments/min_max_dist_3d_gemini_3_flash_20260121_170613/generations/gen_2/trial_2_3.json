{
  "trial_id": "trial_2_3",
  "generation": 2,
  "parent_id": null,
  "code": "import numpy as np\nfrom scipy.optimize import minimize\nfrom scipy.spatial.distance import pdist\nimport itertools\nimport time\n\ndef min_max_dist_dim3_14():\n    \"\"\"\n    Returns a numpy array of shape (14, 3) representing 14 points in 3D space\n    that maximize the squared ratio (min_dist / max_dist)^2.\n    \"\"\"\n    N = 14\n    dim = 3\n    \n    # --- Helper Functions ---\n    def get_score(flat_pts):\n        # Calculate the target metric: (min_dist / max_dist)^2\n        pts = flat_pts.reshape((N, dim))\n        dists = pdist(pts)\n        if dists.size == 0 or dists.max() <= 1e-9: return 0.0\n        return (dists.min() / dists.max())**2\n\n    def objective(flat_pts):\n        # Smooth objective function for the optimizer\n        # We want to maximize min/max, so we minimize -(min/max)\n        # We use SoftMin and SoftMax approximations to make the function differentiable\n        pts = flat_pts.reshape((N, dim))\n        dists_sq = pdist(pts, 'sqeuclidean')\n        \n        # Normalize distances to prevent numerical overflow in exp()\n        # The ratio is scale-invariant, so this doesn't affect the optimum\n        scale = np.mean(dists_sq)\n        if scale < 1e-12: return 1e9\n        \n        # Scaled squared distances\n        ds = dists_sq / scale\n        \n        # SoftMin/SoftMax parameter beta\n        # Larger beta = closer to true min/max but vanishing gradients\n        beta = 20.0\n        \n        # SoftMin of squared distances: -log(sum(exp(-beta * d^2))) / beta\n        # Using LogSumExp trick for stability: log(sum(exp(x))) = max + log(sum(exp(x-max)))\n        neg_ds = -beta * ds\n        max_neg = np.max(neg_ds)\n        soft_min_sq = - (np.log(np.sum(np.exp(neg_ds - max_neg))) + max_neg) / beta\n        \n        # SoftMax of squared distances\n        pos_ds = beta * ds\n        max_pos = np.max(pos_ds)\n        soft_max_sq = (np.log(np.sum(np.exp(pos_ds - max_pos))) + max_pos) / beta\n        \n        if soft_max_sq <= 1e-9: return 1e9\n        \n        # Ratio of smooth squared distances\n        # This approximates (min_dist / max_dist)^2\n        ratio = soft_min_sq / soft_max_sq\n        return -ratio\n\n    # --- 1. Generate Initial Candidates ---\n    candidates = []\n    \n    # Helper to extract best N-subset from a lattice pool\n    def get_lattice_subset(pts_pool, K=19):\n        # We take K closest points to the centroid and check all combinations\n        if len(pts_pool) < N: return None, -1\n        \n        # Center the pool\n        center = np.mean(pts_pool, axis=0)\n        dists_to_center = np.sum((pts_pool - center)**2, axis=1)\n        \n        # Sort and take top K\n        idx = np.argsort(dists_to_center)\n        pool_k = pts_pool[idx[:K]]\n        \n        best_sub_score = -1\n        best_sub = None\n        \n        # Brute force check all subsets of size N from K points\n        # K=19 => 11,628 combinations (very fast in C/Numpy, manageable in Python)\n        for indices in itertools.combinations(range(len(pool_k)), N):\n            cfg = pool_k[list(indices)]\n            # Fast score calc\n            D = pdist(cfg)\n            if D.max() < 1e-9: continue\n            sc = (D.min()/D.max())**2\n            if sc > best_sub_score:\n                best_sub_score = sc\n                best_sub = cfg\n        return best_sub, best_sub_score\n\n    # A. Face Centered Cubic (FCC) Lattice\n    pts_fcc = []\n    r = 2\n    for x in range(-r, r+1):\n        for y in range(-r, r+1):\n            for z in range(-r, r+1):\n                if (x+y+z) % 2 == 0:\n                    pts_fcc.append([x, y, z])\n    pts_fcc = np.array(pts_fcc, dtype=float)\n    \n    # B. Body Centered Cubic (BCC) Lattice\n    pts_bcc = []\n    for x in range(-r, r+1):\n        for y in range(-r, r+1):\n            for z in range(-r, r+1):\n                pts_bcc.append([x, y, z])\n                pts_bcc.append([x+0.5, y+0.5, z+0.5])\n    pts_bcc = np.array(pts_bcc, dtype=float)\n    \n    # C. Hexagonal Close Packing (HCP)\n    pts_hcp = []\n    for k in range(-r, r+1):\n        is_layer_b = (k % 2 != 0)\n        for j in range(-r, r+1):\n            for i in range(-r, r+1):\n                # Standard HCP basis offsets\n                shift = np.array([0.5, 1.0/(2*np.sqrt(3)), 0]) if is_layer_b else np.zeros(3)\n                # Basis vectors: a=(1,0,0), b=(0.5, sqrt(3)/2, 0), c=(0,0,sqrt(8/3))\n                p = np.array([i, 0, 0]) + \\\n                    np.array([0.5*j, np.sqrt(3)/2*j, 0]) + \\\n                    np.array([0, 0, np.sqrt(8/3)*k]) + \\\n                    shift\n                pts_hcp.append(p)\n    pts_hcp = np.array(pts_hcp, dtype=float)\n\n    # Extract best subsets from lattices\n    for lat in [pts_fcc, pts_bcc, pts_hcp]:\n        # Try centered at mean\n        cfg, sc = get_lattice_subset(lat, K=19)\n        if cfg is not None: candidates.append(cfg)\n        \n        # Try shifted (e.g., centered on a void/offset)\n        # Shift lattice by arbitrary small amount relative to selection center\n        lat_shifted = lat + np.array([0.1, 0.1, 0.1])\n        cfg, sc = get_lattice_subset(lat_shifted, K=19)\n        if cfg is not None: candidates.append(cfg)\n\n    # D. Spherical Code (Fibonacci Sphere)\n    # Good for surface-only optimal configurations\n    idx = np.arange(0, N, dtype=float) + 0.5\n    phi = np.arccos(1 - 2*idx/N)\n    theta = np.pi * (1 + 5**0.5) * idx\n    x, y, z = np.cos(theta)*np.sin(phi), np.sin(theta)*np.sin(phi), np.cos(phi)\n    pts_sphere = np.column_stack((x, y, z))\n    candidates.append(pts_sphere)\n\n    # E. Random Clouds\n    for _ in range(3):\n        candidates.append(np.random.randn(N, dim))\n\n    # --- 2. Select and Refine ---\n    \n    # Evaluate starting scores\n    scored_candidates = []\n    for c in candidates:\n        s = get_score(c.flatten())\n        scored_candidates.append((s, c))\n    \n    # Sort by score descending\n    scored_candidates.sort(key=lambda x: x[0], reverse=True)\n    \n    best_overall_pts = None\n    best_overall_score = -1.0\n    \n    t_start = time.time()\n    time_limit = 55  # seconds\n    \n    # Run optimization on the top few candidates\n    for _, start_pts in scored_candidates[:5]:\n        if time.time() - t_start > time_limit: break\n        \n        # Add slight noise to break perfect symmetries that might trap the solver\n        p0 = start_pts.flatten() + np.random.normal(0, 0.01, N*dim)\n        \n        # L-BFGS-B is efficient for high-dim bound/unbound smooth optimization\n        res = minimize(objective, p0, method='L-BFGS-B', \n                       options={'maxiter': 2000, 'ftol': 1e-7})\n        \n        final_pts = res.x.reshape((N, dim))\n        s = get_score(res.x)\n        \n        if s > best_overall_score:\n            best_overall_score = s\n            best_overall_pts = final_pts\n\n    # Final Polish: If time permits, run Nelder-Mead (derivative-free) on the best result\n    # This helps fix small errors from the \"SoftMin\" approximation\n    if time.time() - t_start < time_limit - 5 and best_overall_pts is not None:\n        res = minimize(objective, best_overall_pts.flatten(), method='Nelder-Mead', \n                       options={'maxiter': 1000, 'xatol': 1e-5})\n        s = get_score(res.x)\n        if s > best_overall_score:\n            best_overall_pts = res.x.reshape((N, dim))\n\n    # Fallback if everything failed\n    if best_overall_pts is None:\n        best_overall_pts = np.random.randn(N, dim)\n\n    return best_overall_pts",
  "metrics": {
    "valid": true,
    "score": 0.9687299120964199,
    "min_max_ratio": 0.23254076989772057,
    "min_distance": 1.4023591387104684,
    "max_distance": 2.908102407915083,
    "eval_time": 1.4669477939605713,
    "error": null
  },
  "prompt": "14 points in 3D might be related to a specific lattice or a modified sphere packing. Try initializing the points as a 2x2x3 grid or a BCC lattice subset, then apply 'scipy.optimize.minimize' to perturb the points and maximize the min/max ratio.",
  "response": "An algorithm to find a configuration of 14 points in 3D space that maximizes the squared ratio of the minimum pairwise distance to the maximum pairwise distance.\n\nThe solution employs a multi-stage approach:\n1.  **Candidate Generation**: It generates initial configurations based on subsets of common lattices (FCC, BCC, HCP) and spherical codes (Fibonacci sphere). This leverages the fact that optimal packings often resemble lattice structures or spherical distributions.\n2.  **Subset Selection**: For lattice candidates, it greedily searches for the best subset of 14 points from a larger local cluster (e.g., the 19 closest points to a center), evaluating all $\\binom{19}{14}$ combinations.\n3.  **Continuous Optimization**: The best candidates are refined using numerical optimization (`L-BFGS-B` and `Nelder-Mead`). A smooth approximation of the min-max ratio (using SoftMin and SoftMax with LogSumExp) is used as the objective function to provide gradients for the solver.\n\n```python\nimport numpy as np\nfrom scipy.optimize import minimize\nfrom scipy.spatial.distance import pdist\nimport itertools\nimport time\n\ndef min_max_dist_dim3_14():\n    \"\"\"\n    Returns a numpy array of shape (14, 3) representing 14 points in 3D space\n    that maximize the squared ratio (min_dist / max_dist)^2.\n    \"\"\"\n    N = 14\n    dim = 3\n    \n    # --- Helper Functions ---\n    def get_score(flat_pts):\n        # Calculate the target metric: (min_dist / max_dist)^2\n        pts = flat_pts.reshape((N, dim))\n        dists = pdist(pts)\n        if dists.size == 0 or dists.max() <= 1e-9: return 0.0\n        return (dists.min() / dists.max())**2\n\n    def objective(flat_pts):\n        # Smooth objective function for the optimizer\n        # We want to maximize min/max, so we minimize -(min/max)\n        # We use SoftMin and SoftMax approximations to make the function differentiable\n        pts = flat_pts.reshape((N, dim))\n        dists_sq = pdist(pts, 'sqeuclidean')\n        \n        # Normalize distances to prevent numerical overflow in exp()\n        # The ratio is scale-invariant, so this doesn't affect the optimum\n        scale = np.mean(dists_sq)\n        if scale < 1e-12: return 1e9\n        \n        # Scaled squared distances\n        ds = dists_sq / scale\n        \n        # SoftMin/SoftMax parameter beta\n        # Larger beta = closer to true min/max but vanishing gradients\n        beta = 20.0\n        \n        # SoftMin of squared distances: -log(sum(exp(-beta * d^2))) / beta\n        # Using LogSumExp trick for stability: log(sum(exp(x))) = max + log(sum(exp(x-max)))\n        neg_ds = -beta * ds\n        max_neg = np.max(neg_ds)\n        soft_min_sq = - (np.log(np.sum(np.exp(neg_ds - max_neg))) + max_neg) / beta\n        \n        # SoftMax of squared distances\n        pos_ds = beta * ds\n        max_pos = np.max(pos_ds)\n        soft_max_sq = (np.log(np.sum(np.exp(pos_ds - max_pos))) + max_pos) / beta\n        \n        if soft_max_sq <= 1e-9: return 1e9\n        \n        # Ratio of smooth squared distances\n        # This approximates (min_dist / max_dist)^2\n        ratio = soft_min_sq / soft_max_sq\n        return -ratio\n\n    # --- 1. Generate Initial Candidates ---\n    candidates = []\n    \n    # Helper to extract best N-subset from a lattice pool\n    def get_lattice_subset(pts_pool, K=19):\n        # We take K closest points to the centroid and check all combinations\n        if len(pts_pool) < N: return None, -1\n        \n        # Center the pool\n        center = np.mean(pts_pool, axis=0)\n        dists_to_center = np.sum((pts_pool - center)**2, axis=1)\n        \n        # Sort and take top K\n        idx = np.argsort(dists_to_center)\n        pool_k = pts_pool[idx[:K]]\n        \n        best_sub_score = -1\n        best_sub = None\n        \n        # Brute force check all subsets of size N from K points\n        # K=19 => 11,628 combinations (very fast in C/Numpy, manageable in Python)\n        for indices in itertools.combinations(range(len(pool_k)), N):\n            cfg = pool_k[list(indices)]\n            # Fast score calc\n            D = pdist(cfg)\n            if D.max() < 1e-9: continue\n            sc = (D.min()/D.max())**2\n            if sc > best_sub_score:\n                best_sub_score = sc\n                best_sub = cfg\n        return best_sub, best_sub_score\n\n    # A. Face Centered Cubic (FCC) Lattice\n    pts_fcc = []\n    r = 2\n    for x in range(-r, r+1):\n        for y in range(-r, r+1):\n            for z in range(-r, r+1):\n                if (x+y+z) % 2 == 0:\n                    pts_fcc.append([x, y, z])\n    pts_fcc = np.array(pts_fcc, dtype=float)\n    \n    # B. Body Centered Cubic (BCC) Lattice\n    pts_bcc = []\n    for x in range(-r, r+1):\n        for y in range(-r, r+1):\n            for z in range(-r, r+1):\n                pts_bcc.append([x, y, z])\n                pts_bcc.append([x+0.5, y+0.5, z+0.5])\n    pts_bcc = np.array(pts_bcc, dtype=float)\n    \n    # C. Hexagonal Close Packing (HCP)\n    pts_hcp = []\n    for k in range(-r, r+1):\n        is_layer_b = (k % 2 != 0)\n        for j in range(-r, r+1):\n            for i in range(-r, r+1):\n                # Standard HCP basis offsets\n                shift = np.array([0.5, 1.0/(2*np.sqrt(3)), 0]) if is_layer_b else np.zeros(3)\n                # Basis vectors: a=(1,0,0), b=(0.5, sqrt(3)/2, 0), c=(0,0,sqrt(8/3))\n                p = np.array([i, 0, 0]) + \\\n                    np.array([0.5*j, np.sqrt(3)/2*j, 0]) + \\\n                    np.array([0, 0, np.sqrt(8/3)*k]) + \\\n                    shift\n                pts_hcp.append(p)\n    pts_hcp = np.array(pts_hcp, dtype=float)\n\n    # Extract best subsets from lattices\n    for lat in [pts_fcc, pts_bcc, pts_hcp]:\n        # Try centered at mean\n        cfg, sc = get_lattice_subset(lat, K=19)\n        if cfg is not None: candidates.append(cfg)\n        \n        # Try shifted (e.g., centered on a void/offset)\n        # Shift lattice by arbitrary small amount relative to selection center\n        lat_shifted = lat + np.array([0.1, 0.1, 0.1])\n        cfg, sc = get_lattice_subset(lat_shifted, K=19)\n        if cfg is not None: candidates.append(cfg)\n\n    # D. Spherical Code (Fibonacci Sphere)\n    # Good for surface-only optimal configurations\n    idx = np.arange(0, N, dtype=float) + 0.5\n    phi = np.arccos(1 - 2*idx/N)\n    theta = np.pi * (1 + 5**0.5) * idx\n    x, y, z = np.cos(theta)*np.sin(phi), np.sin(theta)*np.sin(phi), np.cos(phi)\n    pts_sphere = np.column_stack((x, y, z))\n    candidates.append(pts_sphere)\n\n    # E. Random Clouds\n    for _ in range(3):\n        candidates.append(np.random.randn(N, dim))\n\n    # --- 2. Select and Refine ---\n    \n    # Evaluate starting scores\n    scored_candidates = []\n    for c in candidates:\n        s = get_score(c.flatten())\n        scored_candidates.append((s, c))\n    \n    # Sort by score descending\n    scored_candidates.sort(key=lambda x: x[0], reverse=True)\n    \n    best_overall_pts = None\n    best_overall_score = -1.0\n    \n    t_start = time.time()\n    time_limit = 55  # seconds\n    \n    # Run optimization on the top few candidates\n    for _, start_pts in scored_candidates[:5]:\n        if time.time() - t_start > time_limit: break\n        \n        # Add slight noise to break perfect symmetries that might trap the solver\n        p0 = start_pts.flatten() + np.random.normal(0, 0.01, N*dim)\n        \n        # L-BFGS-B is efficient for high-dim bound/unbound smooth optimization\n        res = minimize(objective, p0, method='L-BFGS-B', \n                       options={'maxiter': 2000, 'ftol': 1e-7})\n        \n        final_pts = res.x.reshape((N, dim))\n        s = get_score(res.x)\n        \n        if s > best_overall_score:\n            best_overall_score = s\n            best_overall_pts = final_pts\n\n    # Final Polish: If time permits, run Nelder-Mead (derivative-free) on the best result\n    # This helps fix small errors from the \"SoftMin\" approximation\n    if time.time() - t_start < time_limit - 5 and best_overall_pts is not None:\n        res = minimize(objective, best_overall_pts.flatten(), method='Nelder-Mead', \n                       options={'maxiter': 1000, 'xatol': 1e-5})\n        s = get_score(res.x)\n        if s > best_overall_score:\n            best_overall_pts = res.x.reshape((N, dim))\n\n    # Fallback if everything failed\n    if best_overall_pts is None:\n        best_overall_pts = np.random.randn(N, dim)\n\n    return best_overall_pts\n```",
  "reasoning": "An algorithm to find a configuration of 14 points in 3D space that maximizes the squared ratio of the minimum pairwise distance to the maximum pairwise distance.\n\nThe solution employs a multi-stage approach:\n1.  **Candidate Generation**: It generates initial configurations based on subsets of common lattices (FCC, BCC, HCP) and spherical codes (Fibonacci sphere). This leverages the fact that optimal packings often resemble lattice structures or spherical distributions.\n2.  **Subset Selection**: For lattice candidates, it greedily searches for the best subset of 14 points from a larger local cluster (e.g., the 19 closest points to a center), evaluating all $\\binom{19}{14}$ combinations.\n3.  **Continuous Optimization**: The best candidates are refined using numerical optimization (`L-BFGS-B` and `Nelder-Mead`). A smooth approximation of the min-max ratio (using SoftMin and SoftMax with LogSumExp) is used as the objective function to provide gradients for the solver.",
  "timestamp": "2026-01-21T17:22:19.025167",
  "cost_data": null,
  "model_config": {
    "model": "gemini-3-pro-preview",
    "temperature": 0.7,
    "provider_debug": {
      "finish_reason": "STOP",
      "usage_metadata": {
        "prompt_token_count": 233,
        "candidates_token_count": 2639,
        "thoughts_token_count": 14143
      },
      "response_text_len": 8366
    }
  }
}