{
  "trial_id": "trial_7_5",
  "generation": 7,
  "parent_id": null,
  "code": "import numpy as np\nfrom scipy.optimize import minimize, linprog\n\ndef construct_packing():\n    \"\"\"\n    Construct a packing of 26 non-overlapping circles in the unit square.\n    Returns:\n      centers: np.array (26,2)\n      radii: np.array (26,)\n      sum_radii: float\n    \"\"\"\n    rng = np.random.RandomState(123456)  # deterministic\n\n    n = 26\n\n    # 1) Seed 26 centers via a near-hexagonal tiling clipped to [0,1]^2\n    # Use 5 rows with counts chosen to total 26: [5,6,5,5,5]\n    row_counts = [5, 6, 5, 5, 5]\n    assert sum(row_counts) == n\n    num_rows = len(row_counts)\n    margin = 0.04  # keep away from exact boundary initially\n    ys = np.linspace(margin, 1.0 - margin, num_rows)\n    centers = []\n    for ridx, (y, nx) in enumerate(zip(ys, row_counts)):\n        # x positions\n        if nx > 1:\n            xs = np.linspace(margin, 1.0 - margin, nx)\n        else:\n            xs = np.array([0.5])\n        # apply small row offset for hex-like arrangement\n        if ridx % 2 == 1:\n            # offset xs by half-step but keep inside [margin,1-margin]\n            dx = xs[1] - xs[0] if len(xs) > 1 else 0.05\n            xs = xs + 0.5 * dx\n            # clamp\n            xs = np.clip(xs, margin, 1.0 - margin)\n        for x in xs:\n            centers.append([x, y])\n    centers = np.array(centers[:n], dtype=float)\n\n    # slight deterministic jitter and bias some centers near edges/corners\n    jitter_scale = 0.018\n    centers += (rng.rand(n, 2) - 0.5) * jitter_scale\n\n    # push a few selected indices slightly toward nearest edge/corner to bias edges\n    edge_bias_indices = np.arange(0, min(6, n))\n    for idx in edge_bias_indices:\n        # push outward by up to 0.03 proportionally to position\n        c = centers[idx]\n        # determine direction towards closer edge/corner\n        dx = np.array([0.0, 0.0])\n        # bias in x\n        if c[0] < 0.5:\n            dx[0] -= 0.03 * (0.5 - c[0]) / 0.5\n        else:\n            dx[0] += 0.03 * (c[0] - 0.5) / 0.5\n        # bias in y\n        if c[1] < 0.5:\n            dx[1] -= 0.03 * (0.5 - c[1]) / 0.5\n        else:\n            dx[1] += 0.03 * (c[1] - 0.5) / 0.5\n        centers[idx] = np.clip(c + dx, 0.0, 1.0)\n\n    centers = np.clip(centers, 0.0, 1.0)\n\n    # 2) Initialize provisional radii as boundary distances b_i\n    def boundary_distance(pt):\n        return min(pt[0], pt[1], 1.0 - pt[0], 1.0 - pt[1])\n\n    b = np.minimum.reduce([centers[:, 0], centers[:, 1], 1.0 - centers[:, 0], 1.0 - centers[:, 1]])\n    # ensure positive minimal margin\n    b = np.maximum(b, 1e-3)\n\n    # 3) Dykstra-like projection to reduce overlaps\n    # Pairwise operations vectorized\n    K = 240  # passes\n    beta_start = 0.45\n    beta_end = 1.05\n    relax = 0.65  # relaxation factor for applying corrections\n\n    # Precompute pair index arrays for i<j\n    idx_i, idx_j = np.triu_indices(n, k=1)\n\n    # For deterministic random directions when distance is zero\n    # Create deterministic pseudo-random unit vectors for each pair\n    pair_rng = np.random.RandomState(424242)\n    rand_dirs = pair_rng.randn(len(idx_i), 2)\n    rand_norms = np.linalg.norm(rand_dirs, axis=1, keepdims=True)\n    rand_dirs = rand_dirs / np.maximum(rand_norms, 1e-12)\n\n    # Run passes\n    c = centers.copy()\n    b_vec = b.copy()\n    for it in range(K):\n        beta = beta_start + (beta_end - beta_start) * (it / max(1, K - 1))\n        # compute pairwise diffs and distances\n        # diff from i to j\n        diffs = c[idx_i] - c[idx_j]  # (m,2)\n        dists = np.linalg.norm(diffs, axis=1)\n        # desired spacing\n        s = beta * (b_vec[idx_i] + b_vec[idx_j])\n        deficits = s - dists\n        mask = deficits > 1e-12\n        if not np.any(mask):\n            # nothing to correct this pass\n            continue\n        # unit vectors, handling zero distances\n        u = np.zeros_like(diffs)\n        nz = dists > 1e-12\n        u[nz] = diffs[nz] / dists[nz][:, None]\n        u[~nz] = rand_dirs[~nz]\n        # movement magnitudes for i and j (split by weights proportional to b_i, b_j)\n        bi = b_vec[idx_i]\n        bj = b_vec[idx_j]\n        denom = bi + bj\n        # avoid zero denom (shouldn't happen due to min b constraint)\n        denom = np.maximum(denom, 1e-12)\n        # movement assignments such that movement_i + movement_j = deficits\n        move_i_mag = (bj / denom) * deficits\n        move_j_mag = (bi / denom) * deficits\n        # Only apply for masked pairs\n        move_i_mag = move_i_mag * mask\n        move_j_mag = move_j_mag * mask\n        u_masked = u * mask[:, None]\n\n        # Accumulate corrections\n        corr = np.zeros_like(c)\n        # For i indices add u * move_i_mag\n        np.add.at(corr, idx_i, u_masked * move_i_mag[:, None])\n        # For j indices subtract u * move_j_mag\n        np.add.at(corr, idx_j, -u_masked * move_j_mag[:, None])\n\n        # Apply relaxation and update\n        c += relax * corr\n\n        # Keep centers within [0,1]\n        c = np.clip(c, 0.0, 1.0)\n\n        # Update boundary distances? The algorithm requested using initial b_i but it's fine to keep b_vec constant.\n\n    # After projection, recompute boundary distances\n    b_current = np.minimum.reduce([c[:, 0], c[:, 1], 1.0 - c[:, 0], 1.0 - c[:, 1]])\n    b_current = np.maximum(b_current, 1e-6)\n\n    # Small perturbation to break any exact collisions (deterministic)\n    min_pair = np.inf\n    diffs_full = c[:, None, :] - c[None, :, :]\n    dists_full = np.linalg.norm(diffs_full + np.eye(n)[:, :, None], axis=2)  # add diag offset to avoid zero\n    # compute true pairwise distances\n    true_dists = np.linalg.norm(c[idx_i] - c[idx_j], axis=1)\n    if np.any(true_dists < 1e-8):\n        # perturb slightly\n        perturb = (pair_rng.randn(n, 2) * 1e-5)\n        c = np.clip(c + perturb, 0.0, 1.0)\n        b_current = np.minimum.reduce([c[:, 0], c[:, 1], 1.0 - c[:, 0], 1.0 - c[:, 1]])\n        b_current = np.maximum(b_current, 1e-6)\n\n    # 4) L-BFGS-B polish on smooth overlap penalty\n    eps = 1e-8\n\n    # target spacing s_ij uses boundary distances b_current (we want distances >= b_i + b_j)\n    bi = b_current.copy()\n\n    pair_idx_i = idx_i\n    pair_idx_j = idx_j\n\n    def penalty_obj(flat_c):\n        cmat = flat_c.reshape((n, 2))\n        diffs = cmat[pair_idx_i] - cmat[pair_idx_j]\n        d = np.linalg.norm(diffs, axis=1)\n        s = bi[pair_idx_i] + bi[pair_idx_j]\n        gaps = s - d  # positive if overlap\n        pos = np.maximum(0.0, gaps)\n        # penalty: sum(pos^2 / (d + eps))\n        val = np.sum((pos * pos) / (d + eps))\n        return val\n\n    x0 = c.ravel()\n    bounds = [(0.0, 1.0)] * (2 * n)\n    # minimize penalty\n    res = minimize(penalty_obj, x0, method='L-BFGS-B', bounds=bounds,\n                   options={'maxiter': 200, 'ftol': 1e-9})\n\n    if res.success:\n        c = res.x.reshape((n, 2))\n    else:\n        # if polish fails, keep previous centers\n        c = c\n\n    c = np.clip(c, 0.0, 1.0)\n    # recompute boundary distances\n    b_current = np.minimum.reduce([c[:, 0], c[:, 1], 1.0 - c[:, 0], 1.0 - c[:, 1]])\n    b_current = np.maximum(b_current, 0.0)\n\n    # 5) LP feasibilization to maximize sum(r) subject to constraints\n    # Variables: r_0 ... r_{n-1}\n    # Objective: maximize sum r  -> minimize -sum r\n    c_obj = -np.ones(n)\n\n    # Bounds: 0 <= r_i <= r_i_current (also r_i <= x_i, y_i, ...)\n    # r_i_current as current boundary distances (explicitly include)\n    r_upper = b_current.copy()\n    # also enforce the geometric bounds explicitly (redundant but safe)\n    r_upper = np.minimum(r_upper, c[:, 0])\n    r_upper = np.minimum(r_upper, c[:, 1])\n    r_upper = np.minimum(r_upper, 1.0 - c[:, 0])\n    r_upper = np.minimum(r_upper, 1.0 - c[:, 1])\n    # ensure non-negative\n    r_upper = np.maximum(r_upper, 0.0)\n\n    var_bounds = [(0.0, float(r_upper[i])) for i in range(n)]\n\n    # Pairwise non-overlap constraints: for each pair i<j: r_i + r_j <= dist_ij - 1e-6\n    pairwise_dists = np.linalg.norm(c[pair_idx_i] - c[pair_idx_j], axis=1)\n    eps_margin = 1e-6\n    b_ub = pairwise_dists - eps_margin\n    # If any b_ub < 0, that may make LP infeasible. To be robust, clamp to 0 (will force radii sum <= 0 for that pair)\n    # but better to allow small negative slack by decreasing 1e-6 to zero if necessary. We'll clamp b_ub to >=0\n    # because r_i + r_j >=0 anyways; but we should not allow negative right-hand sides that make problem infeasible.\n    b_ub = np.maximum(b_ub, 0.0)\n\n    # Create A_ub matrix: rows equal number of pairs, columns n\n    m_pairs = len(pair_idx_i)\n    A_ub = np.zeros((m_pairs, n))\n    A_ub[np.arange(m_pairs), pair_idx_i] = 1.0\n    A_ub[np.arange(m_pairs), pair_idx_j] = 1.0\n\n    # Solve LP\n    lp_res = linprog(c=c_obj, A_ub=A_ub, b_ub=b_ub, bounds=var_bounds, method='highs', options={'presolve': True})\n    if lp_res.success:\n        r = lp_res.x\n    else:\n        # Fallback feasible construction:\n        # Choose radii as min(r_upper, half minimum pairwise distance)\n        # Compute min pairwise distances matrix\n        dmat = np.linalg.norm(c[:, None, :] - c[None, :, :], axis=2)\n        # set diag to large\n        np.fill_diagonal(dmat, 1.0)\n        min_pairwise = np.min(dmat)\n        # if min_pairwise very small, use tiny radius\n        if min_pairwise <= 2e-6:\n            fallback_radius = np.minimum(r_upper, 5e-4)\n            r = fallback_radius\n        else:\n            r_uniform = 0.5 * min_pairwise - 1e-6\n            r = np.minimum(r_upper, r_uniform * np.ones_like(r_upper))\n        # ensure non-negative\n        r = np.maximum(r, 0.0)\n\n    # Final sanity check and slight adjustments if needed to ensure strict feasiblity\n    # Recompute pairwise conditions; if violated slightly due to numerics, reduce radii locally.\n    dists_pairs = np.linalg.norm(c[pair_idx_i] - c[pair_idx_j], axis=1)\n    violations = (r[pair_idx_i] + r[pair_idx_j]) - (dists_pairs - 1e-6)\n    if np.any(violations > 1e-12):\n        # reduce radii proportionally for violating pairs\n        for k, viol in enumerate(violations):\n            if viol > 1e-12:\n                i = pair_idx_i[k]\n                j = pair_idx_j[k]\n                total = r[i] + r[j]\n                if total > 0:\n                    # scale down both to satisfy r_i + r_j <= d_ij - 1e-6\n                    target = max(0.0, dists_pairs[k] - 1e-6)\n                    scale = target / total\n                    r[i] *= scale\n                    r[j] *= scale\n\n    # Also ensure radii within boundary constraints\n    r = np.minimum(r, r_upper)\n    r = np.maximum(r, 0.0)\n\n    # Final feasibility check\n    # inside square already enforced by r <= x,y,1-x,1-y\n    # check pairwise non-overlap with tolerance 1e-6\n    final_pairwise_dists = np.linalg.norm(c[pair_idx_i] - c[pair_idx_j], axis=1)\n    final_viol = (r[pair_idx_i] + r[pair_idx_j]) - (final_pairwise_dists - 1e-6)\n    if np.any(final_viol > 1e-9):\n        # As final fallback, shrink all radii slightly to ensure feasibility\n        shrink = 0.999\n        r *= shrink\n        # recheck; if still violation, set to very small radii\n        final_pairwise_dists = np.linalg.norm(c[pair_idx_i] - c[pair_idx_j], axis=1)\n        final_viol = (r[pair_idx_i] + r[pair_idx_j]) - (final_pairwise_dists - 1e-6)\n        if np.any(final_viol > 1e-9):\n            r = np.minimum(r, 1e-4)\n\n    sum_r = float(np.sum(r))\n\n    centers_out = np.asarray(c, dtype=float)\n    radii_out = np.asarray(r, dtype=float)\n    return centers_out, radii_out, sum_r\n\n# Optional testing helper (does not print)\ndef run_packing():\n    centers, radii, sum_r = construct_packing()\n    # Verify constraints silently by returning boolean status and details\n    n = centers.shape[0]\n    ok = True\n    # inside square\n    if np.any(centers < -1e-12) or np.any(centers > 1.0 + 1e-12):\n        ok = False\n    # radii non-negative\n    if np.any(radii < -1e-12):\n        ok = False\n    # inside square by radius\n    if np.any(radii - centers[:, 0] > 1e-6) or np.any(radii - centers[:, 1] > 1e-6) \\\n       or np.any(radii - (1.0 - centers[:, 0]) > 1e-6) or np.any(radii - (1.0 - centers[:, 1]) > 1e-6):\n        ok = False\n    # pairwise non-overlap\n    idx_i, idx_j = np.triu_indices(n, k=1)\n    dists = np.linalg.norm(centers[idx_i] - centers[idx_j], axis=1)\n    overlap = radii[idx_i] + radii[idx_j] - dists\n    if np.any(overlap > 1e-6):\n        ok = False\n    return {\n        'ok': ok,\n        'n': n,\n        'sum_radii': sum_r,\n        'min_pair_dist': float(np.min(dists)) if dists.size > 0 else 0.0,\n        'max_radius': float(np.max(radii)) if radii.size > 0 else 0.0\n    }",
  "metrics": {
    "valid": false,
    "score": 0.0,
    "eval_time": 0.35619497299194336,
    "error": "ValueError: too many values to unpack (expected 3, got 5)"
  },
  "prompt": "You are writing a single Python file that exposes:\n\n- construct_packing() -> (centers, radii, sum_radii)\n- Optional: run_packing() for internal testing\n\nRequirements:\n- Exactly 26 circles.\n- centers: np.array shape (26,2), radii: np.array shape (26,), sum_radii: float\n- All circles strictly inside [0,1]^2; no overlaps with tolerance 1e-6.\n- Maximize sum(radii).\n- Allowed modules: numpy, scipy only.\n- No prints or extraneous output.\n- Return a strictly feasible packing.\n- Keep runtime <= 300s.\n\nImplementation preferences:\n- Use vectorized NumPy wherever possible.\n- For any smooth penalty, apply eps only to divisions (not to the penalty itself) to avoid bias.\n- Use LP feasibilization at the end to guarantee feasibility and maximize sum of radii:\n  Maximize sum(r) subject to:\n    r_i >= 0\n    r_i <= r_i_current\n    r_i <= x_i, r_i <= y_i, r_i <= 1-x_i, r_i <= 1-y_i\n    r_i + r_j <= dist_ij - 1e-6 for all i<j\n  Solve with scipy.optimize.linprog, using -ones as objective (maximize sum by minimizing -sum).\n- Ensure numerical stability; avoid adding eps into the penalty value (only in denominators).\n- Deterministic seeds for any stochastic components.\n- Output only a single Python code block with the program (no prose).\n\nConstruct a fast constructive approach:\n\nSteps:\n1) Seed 26 centers via a near-hexagonal tiling clipped to [0,1]^2 with slight deterministic jitter and bias placing some centers near edges/corners.\n2) Initialize provisional radii as boundary distances b_i = min(x_i, y_i, 1-x_i, 1-y_i).\n3) Run a Dykstra-like projection on centers to reduce pairwise overlaps using target spacings s_ij = beta*(b_i + b_j):\n   - For each pair (i,j), if d_ij < s_ij, shift c_i and c_j minimally along their line to achieve spacing s_ij (split correction by weights proportional to b_i, b_j).\n   - Sweep pairs cyclically for K passes with annealed beta increasing to 1.05.\n   - Keep centers within [0,1] via clamped corrections.\n   - Fully vectorize distance computations per pass.\n4) After projection, run a brief L-BFGS-B polish on a smooth overlap penalty (eps only in divisions).\n5) Finalize with LP feasibilization to maximize sum(r) and ensure strict feasibility.\n\nKeep it deterministic and efficient.\n",
  "response": "```python\nimport numpy as np\nfrom scipy.optimize import minimize, linprog\n\ndef construct_packing():\n    \"\"\"\n    Construct a packing of 26 non-overlapping circles in the unit square.\n    Returns:\n      centers: np.array (26,2)\n      radii: np.array (26,)\n      sum_radii: float\n    \"\"\"\n    rng = np.random.RandomState(123456)  # deterministic\n\n    n = 26\n\n    # 1) Seed 26 centers via a near-hexagonal tiling clipped to [0,1]^2\n    # Use 5 rows with counts chosen to total 26: [5,6,5,5,5]\n    row_counts = [5, 6, 5, 5, 5]\n    assert sum(row_counts) == n\n    num_rows = len(row_counts)\n    margin = 0.04  # keep away from exact boundary initially\n    ys = np.linspace(margin, 1.0 - margin, num_rows)\n    centers = []\n    for ridx, (y, nx) in enumerate(zip(ys, row_counts)):\n        # x positions\n        if nx > 1:\n            xs = np.linspace(margin, 1.0 - margin, nx)\n        else:\n            xs = np.array([0.5])\n        # apply small row offset for hex-like arrangement\n        if ridx % 2 == 1:\n            # offset xs by half-step but keep inside [margin,1-margin]\n            dx = xs[1] - xs[0] if len(xs) > 1 else 0.05\n            xs = xs + 0.5 * dx\n            # clamp\n            xs = np.clip(xs, margin, 1.0 - margin)\n        for x in xs:\n            centers.append([x, y])\n    centers = np.array(centers[:n], dtype=float)\n\n    # slight deterministic jitter and bias some centers near edges/corners\n    jitter_scale = 0.018\n    centers += (rng.rand(n, 2) - 0.5) * jitter_scale\n\n    # push a few selected indices slightly toward nearest edge/corner to bias edges\n    edge_bias_indices = np.arange(0, min(6, n))\n    for idx in edge_bias_indices:\n        # push outward by up to 0.03 proportionally to position\n        c = centers[idx]\n        # determine direction towards closer edge/corner\n        dx = np.array([0.0, 0.0])\n        # bias in x\n        if c[0] < 0.5:\n            dx[0] -= 0.03 * (0.5 - c[0]) / 0.5\n        else:\n            dx[0] += 0.03 * (c[0] - 0.5) / 0.5\n        # bias in y\n        if c[1] < 0.5:\n            dx[1] -= 0.03 * (0.5 - c[1]) / 0.5\n        else:\n            dx[1] += 0.03 * (c[1] - 0.5) / 0.5\n        centers[idx] = np.clip(c + dx, 0.0, 1.0)\n\n    centers = np.clip(centers, 0.0, 1.0)\n\n    # 2) Initialize provisional radii as boundary distances b_i\n    def boundary_distance(pt):\n        return min(pt[0], pt[1], 1.0 - pt[0], 1.0 - pt[1])\n\n    b = np.minimum.reduce([centers[:, 0], centers[:, 1], 1.0 - centers[:, 0], 1.0 - centers[:, 1]])\n    # ensure positive minimal margin\n    b = np.maximum(b, 1e-3)\n\n    # 3) Dykstra-like projection to reduce overlaps\n    # Pairwise operations vectorized\n    K = 240  # passes\n    beta_start = 0.45\n    beta_end = 1.05\n    relax = 0.65  # relaxation factor for applying corrections\n\n    # Precompute pair index arrays for i<j\n    idx_i, idx_j = np.triu_indices(n, k=1)\n\n    # For deterministic random directions when distance is zero\n    # Create deterministic pseudo-random unit vectors for each pair\n    pair_rng = np.random.RandomState(424242)\n    rand_dirs = pair_rng.randn(len(idx_i), 2)\n    rand_norms = np.linalg.norm(rand_dirs, axis=1, keepdims=True)\n    rand_dirs = rand_dirs / np.maximum(rand_norms, 1e-12)\n\n    # Run passes\n    c = centers.copy()\n    b_vec = b.copy()\n    for it in range(K):\n        beta = beta_start + (beta_end - beta_start) * (it / max(1, K - 1))\n        # compute pairwise diffs and distances\n        # diff from i to j\n        diffs = c[idx_i] - c[idx_j]  # (m,2)\n        dists = np.linalg.norm(diffs, axis=1)\n        # desired spacing\n        s = beta * (b_vec[idx_i] + b_vec[idx_j])\n        deficits = s - dists\n        mask = deficits > 1e-12\n        if not np.any(mask):\n            # nothing to correct this pass\n            continue\n        # unit vectors, handling zero distances\n        u = np.zeros_like(diffs)\n        nz = dists > 1e-12\n        u[nz] = diffs[nz] / dists[nz][:, None]\n        u[~nz] = rand_dirs[~nz]\n        # movement magnitudes for i and j (split by weights proportional to b_i, b_j)\n        bi = b_vec[idx_i]\n        bj = b_vec[idx_j]\n        denom = bi + bj\n        # avoid zero denom (shouldn't happen due to min b constraint)\n        denom = np.maximum(denom, 1e-12)\n        # movement assignments such that movement_i + movement_j = deficits\n        move_i_mag = (bj / denom) * deficits\n        move_j_mag = (bi / denom) * deficits\n        # Only apply for masked pairs\n        move_i_mag = move_i_mag * mask\n        move_j_mag = move_j_mag * mask\n        u_masked = u * mask[:, None]\n\n        # Accumulate corrections\n        corr = np.zeros_like(c)\n        # For i indices add u * move_i_mag\n        np.add.at(corr, idx_i, u_masked * move_i_mag[:, None])\n        # For j indices subtract u * move_j_mag\n        np.add.at(corr, idx_j, -u_masked * move_j_mag[:, None])\n\n        # Apply relaxation and update\n        c += relax * corr\n\n        # Keep centers within [0,1]\n        c = np.clip(c, 0.0, 1.0)\n\n        # Update boundary distances? The algorithm requested using initial b_i but it's fine to keep b_vec constant.\n\n    # After projection, recompute boundary distances\n    b_current = np.minimum.reduce([c[:, 0], c[:, 1], 1.0 - c[:, 0], 1.0 - c[:, 1]])\n    b_current = np.maximum(b_current, 1e-6)\n\n    # Small perturbation to break any exact collisions (deterministic)\n    min_pair = np.inf\n    diffs_full = c[:, None, :] - c[None, :, :]\n    dists_full = np.linalg.norm(diffs_full + np.eye(n)[:, :, None], axis=2)  # add diag offset to avoid zero\n    # compute true pairwise distances\n    true_dists = np.linalg.norm(c[idx_i] - c[idx_j], axis=1)\n    if np.any(true_dists < 1e-8):\n        # perturb slightly\n        perturb = (pair_rng.randn(n, 2) * 1e-5)\n        c = np.clip(c + perturb, 0.0, 1.0)\n        b_current = np.minimum.reduce([c[:, 0], c[:, 1], 1.0 - c[:, 0], 1.0 - c[:, 1]])\n        b_current = np.maximum(b_current, 1e-6)\n\n    # 4) L-BFGS-B polish on smooth overlap penalty\n    eps = 1e-8\n\n    # target spacing s_ij uses boundary distances b_current (we want distances >= b_i + b_j)\n    bi = b_current.copy()\n\n    pair_idx_i = idx_i\n    pair_idx_j = idx_j\n\n    def penalty_obj(flat_c):\n        cmat = flat_c.reshape((n, 2))\n        diffs = cmat[pair_idx_i] - cmat[pair_idx_j]\n        d = np.linalg.norm(diffs, axis=1)\n        s = bi[pair_idx_i] + bi[pair_idx_j]\n        gaps = s - d  # positive if overlap\n        pos = np.maximum(0.0, gaps)\n        # penalty: sum(pos^2 / (d + eps))\n        val = np.sum((pos * pos) / (d + eps))\n        return val\n\n    x0 = c.ravel()\n    bounds = [(0.0, 1.0)] * (2 * n)\n    # minimize penalty\n    res = minimize(penalty_obj, x0, method='L-BFGS-B', bounds=bounds,\n                   options={'maxiter': 200, 'ftol': 1e-9})\n\n    if res.success:\n        c = res.x.reshape((n, 2))\n    else:\n        # if polish fails, keep previous centers\n        c = c\n\n    c = np.clip(c, 0.0, 1.0)\n    # recompute boundary distances\n    b_current = np.minimum.reduce([c[:, 0], c[:, 1], 1.0 - c[:, 0], 1.0 - c[:, 1]])\n    b_current = np.maximum(b_current, 0.0)\n\n    # 5) LP feasibilization to maximize sum(r) subject to constraints\n    # Variables: r_0 ... r_{n-1}\n    # Objective: maximize sum r  -> minimize -sum r\n    c_obj = -np.ones(n)\n\n    # Bounds: 0 <= r_i <= r_i_current (also r_i <= x_i, y_i, ...)\n    # r_i_current as current boundary distances (explicitly include)\n    r_upper = b_current.copy()\n    # also enforce the geometric bounds explicitly (redundant but safe)\n    r_upper = np.minimum(r_upper, c[:, 0])\n    r_upper = np.minimum(r_upper, c[:, 1])\n    r_upper = np.minimum(r_upper, 1.0 - c[:, 0])\n    r_upper = np.minimum(r_upper, 1.0 - c[:, 1])\n    # ensure non-negative\n    r_upper = np.maximum(r_upper, 0.0)\n\n    var_bounds = [(0.0, float(r_upper[i])) for i in range(n)]\n\n    # Pairwise non-overlap constraints: for each pair i<j: r_i + r_j <= dist_ij - 1e-6\n    pairwise_dists = np.linalg.norm(c[pair_idx_i] - c[pair_idx_j], axis=1)\n    eps_margin = 1e-6\n    b_ub = pairwise_dists - eps_margin\n    # If any b_ub < 0, that may make LP infeasible. To be robust, clamp to 0 (will force radii sum <= 0 for that pair)\n    # but better to allow small negative slack by decreasing 1e-6 to zero if necessary. We'll clamp b_ub to >=0\n    # because r_i + r_j >=0 anyways; but we should not allow negative right-hand sides that make problem infeasible.\n    b_ub = np.maximum(b_ub, 0.0)\n\n    # Create A_ub matrix: rows equal number of pairs, columns n\n    m_pairs = len(pair_idx_i)\n    A_ub = np.zeros((m_pairs, n))\n    A_ub[np.arange(m_pairs), pair_idx_i] = 1.0\n    A_ub[np.arange(m_pairs), pair_idx_j] = 1.0\n\n    # Solve LP\n    lp_res = linprog(c=c_obj, A_ub=A_ub, b_ub=b_ub, bounds=var_bounds, method='highs', options={'presolve': True})\n    if lp_res.success:\n        r = lp_res.x\n    else:\n        # Fallback feasible construction:\n        # Choose radii as min(r_upper, half minimum pairwise distance)\n        # Compute min pairwise distances matrix\n        dmat = np.linalg.norm(c[:, None, :] - c[None, :, :], axis=2)\n        # set diag to large\n        np.fill_diagonal(dmat, 1.0)\n        min_pairwise = np.min(dmat)\n        # if min_pairwise very small, use tiny radius\n        if min_pairwise <= 2e-6:\n            fallback_radius = np.minimum(r_upper, 5e-4)\n            r = fallback_radius\n        else:\n            r_uniform = 0.5 * min_pairwise - 1e-6\n            r = np.minimum(r_upper, r_uniform * np.ones_like(r_upper))\n        # ensure non-negative\n        r = np.maximum(r, 0.0)\n\n    # Final sanity check and slight adjustments if needed to ensure strict feasiblity\n    # Recompute pairwise conditions; if violated slightly due to numerics, reduce radii locally.\n    dists_pairs = np.linalg.norm(c[pair_idx_i] - c[pair_idx_j], axis=1)\n    violations = (r[pair_idx_i] + r[pair_idx_j]) - (dists_pairs - 1e-6)\n    if np.any(violations > 1e-12):\n        # reduce radii proportionally for violating pairs\n        for k, viol in enumerate(violations):\n            if viol > 1e-12:\n                i = pair_idx_i[k]\n                j = pair_idx_j[k]\n                total = r[i] + r[j]\n                if total > 0:\n                    # scale down both to satisfy r_i + r_j <= d_ij - 1e-6\n                    target = max(0.0, dists_pairs[k] - 1e-6)\n                    scale = target / total\n                    r[i] *= scale\n                    r[j] *= scale\n\n    # Also ensure radii within boundary constraints\n    r = np.minimum(r, r_upper)\n    r = np.maximum(r, 0.0)\n\n    # Final feasibility check\n    # inside square already enforced by r <= x,y,1-x,1-y\n    # check pairwise non-overlap with tolerance 1e-6\n    final_pairwise_dists = np.linalg.norm(c[pair_idx_i] - c[pair_idx_j], axis=1)\n    final_viol = (r[pair_idx_i] + r[pair_idx_j]) - (final_pairwise_dists - 1e-6)\n    if np.any(final_viol > 1e-9):\n        # As final fallback, shrink all radii slightly to ensure feasibility\n        shrink = 0.999\n        r *= shrink\n        # recheck; if still violation, set to very small radii\n        final_pairwise_dists = np.linalg.norm(c[pair_idx_i] - c[pair_idx_j], axis=1)\n        final_viol = (r[pair_idx_i] + r[pair_idx_j]) - (final_pairwise_dists - 1e-6)\n        if np.any(final_viol > 1e-9):\n            r = np.minimum(r, 1e-4)\n\n    sum_r = float(np.sum(r))\n\n    centers_out = np.asarray(c, dtype=float)\n    radii_out = np.asarray(r, dtype=float)\n    return centers_out, radii_out, sum_r\n\n# Optional testing helper (does not print)\ndef run_packing():\n    centers, radii, sum_r = construct_packing()\n    # Verify constraints silently by returning boolean status and details\n    n = centers.shape[0]\n    ok = True\n    # inside square\n    if np.any(centers < -1e-12) or np.any(centers > 1.0 + 1e-12):\n        ok = False\n    # radii non-negative\n    if np.any(radii < -1e-12):\n        ok = False\n    # inside square by radius\n    if np.any(radii - centers[:, 0] > 1e-6) or np.any(radii - centers[:, 1] > 1e-6) \\\n       or np.any(radii - (1.0 - centers[:, 0]) > 1e-6) or np.any(radii - (1.0 - centers[:, 1]) > 1e-6):\n        ok = False\n    # pairwise non-overlap\n    idx_i, idx_j = np.triu_indices(n, k=1)\n    dists = np.linalg.norm(centers[idx_i] - centers[idx_j], axis=1)\n    overlap = radii[idx_i] + radii[idx_j] - dists\n    if np.any(overlap > 1e-6):\n        ok = False\n    return {\n        'ok': ok,\n        'n': n,\n        'sum_radii': sum_r,\n        'min_pair_dist': float(np.min(dists)) if dists.size > 0 else 0.0,\n        'max_radius': float(np.max(radii)) if radii.size > 0 else 0.0\n    }\n```",
  "reasoning": "",
  "timestamp": "2026-02-11T01:46:27.388068",
  "cost_data": null,
  "model_config": {
    "model": "openai/gpt-5-mini",
    "temperature": 0.4
  },
  "llm_call_duration_s": 113.51148230396211,
  "eval_duration_s": 0.35620065790135413
}