{
  "trial_id": "trial_17_5",
  "generation": 17,
  "parent_id": null,
  "code": "import numpy as np\nfrom scipy.spatial import distance_matrix\nfrom scipy.optimize import linprog\n\ndef construct_packing():\n    np.random.seed(12345)\n    N = 26\n    eps_margin = 1e-6  # required separation margin in LP\n    denom_eps = 1e-12  # stabilization for divisions\n    softmin_beta = 60.0  # for smooth clamp to boundary\n    softplus_shift = 1e-6  # shift inside softplus for margins: softplus(d - shift)\n    softplus = lambda x: np.log1p(np.exp(x))\n    sigmoid = lambda x: 1.0 / (1.0 + np.exp(-x))\n    relu = lambda x: np.maximum(0.0, x)\n\n    # kNN neighbors to consider in surrogate penalties\n    k_neighbors = 8\n\n    # Adam-like optimizer parameters\n    lr = 0.03\n    beta1 = 0.9\n    beta2 = 0.999\n    adam_eps = 1e-8\n\n    # Outer alternations and inner gradient steps\n    outer_rounds = 6\n    inner_steps = 60\n\n    # Seeds: grid-like, hex-like, edge-biased, corner-biased with jitter\n    seeds = []\n\n    # grid-ish\n    gx = np.linspace(0.08, 0.92, 6)\n    gy = np.linspace(0.1, 0.9, 5)\n    pts = np.array([[x, y] for y in gy for x in gx])\n    if pts.shape[0] >= N:\n        seeds.append(pts[:N] + (np.random.rand(N,2)-0.5)*0.01)\n\n    # hex-like arrangement\n    pts = []\n    rows = [5,4,5,4,5,3]  # some rows\n    y = 0.06\n    for rcount in rows:\n        xs = np.linspace(0.06, 0.94, rcount)\n        for i,x in enumerate(xs):\n            pts.append([x + (0.02 if (len(pts)%2==0) else -0.02), y])\n        y += 0.16\n    pts = np.array(pts)\n    if pts.shape[0] >= N:\n        seeds.append(pts[:N] + (np.random.rand(N,2)-0.5)*0.02)\n\n    # edge-biased: many near boundary\n    pts = np.random.rand(N,2)*0.5\n    pts[:8,0] = np.random.rand(8)*0.02 + 0.01  # left edge cluster\n    pts[8:14,1] = np.random.rand(6)*0.02 + 0.01  # bottom edge cluster\n    pts[14:,0] = 0.9 + np.random.rand(N-14)*0.09\n    seeds.append(np.clip(pts, 0.01, 0.99))\n\n    # corner-biased\n    pts = np.random.rand(N,2)*0.25\n    pts[:10] += np.array([0.0,0.0])\n    pts[10:18] += np.array([0.75,0.0])\n    pts[18:] += np.array([0.0,0.75])\n    seeds.append(np.clip(pts + (np.random.rand(N,2)-0.5)*0.01, 0.01, 0.99))\n\n    # Ensure we have some seeds\n    if len(seeds) == 0:\n        seeds = [np.random.rand(N,2)*0.9 + 0.05]\n\n    # utility functions for surrogate and gradients\n    def softmin_vals(vals):\n        # vals: shape (N,4)\n        w = np.exp(-softmin_beta * vals)  # shape (N,4)\n        W = np.sum(w, axis=1, keepdims=True)  # (N,1)\n        b = np.sum(vals * w, axis=1, keepdims=True) / W  # (N,1)\n        return b.ravel(), w, W.ravel()\n\n    def compute_b_and_grad(centers):\n        # centers: (N,2)\n        x = centers[:,0]\n        y = centers[:,1]\n        # vals = [x, y, 1-x, 1-y]\n        vals = np.stack([x, y, 1.0 - x, 1.0 - y], axis=1)  # (N,4)\n        b, w, W = softmin_vals(vals)  # b (N,), w (N,4), W (N,)\n        # compute db/dx and db/dy\n        # db/dx = sum_j ( (w_j * dv_j/dx) * W - sum(vals*w)*dW/dx ) / W^2\n        # where dW/dx = sum_j dw_j/dx = sum_j (-beta * w_j * dv_j/dx)\n        # dv_j/dx = [1,0,-1,0] for j=0..3\n        dv_dx = np.array([1.0, 0.0, -1.0, 0.0])\n        dv_dy = np.array([0.0, 1.0, 0.0, -1.0])\n        # w shape (N,4)\n        dW_dx = -softmin_beta * np.sum(w * dv_dx[np.newaxis,:], axis=1)  # (N,)\n        dW_dy = -softmin_beta * np.sum(w * dv_dy[np.newaxis,:], axis=1)\n        VW = np.sum(vals * w, axis=1)  # (N,)\n        # numerator for db/dx: sum_j (w_j * dv_j/dx * W) - VW * dW_dx\n        num_dx = np.sum(w * dv_dx[np.newaxis,:], axis=1) * W - VW * dW_dx\n        num_dy = np.sum(w * dv_dy[np.newaxis,:], axis=1) * W - VW * dW_dy\n        denom = W * W\n        db_dx = num_dx / denom\n        db_dy = num_dy / denom\n        db = np.stack([db_dx, db_dy], axis=1)  # (N,2)\n        return b, db\n\n    def pairwise_soft_margins_and_grad(centers):\n        # compute pairwise distances d_ij and gradient of m_ij wrt centers\n        x = centers[:,0][:,None]\n        y = centers[:,1][:,None]\n        dx = x - x.T  # (N,N)\n        dy = y - y.T\n        d2 = dx*dx + dy*dy\n        d = np.sqrt(d2 + 0.0)  # avoid adding eps here; use denom eps only later\n        # softplus argument\n        arg = d - softplus_shift\n        m = softplus(arg)  # (N,N), symmetric, m_ii = softplus(-eps) ~ small\n        # derivative dm/dd = sigmoid(arg)\n        sm = sigmoid(arg)\n        # dd/dxi = (xi - xj) / d_safe\n        denom = d + denom_eps  # only in division\n        dd_dx = dx / denom\n        dd_dy = dy / denom\n        # dm/dxi = sm * dd_dx\n        dm_dx = sm * dd_dx\n        dm_dy = sm * dd_dy\n        # For pair (i,j), derivative wrt center i is above; wrt center j is negative of that\n        return m, dm_dx, dm_dy, d\n\n    # Surrogate loss and gradient w.r.t centers\n    def surrogate_loss_and_grad(centers, rho, neighbor_idx):\n        # centers (N,2)\n        b, db = compute_b_and_grad(centers)  # b (N,), db (N,2)\n        m, dm_dx, dm_dy, d = pairwise_soft_margins_and_grad(centers)\n        # Build neighbor pairs unique (i<j)\n        Nloc = centers.shape[0]\n        # objective: -sum b_i + rho * (boundary_pen + overlap_pen)\n        obj = -np.sum(b)\n        # boundary penalty: penalize centers outside [0,1] via relu(-x), relu(x-1)\n        bx_neg = relu(-centers[:,0])\n        bx_pos = relu(centers[:,0] - 1.0)\n        by_neg = relu(-centers[:,1])\n        by_pos = relu(centers[:,1] - 1.0)\n        boundary_pen = np.sum(bx_neg*bx_neg + bx_pos*bx_pos + by_neg*by_neg + by_pos*by_pos)\n        obj += rho * boundary_pen\n        # overlap penalties over neighbor pairs\n        overlap_pen = 0.0\n        grad = np.zeros_like(centers)\n        # baseline gradient from -sum b\n        grad -= db  # d(-sum b)/dcenter\n\n        # boundary grad contributions:\n        # derivative of relu(t)^2 is 2*relu(t)*I[t>0] * dt/dcenter\n        # dt/dx for bx_neg = -1 when x<0\n        mask = bx_neg > 0\n        if np.any(mask):\n            dterm = 2.0 * bx_neg[mask] * (-1.0)\n            grad[mask,0] += rho * dterm\n        mask = bx_pos > 0\n        if np.any(mask):\n            dterm = 2.0 * bx_pos[mask] * (1.0)\n            grad[mask,0] += rho * dterm\n        mask = by_neg > 0\n        if np.any(mask):\n            dterm = 2.0 * by_neg[mask] * (-1.0)\n            grad[mask,1] += rho * dterm\n        mask = by_pos > 0\n        if np.any(mask):\n            dterm = 2.0 * by_pos[mask] * (1.0)\n            grad[mask,1] += rho * dterm\n\n        # overlap: for each i, consider its neighbor indices\n        for i in range(Nloc):\n            bi = b[i]\n            dbi = db[i]  # (2,)\n            neighbors = neighbor_idx[i]\n            for j in neighbors:\n                if j <= i:\n                    continue\n                bj = b[j]\n                dbj = db[j]\n                mij = m[i,j]\n                # s = (bi + bj) - mij\n                s = (bi + bj) - mij\n                if s <= 0.0:\n                    continue\n                overlap_pen += s*s\n                # derivative: d( s^2 )/dcenter_k = 2*s * (d(bi)/dck + d(bj)/dck - d(mij)/dck)\n                # For center i: dbi - dm/dcenter_i\n                # dm/dcenter_i = [dm_dx_ij, dm_dy_ij] (since dm_dx is xi-xj / denom * sigmoid)\n                dmij_dx = dm_dx[i,j]\n                dmij_dy = dm_dy[i,j]\n                # For center i:\n                grad[i,0] += rho * 2.0 * s * (dbi[0] - dmij_dx)\n                grad[i,1] += rho * 2.0 * s * (dbi[1] - dmij_dy)\n                # For center j:\n                # d(mij)/dcenter_j = -dmij_dx, -dmij_dy (since derivative of distance wrt xj is -dx/denom)\n                grad[j,0] += rho * 2.0 * s * (dbj[0] + dmij_dx)\n                grad[j,1] += rho * 2.0 * s * (dbj[1] + dmij_dy)\n                # obj will include rho*overlap_pen later\n\n        obj += rho * overlap_pen\n        return obj, grad\n\n    # Helper: build neighbor list from centers using pairwise distances\n    def build_neighbor_idx(centers, k=k_neighbors):\n        D = distance_matrix(centers, centers)\n        # for each i, exclude self and take k nearest\n        neighbor_idx = []\n        for i in range(centers.shape[0]):\n            order = np.argsort(D[i])\n            # skip first which is i\n            neigh = order[1:1+k]\n            neighbor_idx.append(neigh)\n        return neighbor_idx\n\n    # LP solve given centers: maximize sum r s.t. r_i >=0, r_i <= x_i,y_i,1-x_i,1-y_i and r_i + r_j <= d_ij - eps_margin\n    def run_lp_for_centers(centers, initial_cap=None):\n        # centers clipped inside [0,1]\n        centers = np.clip(centers, 0.0, 1.0)\n        Nloc = centers.shape[0]\n        x = centers[:,0]\n        y = centers[:,1]\n        D = distance_matrix(centers, centers)\n        # Build A_ub and b_ub\n        rows = []\n        rhs = []\n        # pairwise constraints\n        for i in range(Nloc):\n            for j in range(i+1, Nloc):\n                rij = np.zeros(Nloc)\n                rij[i] = 1.0\n                rij[j] = 1.0\n                rows.append(rij)\n                rhs.append(D[i,j] - eps_margin)\n        # boundary constraints r_i <= x_i, y_i, 1-x_i, 1-y_i\n        for i in range(Nloc):\n            basis = np.zeros(Nloc)\n            basis[i] = 1.0\n            # r_i <= x_i\n            rows.append(basis.copy()); rhs.append(x[i])\n            rows.append(basis.copy()); rhs.append(y[i])\n            rows.append(basis.copy()); rhs.append(1.0 - x[i])\n            rows.append(basis.copy()); rhs.append(1.0 - y[i])\n        A_ub = np.array(rows, dtype=np.float64)\n        b_ub = np.array(rhs, dtype=np.float64)\n        c = -np.ones(Nloc, dtype=np.float64)\n        bounds = [(0.0, None) for _ in range(Nloc)]\n        # Optionally add upper bound based on initial_cap to help feasibility\n        if initial_cap is not None:\n            for i in range(Nloc):\n                ub = initial_cap[i]\n                if ub is not None and ub >= 0.0:\n                    bounds[i] = (0.0, float(max(0.0, ub)))\n        # Solve LP using HiGHS\n        res = linprog(c, A_ub=A_ub, b_ub=b_ub, bounds=bounds, method='highs', options={'presolve': True})\n        if not res.success:\n            # try with tightened bounds (slightly smaller caps) if initial caps provided\n            if initial_cap is not None:\n                new_bounds = []\n                for i in range(Nloc):\n                    ub = initial_cap[i]\n                    if ub is None:\n                        new_bounds.append((0.0, None))\n                    else:\n                        new_bounds.append((0.0, float(max(0.0, ub * 0.999999))))\n                res = linprog(c, A_ub=A_ub, b_ub=b_ub, bounds=new_bounds, method='highs', options={'presolve': True})\n        if not res.success:\n            return None  # infeasible or failed\n        r = res.x\n        # Numerical stabilization: ensure constraints satisfied, else shrink slightly\n        # Verify feasibility\n        feas = True\n        # boundary\n        if np.any(r < -1e-12):\n            feas = False\n        if np.any(r < 0.0):\n            r = np.maximum(0.0, r)\n        for i in range(Nloc):\n            if r[i] - x[i] > 1e-9 or r[i] - y[i] > 1e-9 or r[i] - (1.0 - x[i]) > 1e-9 or r[i] - (1.0 - y[i]) > 1e-9:\n                feas = False\n        for i in range(Nloc):\n            for j in range(i+1, Nloc):\n                if r[i] + r[j] - (D[i,j] - eps_margin) > 1e-10:\n                    feas = False\n        if not feas:\n            # shrink slightly and recheck\n            r = r * (1.0 - 2e-7)\n            # final check\n            ok = True\n            for i in range(Nloc):\n                for j in range(i+1, Nloc):\n                    if r[i] + r[j] - (D[i,j] - eps_margin) > 1e-9:\n                        ok = False\n                        break\n                if not ok:\n                    break\n            if not ok:\n                return None\n        return r\n\n    best_sum = -1.0\n    best_centers = None\n    best_radii = None\n\n    # Main loop over seeds\n    for seed_idx, seed_centers in enumerate(seeds):\n        centers = np.array(seed_centers, dtype=np.float64).copy()\n        # initial small jitter and clip\n        centers = np.clip(centers + (np.random.rand(N,2)-0.5)*0.01, 1e-6, 1.0-1e-6)\n        # Initialize Adam moments\n        m = np.zeros_like(centers)\n        v = np.zeros_like(centers)\n        t = 0\n        # initial neighbor idx\n        neighbor_idx = build_neighbor_idx(centers, k=k_neighbors)\n        # alternating schedule: rho increases\n        for round_i in range(outer_rounds):\n            rho = 1.0 + (200.0 - 1.0) * (round_i / max(1.0, outer_rounds - 1.0))\n            # inner gradient steps\n            for step in range(inner_steps):\n                t += 1\n                # update neighbor idx occasionally to reflect center moves\n                if step % 8 == 0:\n                    neighbor_idx = build_neighbor_idx(centers, k=k_neighbors)\n                loss, grad = surrogate_loss_and_grad(centers, rho, neighbor_idx)\n                # Adam update\n                m = beta1 * m + (1.0 - beta1) * grad\n                v = beta2 * v + (1.0 - beta2) * (grad * grad)\n                m_hat = m / (1.0 - beta1 ** t)\n                v_hat = v / (1.0 - beta2 ** t)\n                step_update = lr * m_hat / (np.sqrt(v_hat) + adam_eps)\n                centers -= step_update\n                # softly clamp centers into [0,1] via reflection with small factor to avoid hard clipping\n                centers = np.clip(centers, 0.0, 1.0)\n            # After inner steps, run exact LP on current centers to get true radii\n            centers_clipped = np.clip(centers, 0.0, 1.0)\n            # Create initial cap from smooth b (border caps)\n            bvals, _ = compute_b_and_grad(centers_clipped)\n            initial_cap = np.maximum(0.0, bvals)  # allow LP to choose smaller\n            # try LP without using initial caps first (let LP use boundary constraints)\n            r_lp = run_lp_for_centers(centers_clipped, initial_cap=None)\n            if r_lp is None:\n                # try with caps to help feasibility\n                r_lp = run_lp_for_centers(centers_clipped, initial_cap=initial_cap)\n            if r_lp is not None:\n                sumr = float(np.sum(r_lp))\n                if sumr > best_sum + 1e-15:\n                    best_sum = sumr\n                    best_centers = centers_clipped.copy()\n                    best_radii = r_lp.copy()\n            # small random perturbation to escape plateaus\n            centers += (np.random.rand(*centers.shape)-0.5) * 1e-4\n\n    # Finalize: run LP on best_centers found\n    if best_centers is None:\n        # fallback: run LP on last centers\n        candidates = seeds[0]\n        best_centers = np.clip(candidates, 0.0, 1.0)\n    final_centers = np.clip(best_centers, 0.0, 1.0)\n    # Run LP without caps\n    final_r = run_lp_for_centers(final_centers, initial_cap=None)\n    if final_r is None:\n        # try with boundary caps\n        bvals, _ = compute_b_and_grad(final_centers)\n        final_r = run_lp_for_centers(final_centers, initial_cap=np.maximum(0.0, bvals))\n    if final_r is None:\n        # As last resort, try small shrink of centers and retry\n        final_centers = np.clip(final_centers, 1e-6, 1.0 - 1e-6)\n        bvals, _ = compute_b_and_grad(final_centers)\n        final_r = run_lp_for_centers(final_centers, initial_cap=np.maximum(0.0, bvals*0.9999))\n    if final_r is None:\n        # if still infeasible, produce tiny radii\n        final_r = np.zeros(N, dtype=np.float64)\n\n    # Final numeric feasibility adjustment\n    final_centers = np.clip(final_centers, 0.0, 1.0)\n    final_r = np.maximum(final_r, 0.0)\n    Dfinal = distance_matrix(final_centers, final_centers)\n    ok = True\n    for i in range(N):\n        # boundary checks\n        if final_r[i] - final_centers[i,0] > 1e-9 or final_r[i] - final_centers[i,1] > 1e-9 \\\n           or final_r[i] - (1.0 - final_centers[i,0]) > 1e-9 or final_r[i] - (1.0 - final_centers[i,1]) > 1e-9:\n            ok = False\n            break\n    for i in range(N):\n        for j in range(i+1, N):\n            if final_r[i] + final_r[j] - (Dfinal[i,j] - eps_margin) > 1e-9:\n                ok = False\n                break\n        if not ok:\n            break\n    if not ok:\n        final_r = final_r * (1.0 - 2e-7)\n\n    final_sum = float(np.sum(final_r))\n\n    centers_out = np.array(final_centers, dtype=np.float64).reshape((N,2))\n    radii_out = np.array(final_r, dtype=np.float64).reshape((N,))\n\n    return centers_out, radii_out, final_sum\n\n# If run as a module, expose construct_packing\nif __name__ == \"__main__\":\n    c, r, s = construct_packing()",
  "metrics": {
    "valid": true,
    "score": 0.9157484504952731,
    "eval_time": 0.6706194877624512,
    "error": null
  },
  "prompt": "\nImplement alternating optimization where LP defines target radii but centers are updated via a smooth surrogate of LP:\n- Define soft pairwise margins m_ij = softplus(d_ij - 1e-6) and soft boundary caps b_i = min(x_i,y_i,1-x_i,1-y_i) via smooth clamp.\n- Surrogate objective ~ sum soft_r_i with constraints r_i <= b_i and r_i + r_j <= m_ij using smooth penalties; analytically differentiate w.r.t centers.\n- Alternate: 50-80 gradient steps (Adam-like or L-BFGS-B) on centers using surrogate; then run exact LP to get true radii; keep best centers by LP sum.\n- Use kNN neighbor subset in surrogate to reduce noise. Eps only in divisions. Finalize with LP.\n\n\nRequirements:\n- Output a single Python code block, no prose.\n- Allowed modules: numpy, scipy only.\n- Provide a function construct_packing() returning (centers, radii, sum_radii).\n- Shapes: centers (26,2), radii (26,).\n- All circles strictly inside [0,1]^2 and pairwise non-overlapping, tolerance 1e-6.\n- Maximize sum(radii); use a final LP feasibilization to ensure strict feasibility:\n  Max sum r s.t. 0 <= r_i, r_i <= min(current_r_i, x_i, y_i, 1-x_i, 1-y_i),\n  and r_i + r_j <= dist_ij - 1e-6 for all i<j. Use scipy.optimize.linprog (HiGHS).\n- Gradient stabilization: apply eps only in divisions (do not bias penalties).\n- Keep runtime <= 300s. No printing. Deterministic seed ok.\n- Return the best strictly feasible solution found.\n\n\nLP details:\n- Objective: maximize sum r -> minimize c^T r with c = -1.\n- Bounds: (0, None) or (0, current_r_i) but ensure boundary caps r_i <= x_i, y_i, 1-x_i, 1-y_i via A_ub.\n- Pairwise constraints: r_i + r_j <= ||c_i - c_j|| - 1e-6 for all pairs.\n- Use method='highs'; check success; if infeasible due to tight margins, reduce radii bound slightly and retry.\n\n\nFeasibility check:\n- After LP, verify: all 0<=r_i, r_i <= margins; for all i<j: r_i+r_j <= dist_ij - 1e-6 - 1e-12 slack; centers in [0,1].\n- If any violation (numerical), shrink radii slightly (factor 1 - 2e-7) and recheck.\n\n\nPenalty model for centers+radii (when used):\n- Smooth hinge for boundary: phi(t)=relu(-t) with squared penalty; gradients w.r.t x,y,r vectorized.\n- Overlap penalty: for each pair i<j, s_ij = (r_i + r_j) - d_ij; penalize relu(s_ij)^2.\n- Distances stabilized using d_ij_safe = sqrt(d2 + eps2) with eps only in denominator when normalizing.\n- Use annealed weights: rho in [1.0, 200.0] staged, and optionally density-weighted scaling per-circle via k-NN.\n\n\nSeeding:\n- Provide multiple starts: triangular/hex-like rows near edges and interior, plus jitter.\n- Include an edge-biased seed and a corner-biased seed.\n- Keep radii initial guesses moderate; LP will adjust.\n\n\nFinalize:\n- Always run LP on the best candidate centers with generous current_r caps (or infinity); let LP bound by geometry.\n- Return centers, radii, sum(radii). Ensure numpy arrays with correct shapes and dtype=float64.\n\n",
  "response": "```python\nimport numpy as np\nfrom scipy.spatial import distance_matrix\nfrom scipy.optimize import linprog\n\ndef construct_packing():\n    np.random.seed(12345)\n    N = 26\n    eps_margin = 1e-6  # required separation margin in LP\n    denom_eps = 1e-12  # stabilization for divisions\n    softmin_beta = 60.0  # for smooth clamp to boundary\n    softplus_shift = 1e-6  # shift inside softplus for margins: softplus(d - shift)\n    softplus = lambda x: np.log1p(np.exp(x))\n    sigmoid = lambda x: 1.0 / (1.0 + np.exp(-x))\n    relu = lambda x: np.maximum(0.0, x)\n\n    # kNN neighbors to consider in surrogate penalties\n    k_neighbors = 8\n\n    # Adam-like optimizer parameters\n    lr = 0.03\n    beta1 = 0.9\n    beta2 = 0.999\n    adam_eps = 1e-8\n\n    # Outer alternations and inner gradient steps\n    outer_rounds = 6\n    inner_steps = 60\n\n    # Seeds: grid-like, hex-like, edge-biased, corner-biased with jitter\n    seeds = []\n\n    # grid-ish\n    gx = np.linspace(0.08, 0.92, 6)\n    gy = np.linspace(0.1, 0.9, 5)\n    pts = np.array([[x, y] for y in gy for x in gx])\n    if pts.shape[0] >= N:\n        seeds.append(pts[:N] + (np.random.rand(N,2)-0.5)*0.01)\n\n    # hex-like arrangement\n    pts = []\n    rows = [5,4,5,4,5,3]  # some rows\n    y = 0.06\n    for rcount in rows:\n        xs = np.linspace(0.06, 0.94, rcount)\n        for i,x in enumerate(xs):\n            pts.append([x + (0.02 if (len(pts)%2==0) else -0.02), y])\n        y += 0.16\n    pts = np.array(pts)\n    if pts.shape[0] >= N:\n        seeds.append(pts[:N] + (np.random.rand(N,2)-0.5)*0.02)\n\n    # edge-biased: many near boundary\n    pts = np.random.rand(N,2)*0.5\n    pts[:8,0] = np.random.rand(8)*0.02 + 0.01  # left edge cluster\n    pts[8:14,1] = np.random.rand(6)*0.02 + 0.01  # bottom edge cluster\n    pts[14:,0] = 0.9 + np.random.rand(N-14)*0.09\n    seeds.append(np.clip(pts, 0.01, 0.99))\n\n    # corner-biased\n    pts = np.random.rand(N,2)*0.25\n    pts[:10] += np.array([0.0,0.0])\n    pts[10:18] += np.array([0.75,0.0])\n    pts[18:] += np.array([0.0,0.75])\n    seeds.append(np.clip(pts + (np.random.rand(N,2)-0.5)*0.01, 0.01, 0.99))\n\n    # Ensure we have some seeds\n    if len(seeds) == 0:\n        seeds = [np.random.rand(N,2)*0.9 + 0.05]\n\n    # utility functions for surrogate and gradients\n    def softmin_vals(vals):\n        # vals: shape (N,4)\n        w = np.exp(-softmin_beta * vals)  # shape (N,4)\n        W = np.sum(w, axis=1, keepdims=True)  # (N,1)\n        b = np.sum(vals * w, axis=1, keepdims=True) / W  # (N,1)\n        return b.ravel(), w, W.ravel()\n\n    def compute_b_and_grad(centers):\n        # centers: (N,2)\n        x = centers[:,0]\n        y = centers[:,1]\n        # vals = [x, y, 1-x, 1-y]\n        vals = np.stack([x, y, 1.0 - x, 1.0 - y], axis=1)  # (N,4)\n        b, w, W = softmin_vals(vals)  # b (N,), w (N,4), W (N,)\n        # compute db/dx and db/dy\n        # db/dx = sum_j ( (w_j * dv_j/dx) * W - sum(vals*w)*dW/dx ) / W^2\n        # where dW/dx = sum_j dw_j/dx = sum_j (-beta * w_j * dv_j/dx)\n        # dv_j/dx = [1,0,-1,0] for j=0..3\n        dv_dx = np.array([1.0, 0.0, -1.0, 0.0])\n        dv_dy = np.array([0.0, 1.0, 0.0, -1.0])\n        # w shape (N,4)\n        dW_dx = -softmin_beta * np.sum(w * dv_dx[np.newaxis,:], axis=1)  # (N,)\n        dW_dy = -softmin_beta * np.sum(w * dv_dy[np.newaxis,:], axis=1)\n        VW = np.sum(vals * w, axis=1)  # (N,)\n        # numerator for db/dx: sum_j (w_j * dv_j/dx * W) - VW * dW_dx\n        num_dx = np.sum(w * dv_dx[np.newaxis,:], axis=1) * W - VW * dW_dx\n        num_dy = np.sum(w * dv_dy[np.newaxis,:], axis=1) * W - VW * dW_dy\n        denom = W * W\n        db_dx = num_dx / denom\n        db_dy = num_dy / denom\n        db = np.stack([db_dx, db_dy], axis=1)  # (N,2)\n        return b, db\n\n    def pairwise_soft_margins_and_grad(centers):\n        # compute pairwise distances d_ij and gradient of m_ij wrt centers\n        x = centers[:,0][:,None]\n        y = centers[:,1][:,None]\n        dx = x - x.T  # (N,N)\n        dy = y - y.T\n        d2 = dx*dx + dy*dy\n        d = np.sqrt(d2 + 0.0)  # avoid adding eps here; use denom eps only later\n        # softplus argument\n        arg = d - softplus_shift\n        m = softplus(arg)  # (N,N), symmetric, m_ii = softplus(-eps) ~ small\n        # derivative dm/dd = sigmoid(arg)\n        sm = sigmoid(arg)\n        # dd/dxi = (xi - xj) / d_safe\n        denom = d + denom_eps  # only in division\n        dd_dx = dx / denom\n        dd_dy = dy / denom\n        # dm/dxi = sm * dd_dx\n        dm_dx = sm * dd_dx\n        dm_dy = sm * dd_dy\n        # For pair (i,j), derivative wrt center i is above; wrt center j is negative of that\n        return m, dm_dx, dm_dy, d\n\n    # Surrogate loss and gradient w.r.t centers\n    def surrogate_loss_and_grad(centers, rho, neighbor_idx):\n        # centers (N,2)\n        b, db = compute_b_and_grad(centers)  # b (N,), db (N,2)\n        m, dm_dx, dm_dy, d = pairwise_soft_margins_and_grad(centers)\n        # Build neighbor pairs unique (i<j)\n        Nloc = centers.shape[0]\n        # objective: -sum b_i + rho * (boundary_pen + overlap_pen)\n        obj = -np.sum(b)\n        # boundary penalty: penalize centers outside [0,1] via relu(-x), relu(x-1)\n        bx_neg = relu(-centers[:,0])\n        bx_pos = relu(centers[:,0] - 1.0)\n        by_neg = relu(-centers[:,1])\n        by_pos = relu(centers[:,1] - 1.0)\n        boundary_pen = np.sum(bx_neg*bx_neg + bx_pos*bx_pos + by_neg*by_neg + by_pos*by_pos)\n        obj += rho * boundary_pen\n        # overlap penalties over neighbor pairs\n        overlap_pen = 0.0\n        grad = np.zeros_like(centers)\n        # baseline gradient from -sum b\n        grad -= db  # d(-sum b)/dcenter\n\n        # boundary grad contributions:\n        # derivative of relu(t)^2 is 2*relu(t)*I[t>0] * dt/dcenter\n        # dt/dx for bx_neg = -1 when x<0\n        mask = bx_neg > 0\n        if np.any(mask):\n            dterm = 2.0 * bx_neg[mask] * (-1.0)\n            grad[mask,0] += rho * dterm\n        mask = bx_pos > 0\n        if np.any(mask):\n            dterm = 2.0 * bx_pos[mask] * (1.0)\n            grad[mask,0] += rho * dterm\n        mask = by_neg > 0\n        if np.any(mask):\n            dterm = 2.0 * by_neg[mask] * (-1.0)\n            grad[mask,1] += rho * dterm\n        mask = by_pos > 0\n        if np.any(mask):\n            dterm = 2.0 * by_pos[mask] * (1.0)\n            grad[mask,1] += rho * dterm\n\n        # overlap: for each i, consider its neighbor indices\n        for i in range(Nloc):\n            bi = b[i]\n            dbi = db[i]  # (2,)\n            neighbors = neighbor_idx[i]\n            for j in neighbors:\n                if j <= i:\n                    continue\n                bj = b[j]\n                dbj = db[j]\n                mij = m[i,j]\n                # s = (bi + bj) - mij\n                s = (bi + bj) - mij\n                if s <= 0.0:\n                    continue\n                overlap_pen += s*s\n                # derivative: d( s^2 )/dcenter_k = 2*s * (d(bi)/dck + d(bj)/dck - d(mij)/dck)\n                # For center i: dbi - dm/dcenter_i\n                # dm/dcenter_i = [dm_dx_ij, dm_dy_ij] (since dm_dx is xi-xj / denom * sigmoid)\n                dmij_dx = dm_dx[i,j]\n                dmij_dy = dm_dy[i,j]\n                # For center i:\n                grad[i,0] += rho * 2.0 * s * (dbi[0] - dmij_dx)\n                grad[i,1] += rho * 2.0 * s * (dbi[1] - dmij_dy)\n                # For center j:\n                # d(mij)/dcenter_j = -dmij_dx, -dmij_dy (since derivative of distance wrt xj is -dx/denom)\n                grad[j,0] += rho * 2.0 * s * (dbj[0] + dmij_dx)\n                grad[j,1] += rho * 2.0 * s * (dbj[1] + dmij_dy)\n                # obj will include rho*overlap_pen later\n\n        obj += rho * overlap_pen\n        return obj, grad\n\n    # Helper: build neighbor list from centers using pairwise distances\n    def build_neighbor_idx(centers, k=k_neighbors):\n        D = distance_matrix(centers, centers)\n        # for each i, exclude self and take k nearest\n        neighbor_idx = []\n        for i in range(centers.shape[0]):\n            order = np.argsort(D[i])\n            # skip first which is i\n            neigh = order[1:1+k]\n            neighbor_idx.append(neigh)\n        return neighbor_idx\n\n    # LP solve given centers: maximize sum r s.t. r_i >=0, r_i <= x_i,y_i,1-x_i,1-y_i and r_i + r_j <= d_ij - eps_margin\n    def run_lp_for_centers(centers, initial_cap=None):\n        # centers clipped inside [0,1]\n        centers = np.clip(centers, 0.0, 1.0)\n        Nloc = centers.shape[0]\n        x = centers[:,0]\n        y = centers[:,1]\n        D = distance_matrix(centers, centers)\n        # Build A_ub and b_ub\n        rows = []\n        rhs = []\n        # pairwise constraints\n        for i in range(Nloc):\n            for j in range(i+1, Nloc):\n                rij = np.zeros(Nloc)\n                rij[i] = 1.0\n                rij[j] = 1.0\n                rows.append(rij)\n                rhs.append(D[i,j] - eps_margin)\n        # boundary constraints r_i <= x_i, y_i, 1-x_i, 1-y_i\n        for i in range(Nloc):\n            basis = np.zeros(Nloc)\n            basis[i] = 1.0\n            # r_i <= x_i\n            rows.append(basis.copy()); rhs.append(x[i])\n            rows.append(basis.copy()); rhs.append(y[i])\n            rows.append(basis.copy()); rhs.append(1.0 - x[i])\n            rows.append(basis.copy()); rhs.append(1.0 - y[i])\n        A_ub = np.array(rows, dtype=np.float64)\n        b_ub = np.array(rhs, dtype=np.float64)\n        c = -np.ones(Nloc, dtype=np.float64)\n        bounds = [(0.0, None) for _ in range(Nloc)]\n        # Optionally add upper bound based on initial_cap to help feasibility\n        if initial_cap is not None:\n            for i in range(Nloc):\n                ub = initial_cap[i]\n                if ub is not None and ub >= 0.0:\n                    bounds[i] = (0.0, float(max(0.0, ub)))\n        # Solve LP using HiGHS\n        res = linprog(c, A_ub=A_ub, b_ub=b_ub, bounds=bounds, method='highs', options={'presolve': True})\n        if not res.success:\n            # try with tightened bounds (slightly smaller caps) if initial caps provided\n            if initial_cap is not None:\n                new_bounds = []\n                for i in range(Nloc):\n                    ub = initial_cap[i]\n                    if ub is None:\n                        new_bounds.append((0.0, None))\n                    else:\n                        new_bounds.append((0.0, float(max(0.0, ub * 0.999999))))\n                res = linprog(c, A_ub=A_ub, b_ub=b_ub, bounds=new_bounds, method='highs', options={'presolve': True})\n        if not res.success:\n            return None  # infeasible or failed\n        r = res.x\n        # Numerical stabilization: ensure constraints satisfied, else shrink slightly\n        # Verify feasibility\n        feas = True\n        # boundary\n        if np.any(r < -1e-12):\n            feas = False\n        if np.any(r < 0.0):\n            r = np.maximum(0.0, r)\n        for i in range(Nloc):\n            if r[i] - x[i] > 1e-9 or r[i] - y[i] > 1e-9 or r[i] - (1.0 - x[i]) > 1e-9 or r[i] - (1.0 - y[i]) > 1e-9:\n                feas = False\n        for i in range(Nloc):\n            for j in range(i+1, Nloc):\n                if r[i] + r[j] - (D[i,j] - eps_margin) > 1e-10:\n                    feas = False\n        if not feas:\n            # shrink slightly and recheck\n            r = r * (1.0 - 2e-7)\n            # final check\n            ok = True\n            for i in range(Nloc):\n                for j in range(i+1, Nloc):\n                    if r[i] + r[j] - (D[i,j] - eps_margin) > 1e-9:\n                        ok = False\n                        break\n                if not ok:\n                    break\n            if not ok:\n                return None\n        return r\n\n    best_sum = -1.0\n    best_centers = None\n    best_radii = None\n\n    # Main loop over seeds\n    for seed_idx, seed_centers in enumerate(seeds):\n        centers = np.array(seed_centers, dtype=np.float64).copy()\n        # initial small jitter and clip\n        centers = np.clip(centers + (np.random.rand(N,2)-0.5)*0.01, 1e-6, 1.0-1e-6)\n        # Initialize Adam moments\n        m = np.zeros_like(centers)\n        v = np.zeros_like(centers)\n        t = 0\n        # initial neighbor idx\n        neighbor_idx = build_neighbor_idx(centers, k=k_neighbors)\n        # alternating schedule: rho increases\n        for round_i in range(outer_rounds):\n            rho = 1.0 + (200.0 - 1.0) * (round_i / max(1.0, outer_rounds - 1.0))\n            # inner gradient steps\n            for step in range(inner_steps):\n                t += 1\n                # update neighbor idx occasionally to reflect center moves\n                if step % 8 == 0:\n                    neighbor_idx = build_neighbor_idx(centers, k=k_neighbors)\n                loss, grad = surrogate_loss_and_grad(centers, rho, neighbor_idx)\n                # Adam update\n                m = beta1 * m + (1.0 - beta1) * grad\n                v = beta2 * v + (1.0 - beta2) * (grad * grad)\n                m_hat = m / (1.0 - beta1 ** t)\n                v_hat = v / (1.0 - beta2 ** t)\n                step_update = lr * m_hat / (np.sqrt(v_hat) + adam_eps)\n                centers -= step_update\n                # softly clamp centers into [0,1] via reflection with small factor to avoid hard clipping\n                centers = np.clip(centers, 0.0, 1.0)\n            # After inner steps, run exact LP on current centers to get true radii\n            centers_clipped = np.clip(centers, 0.0, 1.0)\n            # Create initial cap from smooth b (border caps)\n            bvals, _ = compute_b_and_grad(centers_clipped)\n            initial_cap = np.maximum(0.0, bvals)  # allow LP to choose smaller\n            # try LP without using initial caps first (let LP use boundary constraints)\n            r_lp = run_lp_for_centers(centers_clipped, initial_cap=None)\n            if r_lp is None:\n                # try with caps to help feasibility\n                r_lp = run_lp_for_centers(centers_clipped, initial_cap=initial_cap)\n            if r_lp is not None:\n                sumr = float(np.sum(r_lp))\n                if sumr > best_sum + 1e-15:\n                    best_sum = sumr\n                    best_centers = centers_clipped.copy()\n                    best_radii = r_lp.copy()\n            # small random perturbation to escape plateaus\n            centers += (np.random.rand(*centers.shape)-0.5) * 1e-4\n\n    # Finalize: run LP on best_centers found\n    if best_centers is None:\n        # fallback: run LP on last centers\n        candidates = seeds[0]\n        best_centers = np.clip(candidates, 0.0, 1.0)\n    final_centers = np.clip(best_centers, 0.0, 1.0)\n    # Run LP without caps\n    final_r = run_lp_for_centers(final_centers, initial_cap=None)\n    if final_r is None:\n        # try with boundary caps\n        bvals, _ = compute_b_and_grad(final_centers)\n        final_r = run_lp_for_centers(final_centers, initial_cap=np.maximum(0.0, bvals))\n    if final_r is None:\n        # As last resort, try small shrink of centers and retry\n        final_centers = np.clip(final_centers, 1e-6, 1.0 - 1e-6)\n        bvals, _ = compute_b_and_grad(final_centers)\n        final_r = run_lp_for_centers(final_centers, initial_cap=np.maximum(0.0, bvals*0.9999))\n    if final_r is None:\n        # if still infeasible, produce tiny radii\n        final_r = np.zeros(N, dtype=np.float64)\n\n    # Final numeric feasibility adjustment\n    final_centers = np.clip(final_centers, 0.0, 1.0)\n    final_r = np.maximum(final_r, 0.0)\n    Dfinal = distance_matrix(final_centers, final_centers)\n    ok = True\n    for i in range(N):\n        # boundary checks\n        if final_r[i] - final_centers[i,0] > 1e-9 or final_r[i] - final_centers[i,1] > 1e-9 \\\n           or final_r[i] - (1.0 - final_centers[i,0]) > 1e-9 or final_r[i] - (1.0 - final_centers[i,1]) > 1e-9:\n            ok = False\n            break\n    for i in range(N):\n        for j in range(i+1, N):\n            if final_r[i] + final_r[j] - (Dfinal[i,j] - eps_margin) > 1e-9:\n                ok = False\n                break\n        if not ok:\n            break\n    if not ok:\n        final_r = final_r * (1.0 - 2e-7)\n\n    final_sum = float(np.sum(final_r))\n\n    centers_out = np.array(final_centers, dtype=np.float64).reshape((N,2))\n    radii_out = np.array(final_r, dtype=np.float64).reshape((N,))\n\n    return centers_out, radii_out, final_sum\n\n# If run as a module, expose construct_packing\nif __name__ == \"__main__\":\n    c, r, s = construct_packing()\n```",
  "reasoning": "",
  "timestamp": "2026-02-11T03:29:12.023042",
  "cost_data": null,
  "model_config": {
    "model": "openai/gpt-5-mini",
    "temperature": 0.3
  },
  "llm_call_duration_s": 107.94431342696771,
  "eval_duration_s": 0.6706254839664325
}