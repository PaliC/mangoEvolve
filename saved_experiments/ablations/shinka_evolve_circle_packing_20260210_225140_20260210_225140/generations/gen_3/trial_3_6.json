{
  "trial_id": "trial_3_6",
  "generation": 3,
  "parent_id": null,
  "code": "import numpy as np\nfrom scipy.optimize import linprog\n\ndef _pair_indices(n):\n    I, J = np.triu_indices(n, k=1)\n    return I.astype(np.int32), J.astype(np.int32)\n\ndef _solve_lp_radii(X, tol=1e-6, r_cap=None):\n    # Maximize sum(r) subject to:\n    # 0 <= r_i <= r_cap_i\n    # r_i <= x_i, r_i <= y_i, r_i <= 1-x_i, r_i <= 1-y_i\n    # r_i + r_j <= dist_ij - tol for all i<j\n    n = X.shape[0]\n    x = X[:, 0]\n    y = X[:, 1]\n\n    # Objective: minimize -sum(r)\n    c = -np.ones(n, dtype=np.float64)\n\n    # Boundary constraints (4n rows)\n    A_rows = []\n    b_vals = []\n\n    # r_i <= x_i\n    A_rows.append(np.eye(n))\n    b_vals.append(x.copy())\n    # r_i <= y_i\n    A_rows.append(np.eye(n))\n    b_vals.append(y.copy())\n    # r_i <= 1 - x_i\n    A_rows.append(np.eye(n))\n    b_vals.append(1.0 - x)\n    # r_i <= 1 - y_i\n    A_rows.append(np.eye(n))\n    b_vals.append(1.0 - y)\n\n    # Pairwise non-overlap constraints\n    I, J = _pair_indices(n)\n    d = np.linalg.norm(X[I] - X[J], axis=1)\n    m = I.shape[0]\n    A_pairs = np.zeros((m, n), dtype=np.float64)\n    A_pairs[np.arange(m), I] = 1.0\n    A_pairs[np.arange(m), J] = 1.0\n    b_pairs = d - tol\n\n    A_ub = np.vstack(A_rows + [A_pairs])\n    b_ub = np.concatenate(b_vals + [b_pairs])\n\n    # Bounds [0, r_cap]\n    if r_cap is None:\n        # Provide generous cap; boundary constraints already limit r\n        r_cap = np.ones(n, dtype=np.float64)\n    bounds = [(0.0, float(r_cap[i])) for i in range(n)]\n\n    res = linprog(c, A_ub=A_ub, b_ub=b_ub, bounds=bounds, method=\"highs\")\n    if not res.success or res.x is None:\n        # Fallback: zeros (always feasible)\n        r = np.zeros(n, dtype=np.float64)\n        return r, 0.0\n    r = res.x\n    return r, float(r.sum())\n\ndef _hex_init_26(jitter=0.01, rng=None):\n    # 6 hex rows with counts summing to 26\n    # Row counts pattern: 5,4,5,4,5,3\n    row_counts = [5, 4, 5, 4, 5, 3]\n    rows = len(row_counts)\n    maxc = max(row_counts)\n\n    dy = 1.0 / (rows + 1)\n    dx = 1.0 / (maxc + 1)\n\n    pts = []\n    for k, c in enumerate(row_counts):\n        y = (k + 1) * dy\n        # Alternate horizontal offset for hex staggering\n        offset = dx * 0.5 if (k % 2 == 1) else 0.0\n        # Center the row horizontally\n        start = (1.0 - (c - 1) * dx) * 0.5\n        start = max(start, dx)  # keep margin\n        xs = start + offset + dx * np.arange(c)\n        xs = np.clip(xs, 0.0 + 2e-3, 1.0 - 2e-3)\n        yv = np.full(c, y)\n        pts.append(np.stack([xs, yv], axis=1))\n    X = np.concatenate(pts, axis=0)\n    if X.shape[0] != 26:\n        # In the unlikely event of mismatch, fall back to random uniform\n        if rng is None:\n            rng = np.random.default_rng()\n        X = rng.uniform(0.1, 0.9, size=(26, 2))\n    if rng is None:\n        rng = np.random.default_rng()\n    X += rng.uniform(-jitter, jitter, size=X.shape)\n    X = np.clip(X, 0.0, 1.0)\n    return X\n\ndef _augmented_penalty_step(X, r, y, rho, pairs, tol, aug_margin, step_max=0.02):\n    # Compute gradient of augmented penalty on overlaps and take a step on X\n    I, J = pairs\n    delta = X[I] - X[J]\n    d = np.linalg.norm(delta, axis=1)\n    denom = np.maximum(d, 1e-12)\n\n    # Overlap violation with a small inflation margin to induce motion on tight pairs\n    v = (r[I] + r[J] + aug_margin) - d + tol\n    mask = v > 0.0\n    if not np.any(mask):\n        return X.copy(), y.copy(), 0.0\n\n    v_active = v[mask]\n    I_a = I[mask]\n    J_a = J[mask]\n    delta_a = delta[mask]\n    denom_a = denom[mask]\n\n    # Weight w = y + rho*v\n    w = y[mask] + rho * v_active\n    # Direction component (delta / d)\n    dir_ij = delta_a / denom_a[:, None]\n\n    # Gradient accumulation\n    grad = np.zeros_like(X)\n    contrib = w[:, None] * dir_ij\n    # For i: subtract; for j: add (because dv/dX_i = -(X_i - X_j)/d)\n    np.add.at(grad, I_a, -contrib)\n    np.add.at(grad, J_a, +contrib)\n\n    # Scale step to cap max movement per coordinate\n    gnorm = np.linalg.norm(grad, axis=1)\n    gmax = float(np.max(gnorm))\n    if gmax <= 1e-16:\n        return X.copy(), y.copy(), 0.0\n    step = min(step_max, step_max * (1.0 / gmax))\n\n    X_new = X - step * grad\n    X_new = np.clip(X_new, 0.0, 1.0)\n\n    # Dual update: y = max(0, y + rho * v)\n    y_new = y.copy()\n    y_new[mask] = np.maximum(0.0, y[mask] + rho * v_active)\n\n    # Return X_new, y_new, and max violation (for diagnostics)\n    return X_new, y_new, float(np.max(v_active))\n\ndef construct_packing():\n    rng = np.random.default_rng(12345)\n    n = 26\n    tol = 1e-6\n\n    # Initialize centers on a hex grid with slight jitter\n    X = _hex_init_26(jitter=0.01, rng=rng)\n\n    # Pair indices\n    I, J = _pair_indices(n)\n    m = I.shape[0]\n    pairs = (I, J)\n\n    # Dual variables for each pairwise constraint\n    y = np.zeros(m, dtype=np.float64)\n\n    # Outer loop parameters\n    outer_iters = 18\n    inner_steps = 5\n    rho = 50.0\n    rho_factor = 1.6\n\n    # Augmented margin schedule to create force at active/tight pairs\n    aug_margin0 = 5e-3\n    aug_decay = 0.75\n\n    best_sum = -np.inf\n    best_X = X.copy()\n    best_r = np.zeros(n, dtype=np.float64)\n\n    # Main optimization\n    aug_margin = aug_margin0\n    for it in range(outer_iters):\n        # 1) Solve LP for radii given current centers\n        r, s = _solve_lp_radii(X, tol=tol)\n        # Record best feasible LP solution so far\n        if s > best_sum + 1e-12:\n            best_sum = s\n            best_X = X.copy()\n            best_r = r.copy()\n\n        # 2-3) A few gradient steps on centers to minimize augmented penalty (overlaps)\n        for _ in range(inner_steps):\n            X, y, _ = _augmented_penalty_step(\n                X, r, y, rho, pairs, tol=tol, aug_margin=aug_margin, step_max=0.02\n            )\n\n        # Project just in case\n        X = np.clip(X, 0.0, 1.0)\n\n        # Anneal parameters\n        rho = min(rho * rho_factor, 5e5)\n        aug_margin *= aug_decay\n\n        # Optionally, a quick LP after movement to update the incumbent\n        r_tmp, s_tmp = _solve_lp_radii(X, tol=tol)\n        if s_tmp > best_sum + 1e-12:\n            best_sum = s_tmp\n            best_X = X.copy()\n            best_r = r_tmp.copy()\n\n    # Final strict LP feasibilization on the best centers found\n    # Use generous caps (1.0); boundary constraints already enforced in LP\n    r_final, s_final = _solve_lp_radii(best_X, tol=tol, r_cap=np.ones(n, dtype=np.float64))\n\n    centers = best_X.astype(np.float64)\n    radii = r_final.astype(np.float64)\n    sum_radii = float(np.sum(radii))\n\n    return centers, radii, sum_radii",
  "metrics": {
    "valid": true,
    "score": 2.3038154353212654,
    "eval_time": 0.40337276458740234,
    "error": null
  },
  "prompt": "\nImplement a primal-dual style scheme:\n- Variables: centers X; radii are solved exactly by LP each iteration.\n- Introduce overlap slacks s_ij >= 0 for constraints r_i + r_j <= d_ij - tol + s_ij.\n- Augmented Lagrangian penalizes sum(s_ij) with rho/2 ||s||^2 + y^T s; eliminate s in closed form to yield a smooth penalty on overlaps.\n- Alternate:\n  1) Given X, solve LP for r (no slacks; slacks appear only in the augmented term for X).\n  2) Take a gradient step on X to minimize augmented penalty from pairwise overlaps using distances from current X and LP radii.\n  3) Update duals y_ij (clipped >=0).\n  4) Project X into [0,1]^2.\n- Anneal rho upward; 10-20 outer iterations; within each, a few center steps.\n- Start from hex grid + jitter.\n- Return best LP-feasible solution.\n\nVectorize all pairwise ops; avoid bias by adding eps only in denominators.\n\n\nRequirements:\n- Implement construct_packing() that returns (centers, radii, sum_radii).\n- centers: np.array shape (26, 2), radii: np.array shape (26,), sum_radii: float.\n- Use only numpy and scipy.\n- Exactly 26 circles; all inside [0,1]^2; no overlaps (tolerance 1e-6); radii >= 0.\n- Runtime <= 300s; no prints.\n- Use a linear program (scipy.optimize.linprog) for final feasibilization to strictly satisfy constraints:\n  maximize sum(r) subject to:\n    0 <= r_i <= r_cap_i\n    r_i <= x_i, r_i <= y_i, r_i <= 1-x_i, r_i <= 1-y_i\n    r_i + r_j <= dist_ij - 1e-6 for all i<j\n  where r_cap_i are current candidate radii (upper bounds) and dist_ij are pairwise distances.\n  Implement as minimizing -sum(r).\n- Provide robust, vectorized computations; avoid numerical bias (apply eps only to denominators).\n- Return the strictly feasible LP output.\n\nProvide construct_packing() and helpers.\n",
  "response": "```python\nimport numpy as np\nfrom scipy.optimize import linprog\n\ndef _pair_indices(n):\n    I, J = np.triu_indices(n, k=1)\n    return I.astype(np.int32), J.astype(np.int32)\n\ndef _solve_lp_radii(X, tol=1e-6, r_cap=None):\n    # Maximize sum(r) subject to:\n    # 0 <= r_i <= r_cap_i\n    # r_i <= x_i, r_i <= y_i, r_i <= 1-x_i, r_i <= 1-y_i\n    # r_i + r_j <= dist_ij - tol for all i<j\n    n = X.shape[0]\n    x = X[:, 0]\n    y = X[:, 1]\n\n    # Objective: minimize -sum(r)\n    c = -np.ones(n, dtype=np.float64)\n\n    # Boundary constraints (4n rows)\n    A_rows = []\n    b_vals = []\n\n    # r_i <= x_i\n    A_rows.append(np.eye(n))\n    b_vals.append(x.copy())\n    # r_i <= y_i\n    A_rows.append(np.eye(n))\n    b_vals.append(y.copy())\n    # r_i <= 1 - x_i\n    A_rows.append(np.eye(n))\n    b_vals.append(1.0 - x)\n    # r_i <= 1 - y_i\n    A_rows.append(np.eye(n))\n    b_vals.append(1.0 - y)\n\n    # Pairwise non-overlap constraints\n    I, J = _pair_indices(n)\n    d = np.linalg.norm(X[I] - X[J], axis=1)\n    m = I.shape[0]\n    A_pairs = np.zeros((m, n), dtype=np.float64)\n    A_pairs[np.arange(m), I] = 1.0\n    A_pairs[np.arange(m), J] = 1.0\n    b_pairs = d - tol\n\n    A_ub = np.vstack(A_rows + [A_pairs])\n    b_ub = np.concatenate(b_vals + [b_pairs])\n\n    # Bounds [0, r_cap]\n    if r_cap is None:\n        # Provide generous cap; boundary constraints already limit r\n        r_cap = np.ones(n, dtype=np.float64)\n    bounds = [(0.0, float(r_cap[i])) for i in range(n)]\n\n    res = linprog(c, A_ub=A_ub, b_ub=b_ub, bounds=bounds, method=\"highs\")\n    if not res.success or res.x is None:\n        # Fallback: zeros (always feasible)\n        r = np.zeros(n, dtype=np.float64)\n        return r, 0.0\n    r = res.x\n    return r, float(r.sum())\n\ndef _hex_init_26(jitter=0.01, rng=None):\n    # 6 hex rows with counts summing to 26\n    # Row counts pattern: 5,4,5,4,5,3\n    row_counts = [5, 4, 5, 4, 5, 3]\n    rows = len(row_counts)\n    maxc = max(row_counts)\n\n    dy = 1.0 / (rows + 1)\n    dx = 1.0 / (maxc + 1)\n\n    pts = []\n    for k, c in enumerate(row_counts):\n        y = (k + 1) * dy\n        # Alternate horizontal offset for hex staggering\n        offset = dx * 0.5 if (k % 2 == 1) else 0.0\n        # Center the row horizontally\n        start = (1.0 - (c - 1) * dx) * 0.5\n        start = max(start, dx)  # keep margin\n        xs = start + offset + dx * np.arange(c)\n        xs = np.clip(xs, 0.0 + 2e-3, 1.0 - 2e-3)\n        yv = np.full(c, y)\n        pts.append(np.stack([xs, yv], axis=1))\n    X = np.concatenate(pts, axis=0)\n    if X.shape[0] != 26:\n        # In the unlikely event of mismatch, fall back to random uniform\n        if rng is None:\n            rng = np.random.default_rng()\n        X = rng.uniform(0.1, 0.9, size=(26, 2))\n    if rng is None:\n        rng = np.random.default_rng()\n    X += rng.uniform(-jitter, jitter, size=X.shape)\n    X = np.clip(X, 0.0, 1.0)\n    return X\n\ndef _augmented_penalty_step(X, r, y, rho, pairs, tol, aug_margin, step_max=0.02):\n    # Compute gradient of augmented penalty on overlaps and take a step on X\n    I, J = pairs\n    delta = X[I] - X[J]\n    d = np.linalg.norm(delta, axis=1)\n    denom = np.maximum(d, 1e-12)\n\n    # Overlap violation with a small inflation margin to induce motion on tight pairs\n    v = (r[I] + r[J] + aug_margin) - d + tol\n    mask = v > 0.0\n    if not np.any(mask):\n        return X.copy(), y.copy(), 0.0\n\n    v_active = v[mask]\n    I_a = I[mask]\n    J_a = J[mask]\n    delta_a = delta[mask]\n    denom_a = denom[mask]\n\n    # Weight w = y + rho*v\n    w = y[mask] + rho * v_active\n    # Direction component (delta / d)\n    dir_ij = delta_a / denom_a[:, None]\n\n    # Gradient accumulation\n    grad = np.zeros_like(X)\n    contrib = w[:, None] * dir_ij\n    # For i: subtract; for j: add (because dv/dX_i = -(X_i - X_j)/d)\n    np.add.at(grad, I_a, -contrib)\n    np.add.at(grad, J_a, +contrib)\n\n    # Scale step to cap max movement per coordinate\n    gnorm = np.linalg.norm(grad, axis=1)\n    gmax = float(np.max(gnorm))\n    if gmax <= 1e-16:\n        return X.copy(), y.copy(), 0.0\n    step = min(step_max, step_max * (1.0 / gmax))\n\n    X_new = X - step * grad\n    X_new = np.clip(X_new, 0.0, 1.0)\n\n    # Dual update: y = max(0, y + rho * v)\n    y_new = y.copy()\n    y_new[mask] = np.maximum(0.0, y[mask] + rho * v_active)\n\n    # Return X_new, y_new, and max violation (for diagnostics)\n    return X_new, y_new, float(np.max(v_active))\n\ndef construct_packing():\n    rng = np.random.default_rng(12345)\n    n = 26\n    tol = 1e-6\n\n    # Initialize centers on a hex grid with slight jitter\n    X = _hex_init_26(jitter=0.01, rng=rng)\n\n    # Pair indices\n    I, J = _pair_indices(n)\n    m = I.shape[0]\n    pairs = (I, J)\n\n    # Dual variables for each pairwise constraint\n    y = np.zeros(m, dtype=np.float64)\n\n    # Outer loop parameters\n    outer_iters = 18\n    inner_steps = 5\n    rho = 50.0\n    rho_factor = 1.6\n\n    # Augmented margin schedule to create force at active/tight pairs\n    aug_margin0 = 5e-3\n    aug_decay = 0.75\n\n    best_sum = -np.inf\n    best_X = X.copy()\n    best_r = np.zeros(n, dtype=np.float64)\n\n    # Main optimization\n    aug_margin = aug_margin0\n    for it in range(outer_iters):\n        # 1) Solve LP for radii given current centers\n        r, s = _solve_lp_radii(X, tol=tol)\n        # Record best feasible LP solution so far\n        if s > best_sum + 1e-12:\n            best_sum = s\n            best_X = X.copy()\n            best_r = r.copy()\n\n        # 2-3) A few gradient steps on centers to minimize augmented penalty (overlaps)\n        for _ in range(inner_steps):\n            X, y, _ = _augmented_penalty_step(\n                X, r, y, rho, pairs, tol=tol, aug_margin=aug_margin, step_max=0.02\n            )\n\n        # Project just in case\n        X = np.clip(X, 0.0, 1.0)\n\n        # Anneal parameters\n        rho = min(rho * rho_factor, 5e5)\n        aug_margin *= aug_decay\n\n        # Optionally, a quick LP after movement to update the incumbent\n        r_tmp, s_tmp = _solve_lp_radii(X, tol=tol)\n        if s_tmp > best_sum + 1e-12:\n            best_sum = s_tmp\n            best_X = X.copy()\n            best_r = r_tmp.copy()\n\n    # Final strict LP feasibilization on the best centers found\n    # Use generous caps (1.0); boundary constraints already enforced in LP\n    r_final, s_final = _solve_lp_radii(best_X, tol=tol, r_cap=np.ones(n, dtype=np.float64))\n\n    centers = best_X.astype(np.float64)\n    radii = r_final.astype(np.float64)\n    sum_radii = float(np.sum(radii))\n\n    return centers, radii, sum_radii\n```",
  "reasoning": "",
  "timestamp": "2026-02-11T01:12:25.594752",
  "cost_data": null,
  "model_config": {
    "model": "openai/gpt-5",
    "temperature": 0.5
  },
  "llm_call_duration_s": 182.64405735803302,
  "eval_duration_s": 0.403378427028656
}