{
  "trial_id": "trial_0_2",
  "generation": 0,
  "parent_id": null,
  "code": "import numpy as np\nfrom scipy.optimize import minimize, linprog\nfrom scipy.spatial.distance import pdist, squareform\n\n# Global constants\nNUM_CIRCLES = 26\n# Tolerance for non-overlap and boundary in the non-linear optimization\n# This is added to the radii sum in penalties: r_i + r_j - dist_ij + OPT_EPS\nOPT_EPS = 1e-6 \n# Tolerance for LP constraints: r_i + r_j <= dist_ij - LP_EPS\nLP_EPS = 1e-6 \n# Tolerance for final validation checks\nVALIDATION_EPS = 1e-6 \n# Small scaling factor if validation fails due to numerical precision\nSCALING_FACTOR_ON_VIOLATION = 1 - 5e-7 \n\ndef _get_centers_radii(z):\n    \"\"\"Converts the flat optimization vector z to (centers, radii).\"\"\"\n    centers = z[:NUM_CIRCLES*2].reshape(NUM_CIRCLES, 2)\n    radii = z[NUM_CIRCLES*2:]\n    return centers, radii\n\ndef _get_z(centers, radii):\n    \"\"\"Converts (centers, radii) to the flat optimization vector z.\"\"\"\n    return np.concatenate([centers.flatten(), radii])\n\ndef _compute_distances(centers):\n    \"\"\"Computes pairwise distances between centers.\"\"\"\n    return squareform(pdist(centers))\n\ndef _objective_and_gradient(z, w):\n    \"\"\"\n    Calculates the penalized objective function and its gradient.\n    f(z) = -sum(r) + w * P(z)\n    P(z) = sum(boundary_penalties) + sum(overlap_penalties)\n    \"\"\"\n    centers, radii = _get_centers_radii(z)\n\n    # Initialize objective and gradient\n    objective = -np.sum(radii)\n    grad_z = np.zeros_like(z)\n    grad_centers = grad_z[:NUM_CIRCLES*2].reshape(NUM_CIRCLES, 2)\n    grad_radii = grad_z[NUM_CIRCLES*2:]\n\n    # --- Boundary Penalties ---\n    # Penalties are max(0, r - x_i), max(0, r - y_i), max(0, r - (1-x_i)), max(0, r - (1-y_i))\n    # Gradients are 1 for r, -1 for x/y, 1 for x/y respectively when active.\n\n    # r - x_i\n    violations_rx = radii - centers[:, 0]\n    active_rx = violations_rx > 0\n    objective += w * np.sum(violations_rx[active_rx])\n    grad_radii[active_rx] += w\n    grad_centers[active_rx, 0] -= w\n\n    # r - y_i\n    violations_ry = radii - centers[:, 1]\n    active_ry = violations_ry > 0\n    objective += w * np.sum(violations_ry[active_ry])\n    grad_radii[active_ry] += w\n    grad_centers[active_ry, 1] -= w\n\n    # r - (1 - x_i)\n    violations_r1mx = radii - (1 - centers[:, 0])\n    active_r1mx = violations_r1mx > 0\n    objective += w * np.sum(violations_r1mx[active_r1mx])\n    grad_radii[active_r1mx] += w\n    grad_centers[active_r1mx, 0] += w \n\n    # r - (1 - y_i)\n    violations_r1my = radii - (1 - centers[:, 1])\n    active_r1my = violations_r1my > 0\n    objective += w * np.sum(violations_r1my[active_r1my])\n    grad_radii[active_r1my] += w\n    grad_centers[active_r1my, 1] += w \n\n    # --- Overlap Penalties ---\n    # Penalty: max(0, r_i + r_j - ||c_i - c_j|| + OPT_EPS)\n    # Use upper triangle to avoid double counting\n\n    # Compute pairwise distances\n    diff_centers = centers[:, np.newaxis, :] - centers[np.newaxis, :, :] # (N, N, 2)\n    dist_sq = np.sum(diff_centers**2, axis=2) # (N, N)\n    # Add a small epsilon to dist_sq before sqrt to prevent division by zero in gradient\n    distances = np.sqrt(dist_sq + 1e-12) \n\n    # Only consider upper triangle for unique pairs\n    triu_indices = np.triu_indices(NUM_CIRCLES, k=1)\n    \n    # Calculate desired minimum distance (sum of radii + OPT_EPS)\n    sum_radii_pairs = radii[triu_indices[0]] + radii[triu_indices[1]]\n    \n    # Actual distances for these pairs\n    actual_distances_pairs = distances[triu_indices]\n\n    # Violations: (r_i + r_j) - dist_ij + OPT_EPS\n    violations_overlap = sum_radii_pairs - actual_distances_pairs + OPT_EPS\n    active_overlap = violations_overlap > 0\n\n    objective += w * np.sum(violations_overlap[active_overlap])\n\n    # Gradients for overlap penalties\n    if np.any(active_overlap):\n        # Indices of active pairs\n        i_active = triu_indices[0][active_overlap]\n        j_active = triu_indices[1][active_overlap]\n\n        # Gradient w.r.t. radii\n        grad_radii[i_active] += w\n        grad_radii[j_active] += w\n\n        # Gradient w.r.t. centers\n        # d/dc_i (r_i + r_j - ||c_i - c_j||) = - (c_i - c_j) / ||c_i - c_j||\n        # d/dc_j (r_i + r_j - ||c_i - c_j||) = - (c_j - c_i) / ||c_i - c_j|| = (c_i - c_j) / ||c_i - c_j||\n        \n        # Normalized difference vectors for active pairs\n        diff_active = centers[i_active] - centers[j_active] # (num_active, 2)\n        dist_active = actual_distances_pairs[active_overlap][:, np.newaxis] # (num_active, 1)\n        \n        norm_diff_active = diff_active / dist_active\n\n        grad_centers[i_active] -= w * norm_diff_active\n        grad_centers[j_active] += w * norm_diff_active\n        \n    return objective, grad_z\n\ndef _generate_initial_packing_grid(num_circles, jitter_scale=0.01):\n    \"\"\"\n    Generates initial centers and radii using a hexagonal-ish grid.\n    \"\"\"\n    # Determine number of rows and columns for a somewhat square-ish grid\n    rows = int(np.ceil(np.sqrt(num_circles)))\n    cols = int(np.ceil(num_circles / rows))\n\n    # Calculate initial radius based on grid size, capped at a reasonable value\n    initial_r = min(0.5 / max(rows, cols, 1), 0.15) \n    \n    # Adjust spacing to fit within [0,1]\n    x_spacing = (1.0 - 2 * initial_r) / (cols - 1) if cols > 1 else 0\n    y_spacing = (1.0 - 2 * initial_r) / (rows - 1) if rows > 1 else 0\n\n    centers = []\n    for i in range(rows):\n        for j in range(cols):\n            if len(centers) < num_circles:\n                x = initial_r + j * x_spacing\n                y = initial_r + i * y_spacing\n                \n                # Offset for hexagonal pattern\n                if i % 2 == 1:\n                    x += x_spacing / 2\n                \n                centers.append([x, y])\n\n    centers = np.array(centers[:num_circles])\n\n    # Ensure all centers are within [initial_r, 1-initial_r]\n    centers = np.clip(centers, initial_r, 1 - initial_r)\n\n    # Add jitter\n    centers += np.random.uniform(-jitter_scale, jitter_scale, centers.shape)\n    centers = np.clip(centers, 0 + VALIDATION_EPS, 1 - VALIDATION_EPS) # Ensure not exactly on boundary\n\n    radii = np.full(num_circles, initial_r)\n    \n    return centers, radii\n\n\ndef _validate_and_adjust(centers, radii):\n    \"\"\"\n    Validates the packing and slightly adjusts radii if there are minor violations.\n    Returns (centers, radii, sum_radii, is_feasible).\n    \"\"\"\n    current_radii = np.copy(radii)\n    \n    # Check boundary constraints\n    min_x_dist = centers[:, 0] - current_radii\n    max_x_dist = 1 - centers[:, 0] - current_radii\n    min_y_dist = centers[:, 1] - current_radii\n    max_y_dist = 1 - centers[:, 1] - current_radii\n    \n    boundary_violations = np.any(min_x_dist < -VALIDATION_EPS) or \\\n                          np.any(max_x_dist < -VALIDATION_EPS) or \\\n                          np.any(min_y_dist < -VALIDATION_EPS) or \\\n                          np.any(max_y_dist < -VALIDATION_EPS)\n    \n    # Check overlap constraints\n    distances = _compute_distances(centers)\n    \n    # Extract upper triangle indices\n    triu_indices = np.triu_indices(NUM_CIRCLES, k=1)\n    \n    # Sum of radii for pairs\n    sum_radii_pairs = current_radii[triu_indices[0]] + current_radii[triu_indices[1]]\n    \n    # Actual distances for pairs\n    actual_distances_pairs = distances[triu_indices]\n    \n    overlap_violations = np.any(sum_radii_pairs > actual_distances_pairs - VALIDATION_EPS)\n\n    is_feasible = not (boundary_violations or overlap_violations)\n\n    if not is_feasible:\n        # If not feasible, scale down radii slightly\n        # Find the maximum violation factor\n        max_violation_factor = 1.0\n        \n        # Boundary violations\n        if np.any(current_radii > centers[:, 0]):\n            max_violation_factor = max(max_violation_factor, np.max(current_radii / centers[:, 0]))\n        if np.any(current_radii > 1 - centers[:, 0]):\n            max_violation_factor = max(max_violation_factor, np.max(current_radii / (1 - centers[:, 0])))\n        if np.any(current_radii > centers[:, 1]):\n            max_violation_factor = max(max_violation_factor, np.max(current_radii / centers[:, 1]))\n        if np.any(current_radii > 1 - centers[:, 1]):\n            max_violation_factor = max(max_violation_factor, np.max(current_radii / (1 - centers[:, 1])))\n\n        # Overlap violations\n        if np.any(sum_radii_pairs > actual_distances_pairs):\n            # Calculate the ratio (r_i + r_j) / dist_ij for violating pairs\n            violating_pairs_mask = sum_radii_pairs > actual_distances_pairs\n            r_sum_violating = sum_radii_pairs[violating_pairs_mask]\n            dist_violating = actual_distances_pairs[violating_pairs_mask]\n            # Avoid division by zero if dist_violating is zero or very small\n            max_violation_factor = max(max_violation_factor, np.max(r_sum_violating / (dist_violating + 1e-12)))\n        \n        # Apply scaling\n        # We need to scale by (1 / max_violation_factor) * (1 - small_margin)\n        current_radii = current_radii / max_violation_factor * (1 - VALIDATION_EPS)\n        # Ensure non-negative\n        current_radii = np.maximum(0, current_radii)\n        \n        # One more small uniform scale to be absolutely sure, in case of cascading numerical errors\n        current_radii *= SCALING_FACTOR_ON_VIOLATION\n        current_radii = np.maximum(0, current_radii)\n\n    return centers, current_radii, np.sum(current_radii), is_feasible\n\n\ndef construct_packing():\n    \"\"\"\n    Packs 26 non-overlapping circles into a unit square to maximize the sum of their radii.\n    \"\"\"\n    best_sum_radii = -np.inf\n    best_centers = None\n    best_radii = None\n\n    # Bounds for L-BFGS-B optimization\n    # x, y in [0, 1], r in [0, 0.5] (0.5 is max possible radius for a single circle)\n    bounds_centers = [(0 + VALIDATION_EPS, 1 - VALIDATION_EPS) for _ in range(NUM_CIRCLES * 2)]\n    bounds_radii = [(0, 0.5) for _ in range(NUM_CIRCLES)]\n    bounds = bounds_centers + bounds_radii\n\n    # --- Seeding Strategy ---\n    # Generate multiple initial configurations\n    num_initial_seeds = 8\n    initial_configs = []\n    for i in range(num_initial_seeds):\n        centers_seed, radii_seed = _generate_initial_packing_grid(NUM_CIRCLES, jitter_scale=0.02 * (i+1)/num_initial_seeds)\n        initial_configs.append(_get_z(centers_seed, radii_seed))\n\n    # Add a seed with very small radii to ensure feasibility in case others are too aggressive\n    centers_small_r, _ = _generate_initial_packing_grid(NUM_CIRCLES, jitter_scale=0.05)\n    radii_small_r = np.full(NUM_CIRCLES, 0.01) # Very small radius\n    initial_configs.append(_get_z(centers_small_r, radii_small_r))\n\n\n    # --- Multi-start L-BFGS-B Optimization ---\n    all_optimized_z = []\n\n    # Pass 1: Moderate penalty weight\n    w1 = 200\n    for i, z_seed in enumerate(initial_configs):\n        res = minimize(\n            _objective_and_gradient, z_seed, args=(w1,), method='L-BFGS-B',\n            jac=True, bounds=bounds, options={'maxiter': 1000, 'ftol': 1e-7, 'gtol': 1e-5}\n        )\n        all_optimized_z.append(res.x)\n    \n    # Pass 2: Perturb best from Pass 1 and re-optimize with higher penalty\n    # Sort by penalized objective value to pick the best few\n    penalized_objectives = [\n        _objective_and_gradient(z_val, w1)[0] for z_val in all_optimized_z\n    ]\n    sorted_indices = np.argsort(penalized_objectives)\n    \n    best_z_pass1 = all_optimized_z[sorted_indices[0]]\n    \n    # Perturb the best solution\n    num_perturbations = 2 # 2 hops\n    perturbed_z_configs = [best_z_pass1] # Include the best as is\n    for _ in range(num_perturbations):\n        # Add Gaussian noise to centers and radii\n        perturbed_z = best_z_pass1 + np.random.normal(0, 0.01, best_z_pass1.shape)\n        # Clip to bounds to avoid issues with L-BFGS-B starting far out\n        perturbed_z = np.clip(perturbed_z, np.array([b[0] for b in bounds]), np.array([b[1] for b in bounds]))\n        perturbed_z_configs.append(perturbed_z)\n\n    w2 = 800 # Higher penalty weight for refinement\n    for z_seed in perturbed_z_configs:\n        res = minimize(\n            _objective_and_gradient, z_seed, args=(w2,), method='L-BFGS-B',\n            jac=True, bounds=bounds, options={'maxiter': 1500, 'ftol': 1e-8, 'gtol': 1e-6}\n        )\n        all_optimized_z.append(res.x)\n\n    # --- LP Feasibilization ---\n    # Try LP on all optimized solutions and pick the best feasible one\n    \n    # Fallback solution in case LP fails for all candidates\n    fallback_centers, _ = _generate_initial_packing_grid(NUM_CIRCLES, jitter_scale=0.01)\n    fallback_radii = np.full(NUM_CIRCLES, 0.001) # Very small, guaranteed feasible\n    fallback_centers, fallback_radii, fallback_sum_radii, _ = _validate_and_adjust(fallback_centers, fallback_radii)\n\n\n    for z_candidate in all_optimized_z:\n        centers_opt, radii_opt_candidate = _get_centers_radii(z_candidate)\n\n        # Ensure centers are within [0,1] and radii are non-negative\n        centers_opt = np.clip(centers_opt, 0, 1)\n        radii_opt_candidate = np.maximum(0, radii_opt_candidate)\n\n        # Define LP for radii\n        c_lp = -np.ones(NUM_CIRCLES) # Maximize sum(r_i) => minimize -sum(r_i)\n\n        # Bounds for r_i: 0 <= r_i <= min(r_cap_i, x_i, y_i, 1-x_i, 1-y_i)\n        # r_cap_i is radii_opt_candidate, but also consider boundary constraints\n        r_max_boundary = np.minimum(centers_opt[:, 0], 1 - centers_opt[:, 0])\n        r_max_boundary = np.minimum(r_max_boundary, centers_opt[:, 1])\n        r_max_boundary = np.minimum(r_max_boundary, 1 - centers_opt[:, 1])\n        \n        # Cap radii by the optimized candidate radii, but allow some growth\n        r_cap_from_opt = radii_opt_candidate * 1.05 # Allow slight growth\n        r_cap_from_opt = np.maximum(r_cap_from_opt, 0.001) # Ensure a minimum cap\n        \n        # The true upper bound for each radius is limited by its center's distance to the walls\n        r_upper_bounds = np.minimum(r_cap_from_opt, r_max_boundary)\n        \n        # Ensure r_upper_bounds are non-negative\n        r_upper_bounds = np.maximum(0, r_upper_bounds)\n\n        bounds_lp = [(0, r_upper_bounds[i]) for i in range(NUM_CIRCLES)]\n\n        # Inequality constraints: r_i + r_j <= ||c_i - c_j|| - LP_EPS\n        # A_ub @ r <= b_ub\n        num_pairs = NUM_CIRCLES * (NUM_CIRCLES - 1) // 2\n        A_ub = np.zeros((num_pairs, NUM_CIRCLES))\n        b_ub = np.zeros(num_pairs)\n\n        distances = _compute_distances(centers_opt)\n        \n        k = 0\n        for i in range(NUM_CIRCLES):\n            for j in range(i + 1, NUM_CIRCLES):\n                A_ub[k, i] = 1\n                A_ub[k, j] = 1\n                b_ub[k] = distances[i, j] - LP_EPS\n                k += 1\n        \n        try:\n            lp_res = linprog(c_lp, A_ub=A_ub, b_ub=b_ub, bounds=bounds_lp, method=\"highs\")\n\n            if lp_res.success and lp_res.status == 0: # Optimal solution found\n                radii_lp = lp_res.x\n                \n                # Validate and adjust the LP result\n                final_centers, final_radii, current_sum_radii, is_feasible = _validate_and_adjust(centers_opt, radii_lp)\n\n                if is_feasible:\n                    if current_sum_radii > best_sum_radii:\n                        best_sum_radii = current_sum_radii\n                        best_centers = final_centers\n                        best_radii = final_radii\n            # else: LP failed for this candidate, try next\n        except Exception:\n            # Catch any potential errors from linprog (e.g., singular matrix, numerical issues)\n            pass\n\n    if best_centers is None:\n        # If no feasible solution found after LP for any candidate, return the fallback\n        best_centers = fallback_centers\n        best_radii = fallback_radii\n        best_sum_radii = fallback_sum_radii\n        \n    return best_centers, best_radii, best_sum_radii",
  "metrics": {
    "valid": true,
    "score": 0.273,
    "eval_time": 0.35268306732177734,
    "error": null
  },
  "prompt": "\nYou are writing Python code only. Output a single Python code block, no prose.\nImplement:\n- construct_packing() -> (centers, radii, sum_radii)\n- Optionally: run_packing() returning same\n\nReturn:\n- centers: np.ndarray shape (26,2) within [0,1]\n- radii:   np.ndarray shape (26,), non-negative\n- sum_radii: float = radii.sum()\n\nConstraints:\n- Exactly 26 circles\n- All circles inside [0,1]^2\n- No overlaps: for all i<j, ||c_i-c_j|| >= r_i + r_j + 1e-6\n- Use only numpy, scipy\n- No prints. Keep runtime <= 300s.\n\nFeasibilization LP (required final step):\n- Given centers C (26,2) and candidate caps r_cap (26,), solve LP to maximize sum(r)\n    variables: r in R^26\n    objective: maximize sum(r)  <=> minimize -sum(r)\n    constraints:\n        0 <= r_i <= min(r_cap_i, x_i, y_i, 1-x_i, 1-y_i)\n        r_i + r_j <= dist(C_i, C_j) - 1e-6  for all i<j\n- Use scipy.optimize.linprog(method=\"highs\")\n- Fallback: if LP infeasible, shrink radii caps or jitter centers slightly and retry a few times.\n\nValidation:\n- After LP, verify boundary and pairwise constraints (with 1e-6 margin). If any small violations remain due to numeric roundoff, uniformly scale radii by (1 - 5e-7) or slightly adjust until feasible.\n\nNumerical tips:\n- When computing pairwise distances in penalties/gradients, apply eps only in division denominators, not inside penalties (avoid bias).\n- Vectorize; avoid Python loops over pairs.\n- Stable masks for active hinge terms; use upper-triangle to avoid double counting, then symmetrize grads.\n\nSeeding:\n- Provide a robust seeding strategy (e.g., hex/tri grid + jitter), always producing 26 points in (0,1)^2.\n\nOutput strictly feasible solution even if optimizer fails (via a conservative fallback: tiny equal radii from LP with well-separated grid).\n\nApproach:\n- Decision vars z = [x,y,r] with bounds x,y in [0,1], r in [0,0.6].\n- Penalized objective f(z) = -sum(r) + w*P(z) with same P and gradients as Strategy 1.\n- Perform multi-start local L-BFGS-B from 8 seeds at w=200, then random perturb and re-optimize (2 hops) with w=800.\n- Keep best penalized solution.\n- Final LP to compute radii; return feasible best.\n\nImplement fully vectorized gradients. No prints.\n",
  "response": "```python\nimport numpy as np\nfrom scipy.optimize import minimize, linprog\nfrom scipy.spatial.distance import pdist, squareform\n\n# Global constants\nNUM_CIRCLES = 26\n# Tolerance for non-overlap and boundary in the non-linear optimization\n# This is added to the radii sum in penalties: r_i + r_j - dist_ij + OPT_EPS\nOPT_EPS = 1e-6 \n# Tolerance for LP constraints: r_i + r_j <= dist_ij - LP_EPS\nLP_EPS = 1e-6 \n# Tolerance for final validation checks\nVALIDATION_EPS = 1e-6 \n# Small scaling factor if validation fails due to numerical precision\nSCALING_FACTOR_ON_VIOLATION = 1 - 5e-7 \n\ndef _get_centers_radii(z):\n    \"\"\"Converts the flat optimization vector z to (centers, radii).\"\"\"\n    centers = z[:NUM_CIRCLES*2].reshape(NUM_CIRCLES, 2)\n    radii = z[NUM_CIRCLES*2:]\n    return centers, radii\n\ndef _get_z(centers, radii):\n    \"\"\"Converts (centers, radii) to the flat optimization vector z.\"\"\"\n    return np.concatenate([centers.flatten(), radii])\n\ndef _compute_distances(centers):\n    \"\"\"Computes pairwise distances between centers.\"\"\"\n    return squareform(pdist(centers))\n\ndef _objective_and_gradient(z, w):\n    \"\"\"\n    Calculates the penalized objective function and its gradient.\n    f(z) = -sum(r) + w * P(z)\n    P(z) = sum(boundary_penalties) + sum(overlap_penalties)\n    \"\"\"\n    centers, radii = _get_centers_radii(z)\n\n    # Initialize objective and gradient\n    objective = -np.sum(radii)\n    grad_z = np.zeros_like(z)\n    grad_centers = grad_z[:NUM_CIRCLES*2].reshape(NUM_CIRCLES, 2)\n    grad_radii = grad_z[NUM_CIRCLES*2:]\n\n    # --- Boundary Penalties ---\n    # Penalties are max(0, r - x_i), max(0, r - y_i), max(0, r - (1-x_i)), max(0, r - (1-y_i))\n    # Gradients are 1 for r, -1 for x/y, 1 for x/y respectively when active.\n\n    # r - x_i\n    violations_rx = radii - centers[:, 0]\n    active_rx = violations_rx > 0\n    objective += w * np.sum(violations_rx[active_rx])\n    grad_radii[active_rx] += w\n    grad_centers[active_rx, 0] -= w\n\n    # r - y_i\n    violations_ry = radii - centers[:, 1]\n    active_ry = violations_ry > 0\n    objective += w * np.sum(violations_ry[active_ry])\n    grad_radii[active_ry] += w\n    grad_centers[active_ry, 1] -= w\n\n    # r - (1 - x_i)\n    violations_r1mx = radii - (1 - centers[:, 0])\n    active_r1mx = violations_r1mx > 0\n    objective += w * np.sum(violations_r1mx[active_r1mx])\n    grad_radii[active_r1mx] += w\n    grad_centers[active_r1mx, 0] += w \n\n    # r - (1 - y_i)\n    violations_r1my = radii - (1 - centers[:, 1])\n    active_r1my = violations_r1my > 0\n    objective += w * np.sum(violations_r1my[active_r1my])\n    grad_radii[active_r1my] += w\n    grad_centers[active_r1my, 1] += w \n\n    # --- Overlap Penalties ---\n    # Penalty: max(0, r_i + r_j - ||c_i - c_j|| + OPT_EPS)\n    # Use upper triangle to avoid double counting\n\n    # Compute pairwise distances\n    diff_centers = centers[:, np.newaxis, :] - centers[np.newaxis, :, :] # (N, N, 2)\n    dist_sq = np.sum(diff_centers**2, axis=2) # (N, N)\n    # Add a small epsilon to dist_sq before sqrt to prevent division by zero in gradient\n    distances = np.sqrt(dist_sq + 1e-12) \n\n    # Only consider upper triangle for unique pairs\n    triu_indices = np.triu_indices(NUM_CIRCLES, k=1)\n    \n    # Calculate desired minimum distance (sum of radii + OPT_EPS)\n    sum_radii_pairs = radii[triu_indices[0]] + radii[triu_indices[1]]\n    \n    # Actual distances for these pairs\n    actual_distances_pairs = distances[triu_indices]\n\n    # Violations: (r_i + r_j) - dist_ij + OPT_EPS\n    violations_overlap = sum_radii_pairs - actual_distances_pairs + OPT_EPS\n    active_overlap = violations_overlap > 0\n\n    objective += w * np.sum(violations_overlap[active_overlap])\n\n    # Gradients for overlap penalties\n    if np.any(active_overlap):\n        # Indices of active pairs\n        i_active = triu_indices[0][active_overlap]\n        j_active = triu_indices[1][active_overlap]\n\n        # Gradient w.r.t. radii\n        grad_radii[i_active] += w\n        grad_radii[j_active] += w\n\n        # Gradient w.r.t. centers\n        # d/dc_i (r_i + r_j - ||c_i - c_j||) = - (c_i - c_j) / ||c_i - c_j||\n        # d/dc_j (r_i + r_j - ||c_i - c_j||) = - (c_j - c_i) / ||c_i - c_j|| = (c_i - c_j) / ||c_i - c_j||\n        \n        # Normalized difference vectors for active pairs\n        diff_active = centers[i_active] - centers[j_active] # (num_active, 2)\n        dist_active = actual_distances_pairs[active_overlap][:, np.newaxis] # (num_active, 1)\n        \n        norm_diff_active = diff_active / dist_active\n\n        grad_centers[i_active] -= w * norm_diff_active\n        grad_centers[j_active] += w * norm_diff_active\n        \n    return objective, grad_z\n\ndef _generate_initial_packing_grid(num_circles, jitter_scale=0.01):\n    \"\"\"\n    Generates initial centers and radii using a hexagonal-ish grid.\n    \"\"\"\n    # Determine number of rows and columns for a somewhat square-ish grid\n    rows = int(np.ceil(np.sqrt(num_circles)))\n    cols = int(np.ceil(num_circles / rows))\n\n    # Calculate initial radius based on grid size, capped at a reasonable value\n    initial_r = min(0.5 / max(rows, cols, 1), 0.15) \n    \n    # Adjust spacing to fit within [0,1]\n    x_spacing = (1.0 - 2 * initial_r) / (cols - 1) if cols > 1 else 0\n    y_spacing = (1.0 - 2 * initial_r) / (rows - 1) if rows > 1 else 0\n\n    centers = []\n    for i in range(rows):\n        for j in range(cols):\n            if len(centers) < num_circles:\n                x = initial_r + j * x_spacing\n                y = initial_r + i * y_spacing\n                \n                # Offset for hexagonal pattern\n                if i % 2 == 1:\n                    x += x_spacing / 2\n                \n                centers.append([x, y])\n\n    centers = np.array(centers[:num_circles])\n\n    # Ensure all centers are within [initial_r, 1-initial_r]\n    centers = np.clip(centers, initial_r, 1 - initial_r)\n\n    # Add jitter\n    centers += np.random.uniform(-jitter_scale, jitter_scale, centers.shape)\n    centers = np.clip(centers, 0 + VALIDATION_EPS, 1 - VALIDATION_EPS) # Ensure not exactly on boundary\n\n    radii = np.full(num_circles, initial_r)\n    \n    return centers, radii\n\n\ndef _validate_and_adjust(centers, radii):\n    \"\"\"\n    Validates the packing and slightly adjusts radii if there are minor violations.\n    Returns (centers, radii, sum_radii, is_feasible).\n    \"\"\"\n    current_radii = np.copy(radii)\n    \n    # Check boundary constraints\n    min_x_dist = centers[:, 0] - current_radii\n    max_x_dist = 1 - centers[:, 0] - current_radii\n    min_y_dist = centers[:, 1] - current_radii\n    max_y_dist = 1 - centers[:, 1] - current_radii\n    \n    boundary_violations = np.any(min_x_dist < -VALIDATION_EPS) or \\\n                          np.any(max_x_dist < -VALIDATION_EPS) or \\\n                          np.any(min_y_dist < -VALIDATION_EPS) or \\\n                          np.any(max_y_dist < -VALIDATION_EPS)\n    \n    # Check overlap constraints\n    distances = _compute_distances(centers)\n    \n    # Extract upper triangle indices\n    triu_indices = np.triu_indices(NUM_CIRCLES, k=1)\n    \n    # Sum of radii for pairs\n    sum_radii_pairs = current_radii[triu_indices[0]] + current_radii[triu_indices[1]]\n    \n    # Actual distances for pairs\n    actual_distances_pairs = distances[triu_indices]\n    \n    overlap_violations = np.any(sum_radii_pairs > actual_distances_pairs - VALIDATION_EPS)\n\n    is_feasible = not (boundary_violations or overlap_violations)\n\n    if not is_feasible:\n        # If not feasible, scale down radii slightly\n        # Find the maximum violation factor\n        max_violation_factor = 1.0\n        \n        # Boundary violations\n        if np.any(current_radii > centers[:, 0]):\n            max_violation_factor = max(max_violation_factor, np.max(current_radii / centers[:, 0]))\n        if np.any(current_radii > 1 - centers[:, 0]):\n            max_violation_factor = max(max_violation_factor, np.max(current_radii / (1 - centers[:, 0])))\n        if np.any(current_radii > centers[:, 1]):\n            max_violation_factor = max(max_violation_factor, np.max(current_radii / centers[:, 1]))\n        if np.any(current_radii > 1 - centers[:, 1]):\n            max_violation_factor = max(max_violation_factor, np.max(current_radii / (1 - centers[:, 1])))\n\n        # Overlap violations\n        if np.any(sum_radii_pairs > actual_distances_pairs):\n            # Calculate the ratio (r_i + r_j) / dist_ij for violating pairs\n            violating_pairs_mask = sum_radii_pairs > actual_distances_pairs\n            r_sum_violating = sum_radii_pairs[violating_pairs_mask]\n            dist_violating = actual_distances_pairs[violating_pairs_mask]\n            # Avoid division by zero if dist_violating is zero or very small\n            max_violation_factor = max(max_violation_factor, np.max(r_sum_violating / (dist_violating + 1e-12)))\n        \n        # Apply scaling\n        # We need to scale by (1 / max_violation_factor) * (1 - small_margin)\n        current_radii = current_radii / max_violation_factor * (1 - VALIDATION_EPS)\n        # Ensure non-negative\n        current_radii = np.maximum(0, current_radii)\n        \n        # One more small uniform scale to be absolutely sure, in case of cascading numerical errors\n        current_radii *= SCALING_FACTOR_ON_VIOLATION\n        current_radii = np.maximum(0, current_radii)\n\n    return centers, current_radii, np.sum(current_radii), is_feasible\n\n\ndef construct_packing():\n    \"\"\"\n    Packs 26 non-overlapping circles into a unit square to maximize the sum of their radii.\n    \"\"\"\n    best_sum_radii = -np.inf\n    best_centers = None\n    best_radii = None\n\n    # Bounds for L-BFGS-B optimization\n    # x, y in [0, 1], r in [0, 0.5] (0.5 is max possible radius for a single circle)\n    bounds_centers = [(0 + VALIDATION_EPS, 1 - VALIDATION_EPS) for _ in range(NUM_CIRCLES * 2)]\n    bounds_radii = [(0, 0.5) for _ in range(NUM_CIRCLES)]\n    bounds = bounds_centers + bounds_radii\n\n    # --- Seeding Strategy ---\n    # Generate multiple initial configurations\n    num_initial_seeds = 8\n    initial_configs = []\n    for i in range(num_initial_seeds):\n        centers_seed, radii_seed = _generate_initial_packing_grid(NUM_CIRCLES, jitter_scale=0.02 * (i+1)/num_initial_seeds)\n        initial_configs.append(_get_z(centers_seed, radii_seed))\n\n    # Add a seed with very small radii to ensure feasibility in case others are too aggressive\n    centers_small_r, _ = _generate_initial_packing_grid(NUM_CIRCLES, jitter_scale=0.05)\n    radii_small_r = np.full(NUM_CIRCLES, 0.01) # Very small radius\n    initial_configs.append(_get_z(centers_small_r, radii_small_r))\n\n\n    # --- Multi-start L-BFGS-B Optimization ---\n    all_optimized_z = []\n\n    # Pass 1: Moderate penalty weight\n    w1 = 200\n    for i, z_seed in enumerate(initial_configs):\n        res = minimize(\n            _objective_and_gradient, z_seed, args=(w1,), method='L-BFGS-B',\n            jac=True, bounds=bounds, options={'maxiter': 1000, 'ftol': 1e-7, 'gtol': 1e-5}\n        )\n        all_optimized_z.append(res.x)\n    \n    # Pass 2: Perturb best from Pass 1 and re-optimize with higher penalty\n    # Sort by penalized objective value to pick the best few\n    penalized_objectives = [\n        _objective_and_gradient(z_val, w1)[0] for z_val in all_optimized_z\n    ]\n    sorted_indices = np.argsort(penalized_objectives)\n    \n    best_z_pass1 = all_optimized_z[sorted_indices[0]]\n    \n    # Perturb the best solution\n    num_perturbations = 2 # 2 hops\n    perturbed_z_configs = [best_z_pass1] # Include the best as is\n    for _ in range(num_perturbations):\n        # Add Gaussian noise to centers and radii\n        perturbed_z = best_z_pass1 + np.random.normal(0, 0.01, best_z_pass1.shape)\n        # Clip to bounds to avoid issues with L-BFGS-B starting far out\n        perturbed_z = np.clip(perturbed_z, np.array([b[0] for b in bounds]), np.array([b[1] for b in bounds]))\n        perturbed_z_configs.append(perturbed_z)\n\n    w2 = 800 # Higher penalty weight for refinement\n    for z_seed in perturbed_z_configs:\n        res = minimize(\n            _objective_and_gradient, z_seed, args=(w2,), method='L-BFGS-B',\n            jac=True, bounds=bounds, options={'maxiter': 1500, 'ftol': 1e-8, 'gtol': 1e-6}\n        )\n        all_optimized_z.append(res.x)\n\n    # --- LP Feasibilization ---\n    # Try LP on all optimized solutions and pick the best feasible one\n    \n    # Fallback solution in case LP fails for all candidates\n    fallback_centers, _ = _generate_initial_packing_grid(NUM_CIRCLES, jitter_scale=0.01)\n    fallback_radii = np.full(NUM_CIRCLES, 0.001) # Very small, guaranteed feasible\n    fallback_centers, fallback_radii, fallback_sum_radii, _ = _validate_and_adjust(fallback_centers, fallback_radii)\n\n\n    for z_candidate in all_optimized_z:\n        centers_opt, radii_opt_candidate = _get_centers_radii(z_candidate)\n\n        # Ensure centers are within [0,1] and radii are non-negative\n        centers_opt = np.clip(centers_opt, 0, 1)\n        radii_opt_candidate = np.maximum(0, radii_opt_candidate)\n\n        # Define LP for radii\n        c_lp = -np.ones(NUM_CIRCLES) # Maximize sum(r_i) => minimize -sum(r_i)\n\n        # Bounds for r_i: 0 <= r_i <= min(r_cap_i, x_i, y_i, 1-x_i, 1-y_i)\n        # r_cap_i is radii_opt_candidate, but also consider boundary constraints\n        r_max_boundary = np.minimum(centers_opt[:, 0], 1 - centers_opt[:, 0])\n        r_max_boundary = np.minimum(r_max_boundary, centers_opt[:, 1])\n        r_max_boundary = np.minimum(r_max_boundary, 1 - centers_opt[:, 1])\n        \n        # Cap radii by the optimized candidate radii, but allow some growth\n        r_cap_from_opt = radii_opt_candidate * 1.05 # Allow slight growth\n        r_cap_from_opt = np.maximum(r_cap_from_opt, 0.001) # Ensure a minimum cap\n        \n        # The true upper bound for each radius is limited by its center's distance to the walls\n        r_upper_bounds = np.minimum(r_cap_from_opt, r_max_boundary)\n        \n        # Ensure r_upper_bounds are non-negative\n        r_upper_bounds = np.maximum(0, r_upper_bounds)\n\n        bounds_lp = [(0, r_upper_bounds[i]) for i in range(NUM_CIRCLES)]\n\n        # Inequality constraints: r_i + r_j <= ||c_i - c_j|| - LP_EPS\n        # A_ub @ r <= b_ub\n        num_pairs = NUM_CIRCLES * (NUM_CIRCLES - 1) // 2\n        A_ub = np.zeros((num_pairs, NUM_CIRCLES))\n        b_ub = np.zeros(num_pairs)\n\n        distances = _compute_distances(centers_opt)\n        \n        k = 0\n        for i in range(NUM_CIRCLES):\n            for j in range(i + 1, NUM_CIRCLES):\n                A_ub[k, i] = 1\n                A_ub[k, j] = 1\n                b_ub[k] = distances[i, j] - LP_EPS\n                k += 1\n        \n        try:\n            lp_res = linprog(c_lp, A_ub=A_ub, b_ub=b_ub, bounds=bounds_lp, method=\"highs\")\n\n            if lp_res.success and lp_res.status == 0: # Optimal solution found\n                radii_lp = lp_res.x\n                \n                # Validate and adjust the LP result\n                final_centers, final_radii, current_sum_radii, is_feasible = _validate_and_adjust(centers_opt, radii_lp)\n\n                if is_feasible:\n                    if current_sum_radii > best_sum_radii:\n                        best_sum_radii = current_sum_radii\n                        best_centers = final_centers\n                        best_radii = final_radii\n            # else: LP failed for this candidate, try next\n        except Exception:\n            # Catch any potential errors from linprog (e.g., singular matrix, numerical issues)\n            pass\n\n    if best_centers is None:\n        # If no feasible solution found after LP for any candidate, return the fallback\n        best_centers = fallback_centers\n        best_radii = fallback_radii\n        best_sum_radii = fallback_sum_radii\n        \n    return best_centers, best_radii, best_sum_radii\n\n```",
  "reasoning": "",
  "timestamp": "2026-02-11T00:16:23.824987",
  "cost_data": null,
  "model_config": {
    "model": "gemini-2.5-flash",
    "temperature": 0.35,
    "provider_debug": {
      "finish_reason": "STOP",
      "usage_metadata": {
        "prompt_token_count": 908,
        "candidates_token_count": 5156,
        "thoughts_token_count": 7969
      },
      "response_text_len": 15782
    }
  },
  "llm_call_duration_s": 50.024327313061804,
  "eval_duration_s": 0.35268776305019855
}