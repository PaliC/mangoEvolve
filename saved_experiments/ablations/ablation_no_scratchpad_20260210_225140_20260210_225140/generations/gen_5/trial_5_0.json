{
  "trial_id": "trial_5_0",
  "generation": 5,
  "parent_id": "trial_3_0",
  "code": "import numpy as np\nfrom scipy.optimize import minimize, linprog\nimport time\n\ndef run_packing():\n    \"\"\"\n    Packs 26 circles into a unit square [0,1] x [0,1] to maximize the sum of their radii.\n    The strategy uses a multi-start SLSQP approach with a simulated annealing style \n    temperature that decays, controlling the magnitude of random perturbations \n    between SLSQP runs. A Linear Programming (LP) step is used to find the \n    optimal radii for each set of centers found by SLSQP.\n    \"\"\"\n    n = 26\n    start_time = time.time()\n    \n    # Pre-calculate indices for vectorization of non-linear constraints\n    i_idx, j_idx = np.triu_indices(n, k=1)\n    num_overlap = n * (n - 1) // 2\n    idx_n = np.arange(n)\n    row_idx_overlap = 4 * n + np.arange(num_overlap)\n    \n    # Pre-calculate the constant part of the LP constraint matrix for radii optimization\n    # Constraints: r_i + r_j <= distance_ij\n    A_ub_lp = np.zeros((num_overlap, n))\n    k = 0\n    for i in range(n):\n        for j in range(i + 1, n):\n            A_ub_lp[k, i], A_ub_lp[k, j] = 1, 1\n            k += 1\n    c_lp = -np.ones(n)\n\n    def objective(vars):\n        # vars contains [x1...xn, y1...yn, r1...rn]\n        # Maximize sum(r) -> Minimize -sum(r)\n        return -np.sum(vars[2*n:])\n\n    def obj_jac(vars):\n        # Gradient of objective\n        j = np.zeros(3*n)\n        j[2*n:] = -1.0\n        return j\n\n    def constraints_vectorized(vars):\n        # Boundary and non-overlap constraints\n        x = vars[:n]\n        y = vars[n:2*n]\n        r = vars[2*n:]\n        \n        # Boundary constraints: x-r >= 0, 1-x-r >= 0, y-r >= 0, 1-y-r >= 0\n        c_bound = np.concatenate([x - r, 1 - x - r, y - r, 1 - y - r])\n        \n        # Overlap constraints: dist(i,j) - (ri + rj) >= 0\n        dx = x[i_idx] - x[j_idx]\n        dy = y[i_idx] - y[j_idx]\n        d = np.sqrt(dx**2 + dy**2 + 1e-12)\n        c_overlap = d - (r[i_idx] + r[j_idx])\n        \n        return np.concatenate([c_bound, c_overlap])\n\n    def constraints_jac_vectorized(vars):\n        # Jacobian of constraints\n        x = vars[:n]\n        y = vars[n:2*n]\n        r = vars[2*n:]\n        jac = np.zeros((4*n + num_overlap, 3*n))\n        \n        # Boundary constraints: x-r, 1-x-r, y-r, 1-y-r\n        jac[idx_n, idx_n] = 1.0\n        jac[idx_n, 2*n + idx_n] = -1.0\n        jac[n + idx_n, idx_n] = -1.0\n        jac[n + idx_n, 2*n + idx_n] = -1.0\n        jac[2*n + idx_n, n + idx_n] = 1.0\n        jac[2*n + idx_n, 2*n + idx_n] = -1.0\n        jac[3*n + idx_n, n + idx_n] = -1.0\n        jac[3*n + idx_n, 2*n + idx_n] = -1.0\n        \n        # Overlap constraints: d(i,j) - ri - rj\n        dx = x[i_idx] - x[j_idx]\n        dy = y[i_idx] - y[j_idx]\n        d = np.sqrt(dx**2 + dy**2 + 1e-12)\n        \n        jac[row_idx_overlap, i_idx] = dx / d\n        jac[row_idx_overlap, j_idx] = -dx / d\n        jac[row_idx_overlap, n + i_idx] = dy / d\n        jac[row_idx_overlap, n + j_idx] = -dy / d\n        jac[row_idx_overlap, 2*n + i_idx] = -1.0\n        jac[row_idx_overlap, 2*n + j_idx] = -1.0\n        \n        return jac\n\n    def solve_lp_for_radii(x_final, y_final):\n        # Given fixed centers, find the optimal radii using Linear Programming\n        dx = x_final[i_idx] - x_final[j_idx]\n        dy = y_final[i_idx] - y_final[j_idx]\n        b_ub = np.sqrt(dx**2 + dy**2)\n        max_r_bound = np.minimum.reduce([x_final, 1 - x_final, y_final, 1 - y_final])\n        lp_bounds = [(0, max(0, b)) for b in max_r_bound]\n        \n        try:\n            # Try Highs solver first for efficiency\n            lp_res = linprog(c_lp, A_ub=A_ub_lp, b_ub=b_ub, bounds=lp_bounds, method='highs')\n            if lp_res.success:\n                return lp_res.x, -lp_res.fun\n        except:\n            try:\n                # Fallback to default solver\n                lp_res = linprog(c_lp, A_ub=A_ub_lp, b_ub=b_ub, bounds=lp_bounds)\n                if lp_res.success:\n                    return lp_res.x, -lp_res.fun\n            except:\n                pass\n        return None, 0\n\n    # Initialize best configuration\n    xg, yg = np.meshgrid(np.linspace(0.1, 0.9, 5), np.linspace(0.1, 0.9, 5))\n    x_init = np.concatenate([xg.flatten(), [0.5]])\n    y_init = np.concatenate([yg.flatten(), [0.5]])\n    best_vars = np.concatenate([x_init, y_init, np.zeros(n)])\n    best_sum = 0\n\n    # Initial multi-start to find a baseline\n    for i in range(3):\n        if i > 0:\n            x_init = np.random.rand(n)\n            y_init = np.random.rand(n)\n        radii, score = solve_lp_for_radii(x_init, y_init)\n        if score > best_sum:\n            best_sum = score\n            best_vars = np.concatenate([x_init, y_init, radii])\n\n    # Simulated Annealing with SLSQP\n    T_start = 0.08\n    T = T_start\n    cooling_rate = 0.96\n    \n    while time.time() - start_time < 285:\n        # Perturb the best known configuration by adding Gaussian noise to centers\n        noise = np.random.normal(0, T, 3*n)\n        noise[2*n:] = 0 # Radii are re-optimized by SLSQP and LP\n        test_vars = best_vars + noise\n        test_vars[:2*n] = np.clip(test_vars[:2*n], 0, 1) # Keep centers in bounds\n        \n        # Local optimization using SLSQP\n        res = minimize(objective, test_vars, method='SLSQP', jac=obj_jac,\n                       constraints={'type': 'ineq', 'fun': constraints_vectorized, 'jac': constraints_jac_vectorized},\n                       bounds=[(0, 1)]*2*n + [(0, 0.5)]*n,\n                       options={'maxiter': 80})\n        \n        # Polish the SLSQP result with an exact LP for radii\n        radii_opt, score_opt = solve_lp_for_radii(res.x[:n], res.x[n:2*n])\n        \n        if score_opt > best_sum:\n            best_sum = score_opt\n            best_vars = np.concatenate([res.x[:2*n], radii_opt])\n        \n        # Decay the temperature\n        T *= cooling_rate\n        # Re-heat slightly or reset T periodically to explore new basins\n        if T < 0.002:\n            elapsed = time.time() - start_time\n            T = T_start * (0.8 ** (elapsed // 40))\n            \n    # Final configuration formatting\n    final_centers = best_vars[:2*n].reshape((2, n)).T\n    final_radii = best_vars[2*n:]\n    \n    return final_centers, final_radii, best_sum",
  "metrics": {
    "valid": true,
    "score": 2.6307297310090516,
    "eval_time": 285.6643762588501,
    "error": null
  },
  "prompt": "Improve upon the best solution (Trial trial_3_0, score 2.631867250238027). Use a multi-start SLSQP approach but incorporate a 'simulated annealing' style temperature that decays, controlling the magnitude of random perturbations between SLSQP runs. Focus on the sum-of-radii objective. import numpy as np\nfrom scipy.optimize import minimize, linprog\nimport time\n\ndef run_packing():\n    \"\"\"\n    Packs 26 circles into a unit square [0,1] x [0,1] to maximize the sum of their radii.\n    The strategy uses a hybrid approach:\n    1. Multi-start with a combination of grid-based, random, and basin-hopping initializations.\n    2. Non-linear optimization (L-BFGS-B) with a penalty method to find promising center layouts.\n    3. Linear Programming (LP) to find the exact optimal radii for those fixed centers.\n    \"\"\"\n    n = 26\n    start_time = time.time()\n    best_sum = 0\n    best_centers = np.random.rand(n, 2) * 0.8 + 0.1\n    best_radii = np.zeros(n)\n\n    def objective(vars, n, lam):\n        # vars contains [x1...xn, y1...yn, r1...rn]\n        x, y, r = vars[:n], vars[n:2*n], vars[2*n:]\n        \n        # Boundary violation penalty\n        # Constraints: r_i <= x_i, r_i <= 1-x_i, r_i <= y_i, r_i <= 1-y_i\n        b1 = r - x\n        b2 = x + r - 1\n        b3 = r - y\n        b4 = y + r - 1\n        p_bound = np.sum(np.maximum(0, b1)**2 + np.maximum(0, b2)**2 + \n                         np.maximum(0, b3)**2 + np.maximum(0, b4)**2)\n        \n        # Overlap violation penalty\n        # Constraints: r_i + r_j <= distance(C_i, C_j)\n        dx = x[:, np.newaxis] - x[np.newaxis, :]\n        dy = y[:, np.newaxis] - y[np.newaxis, :]\n        d = np.sqrt(dx**2 + dy**2 + 1e-12)\n        rr = r[:, np.newaxis] + r[np.newaxis, :]\n        violation = np.maximum(0, rr - d)\n        # Use only upper triangle to avoid double counting and diagonal\n        p_overlap = np.sum(np.triu(violation**2, k=1))\n        \n        # Objective: Maximize sum(r) -> Minimize -sum(r)\n        return -np.sum(r) + lam * (p_bound + p_overlap)\n\n    def gradient(vars, n, lam):\n        x, y, r = vars[:n], vars[n:2*n], vars[2*n:]\n        dx_vec, dy_vec, dr_vec = np.zeros(n), np.zeros(n), -np.ones(n)\n        \n        # Boundary gradients\n        b1, b2, b3, b4 = r - x, x + r - 1, r - y, y + r - 1\n        m1, m2, m3, m4 = b1 > 0, b2 > 0, b3 > 0, b4 > 0\n        dx_vec += 2 * lam * (-b1 * m1 + b2 * m2)\n        dy_vec += 2 * lam * (-b3 * m3 + b4 * m4)\n        dr_vec += 2 * lam * (b1 * m1 + b2 * m2 + b3 * m3 + b4 * m4)\n        \n        # Overlap gradients\n        dx_mat = x[:, np.newaxis] - x[np.newaxis, :]\n        dy_mat = y[:, np.newaxis] - y[np.newaxis, :]\n        d_mat = np.sqrt(dx_mat**2 + dy_mat**2 + 1e-12)\n        rr_mat = r[:, np.newaxis] + r[np.newaxis, :]\n        violation = rr_mat - d_mat\n        mask = violation > 0\n        np.fill_diagonal(mask, False)\n        \n        common = 2 * lam * violation * mask\n        # Gradient of -d_ij w.r.t x_i is -(x_i - x_j) / d_ij\n        dx_vec += np.sum(common * (-dx_mat / d_mat), axis=1)\n        dy_vec += np.sum(common * (-dy_mat / d_mat), axis=1)\n        dr_vec += np.sum(common, axis=1)\n        \n        return np.concatenate([dx_vec, dy_vec, dr_vec])\n\n    # Pre-calculate the constant part of the LP constraint matrix\n    A_ub = np.zeros((n * (n - 1) // 2, n))\n    k = 0\n    for i in range(n):\n        for j in range(i + 1, n):\n            A_ub[k, i], A_ub[k, j] = 1, 1\n            k += 1\n    c_lp = -np.ones(n)\n\n    iter_idx = 0\n    while time.time() - start_time < 285:\n        # Multi-start strategy incorporating Basin Hopping\n        if iter_idx == 0:\n            # 1. Grid-like initialization (5x5 + 1)\n            xg, yg = np.meshgrid(np.linspace(0.1, 0.9, 5), np.linspace(0.1, 0.9, 5))\n            x_init = np.concatenate([xg.flatten(), [0.5]])\n            y_init = np.concatenate([yg.flatten(), [0.5]])\n        elif iter_idx % 3 == 0 and best_sum > 0:\n            # 2. Basin Hopping: Perturb the best known configuration\n            scale = 0.06 / (1 + (iter_idx // 30)) \n            x_init = np.clip(best_centers[:, 0] + np.random.normal(0, scale, n), 0.01, 0.99)\n            y_init = np.clip(best_centers[:, 1] + np.random.normal(0, scale, n), 0.01, 0.99)\n        else:\n            # 3. Pure random initialization\n            x_init = np.random.uniform(0.05, 0.95, n)\n            y_init = np.random.uniform(0.05, 0.95, n)\n            \n        # Initial radii guess\n        r_init = np.ones(n) * 0.05\n        vars_curr = np.concatenate([x_init, y_init, r_init])\n        \n        # Optimization with increasing penalty strength (Continuation Method)\n        for lam in [20, 200, 2000]:\n            res = minimize(objective, vars_curr, args=(n, lam), jac=gradient, method='L-BFGS-B', \n                           bounds=[(0, 1)]*2*n + [(0, 0.5)]*n, \n                           options={'maxiter': 400, 'ftol': 1e-8})\n            vars_curr = res.x\n            \n        # Extract centers from non-linear optimization result\n        x_final = np.clip(vars_curr[:n], 0, 1)\n        y_final = np.clip(vars_curr[n:2*n], 0, 1)\n        \n        # Solve LP to find the exact optimal radii for the fixed centers\n        b_ub = np.zeros(n * (n - 1) // 2)\n        k = 0\n        for i in range(n):\n            for j in range(i + 1, n):\n                b_ub[k] = np.sqrt((x_final[i] - x_final[j])**2 + (y_final[i] - y_final[j])**2)\n                k += 1\n        \n        # Radii must also satisfy boundary constraints\n        max_r_bound = np.minimum.reduce([x_final, 1 - x_final, y_final, 1 - y_final])\n        lp_bounds = [(0, max(0, b)) for b in max_r_bound]\n        \n        try:\n            # Highs is significantly faster for LP\n            lp_res = linprog(c_lp, A_ub=A_ub, b_ub=b_ub, bounds=lp_bounds, method='highs')\n        except:\n            # Fallback for older environments\n            lp_res = linprog(c_lp, A_ub=A_ub, b_ub=b_ub, bounds=lp_bounds)\n            \n        if lp_res.success:\n            current_sum = -lp_res.fun\n            if current_sum > best_sum:\n                best_sum = current_sum\n                best_radii = lp_res.x\n                best_centers = np.stack([x_final, y_final], axis=1)\n        \n        iter_idx += 1\n\n    return best_centers, best_radii, best_sum",
  "response": "```python\nimport numpy as np\nfrom scipy.optimize import minimize, linprog\nimport time\n\ndef run_packing():\n    \"\"\"\n    Packs 26 circles into a unit square [0,1] x [0,1] to maximize the sum of their radii.\n    The strategy uses a multi-start SLSQP approach with a simulated annealing style \n    temperature that decays, controlling the magnitude of random perturbations \n    between SLSQP runs. A Linear Programming (LP) step is used to find the \n    optimal radii for each set of centers found by SLSQP.\n    \"\"\"\n    n = 26\n    start_time = time.time()\n    \n    # Pre-calculate indices for vectorization of non-linear constraints\n    i_idx, j_idx = np.triu_indices(n, k=1)\n    num_overlap = n * (n - 1) // 2\n    idx_n = np.arange(n)\n    row_idx_overlap = 4 * n + np.arange(num_overlap)\n    \n    # Pre-calculate the constant part of the LP constraint matrix for radii optimization\n    # Constraints: r_i + r_j <= distance_ij\n    A_ub_lp = np.zeros((num_overlap, n))\n    k = 0\n    for i in range(n):\n        for j in range(i + 1, n):\n            A_ub_lp[k, i], A_ub_lp[k, j] = 1, 1\n            k += 1\n    c_lp = -np.ones(n)\n\n    def objective(vars):\n        # vars contains [x1...xn, y1...yn, r1...rn]\n        # Maximize sum(r) -> Minimize -sum(r)\n        return -np.sum(vars[2*n:])\n\n    def obj_jac(vars):\n        # Gradient of objective\n        j = np.zeros(3*n)\n        j[2*n:] = -1.0\n        return j\n\n    def constraints_vectorized(vars):\n        # Boundary and non-overlap constraints\n        x = vars[:n]\n        y = vars[n:2*n]\n        r = vars[2*n:]\n        \n        # Boundary constraints: x-r >= 0, 1-x-r >= 0, y-r >= 0, 1-y-r >= 0\n        c_bound = np.concatenate([x - r, 1 - x - r, y - r, 1 - y - r])\n        \n        # Overlap constraints: dist(i,j) - (ri + rj) >= 0\n        dx = x[i_idx] - x[j_idx]\n        dy = y[i_idx] - y[j_idx]\n        d = np.sqrt(dx**2 + dy**2 + 1e-12)\n        c_overlap = d - (r[i_idx] + r[j_idx])\n        \n        return np.concatenate([c_bound, c_overlap])\n\n    def constraints_jac_vectorized(vars):\n        # Jacobian of constraints\n        x = vars[:n]\n        y = vars[n:2*n]\n        r = vars[2*n:]\n        jac = np.zeros((4*n + num_overlap, 3*n))\n        \n        # Boundary constraints: x-r, 1-x-r, y-r, 1-y-r\n        jac[idx_n, idx_n] = 1.0\n        jac[idx_n, 2*n + idx_n] = -1.0\n        jac[n + idx_n, idx_n] = -1.0\n        jac[n + idx_n, 2*n + idx_n] = -1.0\n        jac[2*n + idx_n, n + idx_n] = 1.0\n        jac[2*n + idx_n, 2*n + idx_n] = -1.0\n        jac[3*n + idx_n, n + idx_n] = -1.0\n        jac[3*n + idx_n, 2*n + idx_n] = -1.0\n        \n        # Overlap constraints: d(i,j) - ri - rj\n        dx = x[i_idx] - x[j_idx]\n        dy = y[i_idx] - y[j_idx]\n        d = np.sqrt(dx**2 + dy**2 + 1e-12)\n        \n        jac[row_idx_overlap, i_idx] = dx / d\n        jac[row_idx_overlap, j_idx] = -dx / d\n        jac[row_idx_overlap, n + i_idx] = dy / d\n        jac[row_idx_overlap, n + j_idx] = -dy / d\n        jac[row_idx_overlap, 2*n + i_idx] = -1.0\n        jac[row_idx_overlap, 2*n + j_idx] = -1.0\n        \n        return jac\n\n    def solve_lp_for_radii(x_final, y_final):\n        # Given fixed centers, find the optimal radii using Linear Programming\n        dx = x_final[i_idx] - x_final[j_idx]\n        dy = y_final[i_idx] - y_final[j_idx]\n        b_ub = np.sqrt(dx**2 + dy**2)\n        max_r_bound = np.minimum.reduce([x_final, 1 - x_final, y_final, 1 - y_final])\n        lp_bounds = [(0, max(0, b)) for b in max_r_bound]\n        \n        try:\n            # Try Highs solver first for efficiency\n            lp_res = linprog(c_lp, A_ub=A_ub_lp, b_ub=b_ub, bounds=lp_bounds, method='highs')\n            if lp_res.success:\n                return lp_res.x, -lp_res.fun\n        except:\n            try:\n                # Fallback to default solver\n                lp_res = linprog(c_lp, A_ub=A_ub_lp, b_ub=b_ub, bounds=lp_bounds)\n                if lp_res.success:\n                    return lp_res.x, -lp_res.fun\n            except:\n                pass\n        return None, 0\n\n    # Initialize best configuration\n    xg, yg = np.meshgrid(np.linspace(0.1, 0.9, 5), np.linspace(0.1, 0.9, 5))\n    x_init = np.concatenate([xg.flatten(), [0.5]])\n    y_init = np.concatenate([yg.flatten(), [0.5]])\n    best_vars = np.concatenate([x_init, y_init, np.zeros(n)])\n    best_sum = 0\n\n    # Initial multi-start to find a baseline\n    for i in range(3):\n        if i > 0:\n            x_init = np.random.rand(n)\n            y_init = np.random.rand(n)\n        radii, score = solve_lp_for_radii(x_init, y_init)\n        if score > best_sum:\n            best_sum = score\n            best_vars = np.concatenate([x_init, y_init, radii])\n\n    # Simulated Annealing with SLSQP\n    T_start = 0.08\n    T = T_start\n    cooling_rate = 0.96\n    \n    while time.time() - start_time < 285:\n        # Perturb the best known configuration by adding Gaussian noise to centers\n        noise = np.random.normal(0, T, 3*n)\n        noise[2*n:] = 0 # Radii are re-optimized by SLSQP and LP\n        test_vars = best_vars + noise\n        test_vars[:2*n] = np.clip(test_vars[:2*n], 0, 1) # Keep centers in bounds\n        \n        # Local optimization using SLSQP\n        res = minimize(objective, test_vars, method='SLSQP', jac=obj_jac,\n                       constraints={'type': 'ineq', 'fun': constraints_vectorized, 'jac': constraints_jac_vectorized},\n                       bounds=[(0, 1)]*2*n + [(0, 0.5)]*n,\n                       options={'maxiter': 80})\n        \n        # Polish the SLSQP result with an exact LP for radii\n        radii_opt, score_opt = solve_lp_for_radii(res.x[:n], res.x[n:2*n])\n        \n        if score_opt > best_sum:\n            best_sum = score_opt\n            best_vars = np.concatenate([res.x[:2*n], radii_opt])\n        \n        # Decay the temperature\n        T *= cooling_rate\n        # Re-heat slightly or reset T periodically to explore new basins\n        if T < 0.002:\n            elapsed = time.time() - start_time\n            T = T_start * (0.8 ** (elapsed // 40))\n            \n    # Final configuration formatting\n    final_centers = best_vars[:2*n].reshape((2, n)).T\n    final_radii = best_vars[2*n:]\n    \n    return final_centers, final_radii, best_sum\n\n```",
  "reasoning": "",
  "timestamp": "2026-02-10T23:37:57.186547",
  "cost_data": null,
  "model_config": {
    "model": "gemini-3-flash-preview",
    "temperature": 0.7,
    "provider_debug": {
      "finish_reason": "STOP",
      "usage_metadata": {
        "prompt_token_count": 2511,
        "candidates_token_count": 2250,
        "thoughts_token_count": 14541
      },
      "response_text_len": 6204
    }
  },
  "llm_call_duration_s": 94.54347627295647,
  "eval_duration_s": 285.664384929114
}