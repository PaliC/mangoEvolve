{
  "trial_id": "trial_0_3",
  "generation": 0,
  "parent_id": null,
  "code": "import numpy as np\nfrom scipy.optimize import minimize, linprog\nimport time\n\ndef run_packing():\n    \"\"\"\n    Packs 26 circles into a unit square [0,1] x [0,1] to maximize the sum of their radii.\n    Uses a combination of Linear Programming for radii optimization and SLSQP for \n    simultaneous center and radii refinement, with multiple restarts.\n    \"\"\"\n    N = 26\n    start_time = time.time()\n    \n    # Objective function: maximize sum of radii (minimize negative sum)\n    def objective(v, N):\n        return -np.sum(v[2*N:])\n\n    # Jacobian of the objective function\n    def obj_jac(v, N):\n        j = np.zeros(3*N)\n        j[2*N:] = -1.0\n        return j\n\n    # Constraint function: all returned values must be >= 0\n    def constraints(v, N):\n        x, y, r = v[:N], v[N:2*N], v[2*N:]\n        \n        # Boundary constraints: circle must be inside [0,1]x[0,1]\n        c_boundary = np.empty(4*N)\n        c_boundary[0::4] = x - r\n        c_boundary[1::4] = 1.0 - x - r\n        c_boundary[2::4] = y - r\n        c_boundary[3::4] = 1.0 - y - r\n        \n        # Distance constraints: distance between centers >= sum of radii\n        # Use vectorized operations for efficiency\n        i_idx, j_idx = np.triu_indices(N, k=1)\n        dx = x[i_idx] - x[j_idx]\n        dy = y[i_idx] - y[j_idx]\n        d_ij = np.sqrt(dx**2 + dy**2 + 1e-9)\n        c_dist = d_ij - (r[i_idx] + r[j_idx])\n        \n        return np.concatenate([c_boundary, c_dist])\n\n    # Jacobian of the constraints\n    def constraints_jac(v, N):\n        x, y, r = v[:N], v[N:2*N], v[2*N:]\n        num_dist = N * (N - 1) // 2\n        jac = np.zeros((4 * N + num_dist, 3 * N))\n        \n        # Boundary Jacobian\n        idx = np.arange(N)\n        jac[4*idx, idx] = 1\n        jac[4*idx, 2*N+idx] = -1\n        jac[4*idx+1, idx] = -1\n        jac[4*idx+1, 2*N+idx] = -1\n        jac[4*idx+2, N+idx] = 1\n        jac[4*idx+2, 2*N+idx] = -1\n        jac[4*idx+3, N+idx] = -1\n        jac[4*idx+3, 2*N+idx] = -1\n        \n        # Distance Jacobian\n        i_idx, j_idx = np.triu_indices(N, k=1)\n        dx = x[i_idx] - x[j_idx]\n        dy = y[i_idx] - y[j_idx]\n        d_ij = np.sqrt(dx**2 + dy**2 + 1e-9)\n        \n        row_idx = 4 * N + np.arange(num_dist)\n        jac[row_idx, i_idx] = dx / d_ij\n        jac[row_idx, j_idx] = -dx / d_ij\n        jac[row_idx, N + i_idx] = dy / d_ij\n        jac[row_idx, N + j_idx] = -dy / d_ij\n        jac[row_idx, 2 * N + i_idx] = -1\n        jac[row_idx, 2 * N + j_idx] = -1\n        \n        return jac\n\n    # Precompute constant parts of the Linear Programming setup\n    num_dist = N * (N - 1) // 2\n    A_lp = np.zeros((num_dist, N))\n    i_idx, j_idx = np.triu_indices(N, k=1)\n    A_lp[np.arange(num_dist), i_idx] = 1\n    A_lp[np.arange(num_dist), j_idx] = 1\n    \n    # Initial fallback solution\n    x_g, y_g = np.meshgrid(np.linspace(0.1, 0.9, 5), np.linspace(0.1, 0.9, 5))\n    x_f, y_f = x_g.flatten(), y_g.flatten()\n    best_v = np.concatenate([np.pad(x_f, (0, 1), mode='constant', constant_values=0.5),\n                             np.pad(y_f, (0, 1), mode='constant', constant_values=0.5),\n                             np.zeros(26)])\n    best_sum = 0\n    \n    iteration = 0\n    while time.time() - start_time < 280:\n        # Generate initial centers: try grids first, then random\n        if iteration < 6:\n            grids = [(5, 6), (6, 5), (4, 7), (7, 4), (5, 5), (8, 4)]\n            rows, cols = grids[iteration]\n            x_g, y_g = np.linspace(0.1, 0.9, cols), np.linspace(0.1, 0.9, rows)\n            xx, yy = np.meshgrid(x_g, y_g)\n            x_init, y_init = xx.flatten()[:N], yy.flatten()[:N]\n            if len(x_init) < N:\n                x_init = np.concatenate([x_init, 0.1 + 0.8 * np.random.rand(N - len(x_init))])\n                y_init = np.concatenate([y_init, 0.1 + 0.8 * np.random.rand(N - len(y_init))])\n        else:\n            x_init, y_init = 0.1 + 0.8 * np.random.rand(N), 0.1 + 0.8 * np.random.rand(N)\n        \n        # Step 1: Fix centers and solve for optimal radii using Linear Programming\n        dx_init = x_init[i_idx] - x_init[j_idx]\n        dy_init = y_init[i_idx] - y_init[j_idx]\n        b_lp = np.sqrt(dx_init**2 + dy_init**2)\n        r_bounds = [(0, max(0, min(xi, 1-xi, yi, 1-yi))) for xi, yi in zip(x_init, y_init)]\n        \n        try:\n            res_lp = linprog(-np.ones(N), A_ub=A_lp, b_ub=b_lp, bounds=r_bounds, method='highs')\n            r_init = res_lp.x * 0.99 if res_lp.success else np.ones(N) * 0.01\n        except:\n            r_init = np.ones(N) * 0.01\n\n        # Step 2: Refine both centers and radii using a local non-linear optimizer (SLSQP)\n        v0 = np.concatenate([x_init, y_init, r_init])\n        res = minimize(objective, v0, args=(N,), method='SLSQP', jac=obj_jac,\n                       constraints={'type': 'ineq', 'fun': constraints, 'jac': constraints_jac, 'args': (N,)},\n                       bounds=[(0, 1)]*N + [(0, 1)]*N + [(0, 0.5)]*N,\n                       options={'maxiter': 200})\n        \n        if -res.fun > best_sum:\n            best_sum = -res.fun\n            best_v = res.x\n        iteration += 1\n\n    # Extract final results from the best optimization run\n    x, y, r = best_v[:N], best_v[N:2*N], best_v[2*N:]\n    centers = np.stack([x, y], axis=1)\n    return centers, r, best_sum",
  "metrics": {
    "valid": false,
    "score": 0.0,
    "eval_time": 280.8571174144745,
    "error": "Circle 0 at (0.0, 0.0) with radius 0.5 extends outside x-bounds"
  },
  "prompt": "Design an algorithm to pack 26 circles in a unit square to maximize the sum of their radii.\n        Use an iterative coordinate-descent-like approach:\n        1. Fix centers and solve for optimal radii using Linear Programming (scipy.optimize.linprog).\n        2. Fix radii and nudge centers using a local optimizer or a gradient-based step to increase the 'gap' between circles.\n        3. Repeat until convergence or timeout.\n        Initialize with several different random configurations.",
  "response": "```python\nimport numpy as np\nfrom scipy.optimize import minimize, linprog\nimport time\n\ndef run_packing():\n    \"\"\"\n    Packs 26 circles into a unit square [0,1] x [0,1] to maximize the sum of their radii.\n    Uses a combination of Linear Programming for radii optimization and SLSQP for \n    simultaneous center and radii refinement, with multiple restarts.\n    \"\"\"\n    N = 26\n    start_time = time.time()\n    \n    # Objective function: maximize sum of radii (minimize negative sum)\n    def objective(v, N):\n        return -np.sum(v[2*N:])\n\n    # Jacobian of the objective function\n    def obj_jac(v, N):\n        j = np.zeros(3*N)\n        j[2*N:] = -1.0\n        return j\n\n    # Constraint function: all returned values must be >= 0\n    def constraints(v, N):\n        x, y, r = v[:N], v[N:2*N], v[2*N:]\n        \n        # Boundary constraints: circle must be inside [0,1]x[0,1]\n        c_boundary = np.empty(4*N)\n        c_boundary[0::4] = x - r\n        c_boundary[1::4] = 1.0 - x - r\n        c_boundary[2::4] = y - r\n        c_boundary[3::4] = 1.0 - y - r\n        \n        # Distance constraints: distance between centers >= sum of radii\n        # Use vectorized operations for efficiency\n        i_idx, j_idx = np.triu_indices(N, k=1)\n        dx = x[i_idx] - x[j_idx]\n        dy = y[i_idx] - y[j_idx]\n        d_ij = np.sqrt(dx**2 + dy**2 + 1e-9)\n        c_dist = d_ij - (r[i_idx] + r[j_idx])\n        \n        return np.concatenate([c_boundary, c_dist])\n\n    # Jacobian of the constraints\n    def constraints_jac(v, N):\n        x, y, r = v[:N], v[N:2*N], v[2*N:]\n        num_dist = N * (N - 1) // 2\n        jac = np.zeros((4 * N + num_dist, 3 * N))\n        \n        # Boundary Jacobian\n        idx = np.arange(N)\n        jac[4*idx, idx] = 1\n        jac[4*idx, 2*N+idx] = -1\n        jac[4*idx+1, idx] = -1\n        jac[4*idx+1, 2*N+idx] = -1\n        jac[4*idx+2, N+idx] = 1\n        jac[4*idx+2, 2*N+idx] = -1\n        jac[4*idx+3, N+idx] = -1\n        jac[4*idx+3, 2*N+idx] = -1\n        \n        # Distance Jacobian\n        i_idx, j_idx = np.triu_indices(N, k=1)\n        dx = x[i_idx] - x[j_idx]\n        dy = y[i_idx] - y[j_idx]\n        d_ij = np.sqrt(dx**2 + dy**2 + 1e-9)\n        \n        row_idx = 4 * N + np.arange(num_dist)\n        jac[row_idx, i_idx] = dx / d_ij\n        jac[row_idx, j_idx] = -dx / d_ij\n        jac[row_idx, N + i_idx] = dy / d_ij\n        jac[row_idx, N + j_idx] = -dy / d_ij\n        jac[row_idx, 2 * N + i_idx] = -1\n        jac[row_idx, 2 * N + j_idx] = -1\n        \n        return jac\n\n    # Precompute constant parts of the Linear Programming setup\n    num_dist = N * (N - 1) // 2\n    A_lp = np.zeros((num_dist, N))\n    i_idx, j_idx = np.triu_indices(N, k=1)\n    A_lp[np.arange(num_dist), i_idx] = 1\n    A_lp[np.arange(num_dist), j_idx] = 1\n    \n    # Initial fallback solution\n    x_g, y_g = np.meshgrid(np.linspace(0.1, 0.9, 5), np.linspace(0.1, 0.9, 5))\n    x_f, y_f = x_g.flatten(), y_g.flatten()\n    best_v = np.concatenate([np.pad(x_f, (0, 1), mode='constant', constant_values=0.5),\n                             np.pad(y_f, (0, 1), mode='constant', constant_values=0.5),\n                             np.zeros(26)])\n    best_sum = 0\n    \n    iteration = 0\n    while time.time() - start_time < 280:\n        # Generate initial centers: try grids first, then random\n        if iteration < 6:\n            grids = [(5, 6), (6, 5), (4, 7), (7, 4), (5, 5), (8, 4)]\n            rows, cols = grids[iteration]\n            x_g, y_g = np.linspace(0.1, 0.9, cols), np.linspace(0.1, 0.9, rows)\n            xx, yy = np.meshgrid(x_g, y_g)\n            x_init, y_init = xx.flatten()[:N], yy.flatten()[:N]\n            if len(x_init) < N:\n                x_init = np.concatenate([x_init, 0.1 + 0.8 * np.random.rand(N - len(x_init))])\n                y_init = np.concatenate([y_init, 0.1 + 0.8 * np.random.rand(N - len(y_init))])\n        else:\n            x_init, y_init = 0.1 + 0.8 * np.random.rand(N), 0.1 + 0.8 * np.random.rand(N)\n        \n        # Step 1: Fix centers and solve for optimal radii using Linear Programming\n        dx_init = x_init[i_idx] - x_init[j_idx]\n        dy_init = y_init[i_idx] - y_init[j_idx]\n        b_lp = np.sqrt(dx_init**2 + dy_init**2)\n        r_bounds = [(0, max(0, min(xi, 1-xi, yi, 1-yi))) for xi, yi in zip(x_init, y_init)]\n        \n        try:\n            res_lp = linprog(-np.ones(N), A_ub=A_lp, b_ub=b_lp, bounds=r_bounds, method='highs')\n            r_init = res_lp.x * 0.99 if res_lp.success else np.ones(N) * 0.01\n        except:\n            r_init = np.ones(N) * 0.01\n\n        # Step 2: Refine both centers and radii using a local non-linear optimizer (SLSQP)\n        v0 = np.concatenate([x_init, y_init, r_init])\n        res = minimize(objective, v0, args=(N,), method='SLSQP', jac=obj_jac,\n                       constraints={'type': 'ineq', 'fun': constraints, 'jac': constraints_jac, 'args': (N,)},\n                       bounds=[(0, 1)]*N + [(0, 1)]*N + [(0, 0.5)]*N,\n                       options={'maxiter': 200})\n        \n        if -res.fun > best_sum:\n            best_sum = -res.fun\n            best_v = res.x\n        iteration += 1\n\n    # Extract final results from the best optimization run\n    x, y, r = best_v[:N], best_v[N:2*N], best_v[2*N:]\n    centers = np.stack([x, y], axis=1)\n    return centers, r, best_sum\n\n```",
  "reasoning": "",
  "timestamp": "2026-02-10T22:59:04.830395",
  "cost_data": null,
  "model_config": {
    "model": "gemini-3-flash-preview",
    "temperature": 0.7,
    "provider_debug": {
      "finish_reason": "STOP",
      "usage_metadata": {
        "prompt_token_count": 332,
        "candidates_token_count": 2045,
        "thoughts_token_count": 22727
      },
      "response_text_len": 5284
    }
  },
  "llm_call_duration_s": 141.96062122297008,
  "eval_duration_s": 280.8571279210737
}