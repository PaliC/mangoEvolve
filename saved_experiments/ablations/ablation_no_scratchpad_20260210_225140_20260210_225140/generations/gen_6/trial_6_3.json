{
  "trial_id": "trial_6_3",
  "generation": 6,
  "parent_id": "trial_5_3",
  "code": "import numpy as np\nfrom scipy.optimize import minimize, linprog\nimport time\n\ndef run_packing():\n    \"\"\"\n    Packs 26 circles into a unit square [0,1] x [0,1] to maximize the sum of their radii.\n    \n    Strategy:\n    1.  The problem is solved by optimizing the centers (x_i, y_i) of the circles.\n    2.  For a fixed set of centers, the optimal radii (r_i) are found using Linear Programming (LP).\n    3.  The sum of radii S(x, y) is a function of the centers. The gradient of S with respect\n        to the centers is calculated using the dual variables (shadow prices) of the LP.\n    4.  A multi-start approach is used, combining grid-based, hex-like, and random initializations.\n    5.  Each initialization is refined using the L-BFGS-B optimizer on the center coordinates.\n    \"\"\"\n    n = 26\n    start_time = time.time()\n    \n    # Pre-calculate the constant part of the LP constraint matrix A_ub\n    # Number of pairwise distance constraints: n*(n-1)/2 = 325\n    # Number of boundary distance constraints: 4*n = 104\n    num_pairs = n * (n - 1) // 2\n    num_constraints = num_pairs + 4 * n\n    A_ub = np.zeros((num_constraints, n))\n    \n    # Pairwise distance constraints: r_i + r_j <= d_ij\n    k = 0\n    for i in range(n):\n        for j in range(i + 1, n):\n            A_ub[k, i] = 1\n            A_ub[k, j] = 1\n            k += 1\n            \n    # Boundary constraints: r_i <= x_i, r_i <= 1-x_i, r_i <= y_i, r_i <= 1-y_i\n    for i in range(n):\n        A_ub[k, i] = 1; k += 1 # r_i <= x_i\n        A_ub[k, i] = 1; k += 1 # r_i <= 1 - x_i\n        A_ub[k, i] = 1; k += 1 # r_i <= y_i\n        A_ub[k, i] = 1; k += 1 # r_i <= 1 - y_i\n        \n    c_lp = -np.ones(n)\n    \n    def get_S_and_grad(centers_flat):\n        \"\"\"Calculates the sum of radii and its gradient with respect to centers.\"\"\"\n        centers = centers_flat.reshape((n, 2))\n        x = centers[:, 0]\n        y = centers[:, 1]\n        \n        # Build the b_ub vector (the right-hand side of the LP constraints)\n        b_ub = np.zeros(num_constraints)\n        \n        # Distances between all pairs of centers\n        dx = x[:, np.newaxis] - x[np.newaxis, :]\n        dy = y[:, np.newaxis] - y[np.newaxis, :]\n        d_sq = dx**2 + dy**2 + 1e-13\n        d = np.sqrt(d_sq)\n        \n        # Fill pairwise distance bounds\n        k = 0\n        for i in range(n):\n            for j in range(i + 1, n):\n                b_ub[k] = d[i, j]\n                k += 1\n                \n        # Fill boundary distance bounds\n        for i in range(n):\n            b_ub[k] = x[i]; k += 1\n            b_ub[k] = 1.0 - x[i]; k += 1\n            b_ub[k] = y[i]; k += 1\n            b_ub[k] = 1.0 - y[i]; k += 1\n            \n        # Solve the Linear Program to find optimal radii for fixed centers\n        # We use the 'highs' method for speed and reliability.\n        res = linprog(c_lp, A_ub=A_ub, b_ub=b_ub, method='highs')\n        \n        if not res.success or res.x is None:\n            return 0.0, np.zeros(2 * n), np.zeros(n)\n        \n        sum_radii = -res.fun\n        radii = res.x\n        \n        # Shadow prices (duals) of the LP constraints\n        # By strong duality, dS/db_k = dual_k. \n        # In SciPy's 'highs', the marginals for A_ub*r <= b_ub are typically <= 0.\n        y_dual = -res.ineqlin.marginals\n        \n        # Calculate gradient of sum_radii S with respect to x and y using the chain rule\n        grad_x = np.zeros(n)\n        grad_y = np.zeros(n)\n        \n        k = 0\n        for i in range(n):\n            for j in range(i + 1, n):\n                val = y_dual[k]\n                if val > 1e-10:\n                    dist = d[i, j]\n                    # Gradient of distance d_ij w.r.t. x_i is (x_i - x_j) / d_ij\n                    common_x = val * (x[i] - x[j]) / dist\n                    common_y = val * (y[i] - y[j]) / dist\n                    grad_x[i] += common_x\n                    grad_x[j] -= common_x\n                    grad_y[i] += common_y\n                    grad_y[j] -= common_y\n                k += 1\n                \n        for i in range(n):\n            # Gradient contributions from boundary constraints\n            grad_x[i] += y_dual[k]; k += 1     # from r_i <= x_i\n            grad_x[i] -= y_dual[k]; k += 1     # from r_i <= 1 - x_i\n            grad_y[i] += y_dual[k]; k += 1     # from r_i <= y_i\n            grad_y[i] -= y_dual[k]; k += 1     # from r_i <= 1 - y_i\n            \n        return sum_radii, np.concatenate([grad_x, grad_y]), radii\n\n    def objective_and_jac(centers_flat):\n        S, grad, _ = get_S_and_grad(centers_flat)\n        return -S, -grad\n\n    best_sum = 0\n    best_centers = np.random.rand(n, 2)\n    best_radii = np.zeros(n)\n    \n    iter_idx = 0\n    # Run until nearly 300 seconds have passed\n    while time.time() - start_time < 280:\n        if iter_idx == 0:\n            # 1. Grid-based initialization (5x5 + 1)\n            xg, yg = np.meshgrid(np.linspace(0.1, 0.9, 5), np.linspace(0.1, 0.9, 5))\n            x_init = np.concatenate([xg.flatten(), [0.5]])\n            y_init = np.concatenate([yg.flatten(), [0.5]])\n        elif iter_idx == 1:\n            # 2. Hexagonal-like initialization\n            x_init = np.tile(np.linspace(0.1, 0.9, 5), 5)\n            y_init = np.repeat(np.linspace(0.1, 0.9, 5), 5)\n            x_init[::2] += 0.05\n            x_init = np.concatenate([x_init, [0.5]])\n            y_init = np.concatenate([y_init, [0.95]])\n        elif iter_idx % 4 == 0 and best_sum > 0:\n            # 3. Neighborhood exploration: Perturb the best found configuration\n            scale = 0.05 / (1 + (iter_idx // 20))\n            x_init = np.clip(best_centers[:, 0] + np.random.normal(0, scale, n), 0.01, 0.99)\n            y_init = np.clip(best_centers[:, 1] + np.random.normal(0, scale, n), 0.01, 0.99)\n        else:\n            # 4. Random initialization\n            x_init = np.random.uniform(0.05, 0.95, n)\n            y_init = np.random.uniform(0.05, 0.95, n)\n            \n        centers_flat = np.concatenate([x_init, y_init])\n        \n        # Optimize center coordinates using L-BFGS-B based on the LP-gradient\n        res = minimize(objective_and_jac,\n                       centers_flat,\n                       jac=True,\n                       method='L-BFGS-B',\n                       bounds=[(0, 1)] * (2 * n),\n                       options={'maxiter': 100, 'ftol': 1e-8})\n        \n        # Evaluate the final sum and radii for the optimized layout\n        current_sum, _, current_radii = get_S_and_grad(res.x)\n        \n        if current_sum > best_sum:\n            best_sum = current_sum\n            best_centers = res.x.reshape((n, 2))\n            best_radii = current_radii\n            \n        iter_idx += 1\n        \n    return best_centers, best_radii, best_sum\n\nif __name__ == \"__main__\":\n    centers, radii, total_r = run_packing()",
  "metrics": {
    "valid": true,
    "score": 1.8730702379653195,
    "eval_time": 280.81758546829224,
    "error": null
  },
  "prompt": "\nImprove the following circle packing solution (score=2.635317965104822).\nimport numpy as np\nfrom scipy.optimize import minimize, linprog\nimport time\n\ndef run_packing():\n    \"\"\"\n    Packs 26 circles into a unit square [0,1] x [0,1] to maximize the sum of their radii.\n    The strategy uses a hybrid approach:\n    1. Multi-start with a combination of grid-based, random, and basin-hopping initializations.\n    2. Non-linear optimization (L-BFGS-B) with a penalty method to find promising center layouts.\n    3. Linear Programming (LP) to find the exact optimal radii for those fixed centers.\n    \n    This strategy focuses on exploring the neighborhood of the best-found solutions\n    using an adaptive perturbation method, similar to the core idea of CMA-ES.\n    \"\"\"\n    n = 26\n    start_time = time.time()\n    best_sum = 0\n    best_centers = np.random.rand(n, 2) * 0.8 + 0.1\n    best_radii = np.zeros(n)\n\n    # Pre-calculate the constant part of the LP constraint matrix\n    num_pairs = n * (n - 1) // 2\n    A_ub = np.zeros((num_pairs, n))\n    k = 0\n    for i in range(n):\n        for j in range(i + 1, n):\n            A_ub[k, i], A_ub[k, j] = 1, 1\n            k += 1\n    c_lp = -np.ones(n)\n\n    def objective(vars, n, lam):\n        # vars contains [x1...xn, y1...yn, r1...rn]\n        x, y, r = vars[:n], vars[n:2*n], vars[2*n:]\n        \n        # Boundary violation penalty\n        # Constraints: r_i <= x_i, r_i <= 1-x_i, r_i <= y_i, r_i <= 1-y_i\n        b1 = r - x\n        b2 = x + r - 1\n        b3 = r - y\n        b4 = y + r - 1\n        p_bound = np.sum(np.maximum(0, b1)**2 + np.maximum(0, b2)**2 + \n                         np.maximum(0, b3)**2 + np.maximum(0, b4)**2)\n        \n        # Overlap violation penalty\n        # Constraints: r_i + r_j <= distance(C_i, C_j)\n        dx = x[:, np.newaxis] - x[np.newaxis, :]\n        dy = y[:, np.newaxis] - y[np.newaxis, :]\n        d = np.sqrt(dx**2 + dy**2 + 1e-12)\n        rr = r[:, np.newaxis] + r[np.newaxis, :]\n        violation = np.maximum(0, rr - d)\n        # Use only upper triangle to avoid double counting and diagonal\n        p_overlap = np.sum(np.triu(violation**2, k=1))\n        \n        # Objective: Maximize sum(r) -> Minimize -sum(r)\n        return -np.sum(r) + lam * (p_bound + p_overlap)\n\n    def gradient(vars, n, lam):\n        x, y, r = vars[:n], vars[n:2*n], vars[2*n:]\n        dx_vec, dy_vec, dr_vec = np.zeros(n), np.zeros(n), -np.ones(n)\n        \n        # Boundary gradients\n        b1, b2, b3, b4 = r - x, x + r - 1, r - y, y + r - 1\n        m1, m2, m3, m4 = b1 > 0, b2 > 0, b3 > 0, b4 > 0\n        dx_vec += 2 * lam * (-b1 * m1 + b2 * m2)\n        dy_vec += 2 * lam * (-b3 * m3 + b4 * m4)\n        dr_vec += 2 * lam * (b1 * m1 + b2 * m2 + b3 * m3 + b4 * m4)\n        \n        # Overlap gradients\n        dx_mat = x[:, np.newaxis] - x[np.newaxis, :]\n        dy_mat = y[:, np.newaxis] - y[np.newaxis, :]\n        d_mat = np.sqrt(dx_mat**2 + dy_mat**2 + 1e-12)\n        rr_mat = r[:, np.newaxis] + r[np.newaxis, :]\n        violation = rr_mat - d_mat\n        mask = violation > 0\n        np.fill_diagonal(mask, False)\n        \n        common = 2 * lam * violation * mask\n        # Gradient of -d_ij w.r.t x_i is -(x_i - x_j) / d_ij\n        dx_vec += np.sum(common * (-dx_mat / d_mat), axis=1)\n        dy_vec += np.sum(common * (-dy_mat / d_mat), axis=1)\n        dr_vec += np.sum(common, axis=1)\n        \n        return np.concatenate([dx_vec, dy_vec, dr_vec])\n\n    iter_idx = 0\n    while time.time() - start_time < 285:\n        # Hybrid initialization strategy\n        if iter_idx == 0:\n            # 1. Grid-like initialization (5x5 + 1)\n            xg, yg = np.meshgrid(np.linspace(0.1, 0.9, 5), np.linspace(0.1, 0.9, 5))\n            x_init = np.concatenate([xg.flatten(), [0.5]])\n            y_init = np.concatenate([yg.flatten(), [0.5]])\n        elif iter_idx % 4 == 0 and best_sum > 0:\n            # 2. Neighborhood exploration: Perturb the best configuration (Basin Hopping)\n            scale = 0.05 / (1 + (iter_idx % 20)) \n            x_init = np.clip(best_centers[:, 0] + np.random.normal(0, scale, n), 0.01, 0.99)\n            y_init = np.clip(best_centers[:, 1] + np.random.normal(0, scale, n), 0.01, 0.99)\n        else:\n            # 3. Pure random initialization\n            x_init = np.random.uniform(0.05, 0.95, n)\n            y_init = np.random.uniform(0.05, 0.95, n)\n            \n        # Initial radii guess\n        r_init = np.ones(n) * 0.04\n        vars_curr = np.concatenate([x_init, y_init, r_init])\n        \n        # Optimization with increasing penalty strength (Continuation Method)\n        for lam in [15, 150, 1500]:\n            res = minimize(objective, vars_curr, args=(n, lam), jac=gradient, method='L-BFGS-B', \n                           bounds=[(0, 1)]*2*n + [(0, 0.5)]*n, \n                           options={'maxiter': 300, 'ftol': 1e-7})\n            vars_curr = res.x\n            \n        # Extract centers and clip to square\n        x_final = np.clip(vars_curr[:n], 0, 1)\n        y_final = np.clip(vars_curr[n:2*n], 0, 1)\n        \n        # Solve LP to find the exact optimal radii for the fixed centers\n        b_ub = np.zeros(num_pairs)\n        k = 0\n        for i in range(n):\n            for j in range(i + 1, n):\n                b_ub[k] = np.sqrt((x_final[i] - x_final[j])**2 + (y_final[i] - y_final[j])**2)\n                k += 1\n        \n        # Radii must also satisfy boundary constraints: r_i <= dist to wall\n        max_r_bound = np.minimum.reduce([x_final, 1 - x_final, y_final, 1 - y_final])\n        lp_bounds = [(0, max(0.0, b)) for b in max_r_bound]\n        \n        try:\n            # Highs is significantly faster for LP\n            lp_res = linprog(c_lp, A_ub=A_ub, b_ub=b_ub, bounds=lp_bounds, method='highs')\n        except:\n            # Fallback for older environments\n            lp_res = linprog(c_lp, A_ub=A_ub, b_ub=b_ub, bounds=lp_bounds)\n            \n        if lp_res.success:\n            current_sum = -lp_res.fun\n            if current_sum > best_sum:\n                best_sum = current_sum\n                best_radii = lp_res.x\n                best_centers = np.stack([x_final, y_final], axis=1)\n        \n        iter_idx += 1\n\n    return best_centers, best_radii, best_sum\n\nStrategy:\n1. Identify the circles with the smallest radii.\n2. Try to 'jiggle' these specific circles by moving them to nearby empty spaces or swapping their positions with others.\n3. For each jiggle, run a local optimization (SLSQP).\n4. Keep the best configuration found.\n",
  "response": "```python\nimport numpy as np\nfrom scipy.optimize import minimize, linprog\nimport time\n\ndef run_packing():\n    \"\"\"\n    Packs 26 circles into a unit square [0,1] x [0,1] to maximize the sum of their radii.\n    \n    Strategy:\n    1.  The problem is solved by optimizing the centers (x_i, y_i) of the circles.\n    2.  For a fixed set of centers, the optimal radii (r_i) are found using Linear Programming (LP).\n    3.  The sum of radii S(x, y) is a function of the centers. The gradient of S with respect\n        to the centers is calculated using the dual variables (shadow prices) of the LP.\n    4.  A multi-start approach is used, combining grid-based, hex-like, and random initializations.\n    5.  Each initialization is refined using the L-BFGS-B optimizer on the center coordinates.\n    \"\"\"\n    n = 26\n    start_time = time.time()\n    \n    # Pre-calculate the constant part of the LP constraint matrix A_ub\n    # Number of pairwise distance constraints: n*(n-1)/2 = 325\n    # Number of boundary distance constraints: 4*n = 104\n    num_pairs = n * (n - 1) // 2\n    num_constraints = num_pairs + 4 * n\n    A_ub = np.zeros((num_constraints, n))\n    \n    # Pairwise distance constraints: r_i + r_j <= d_ij\n    k = 0\n    for i in range(n):\n        for j in range(i + 1, n):\n            A_ub[k, i] = 1\n            A_ub[k, j] = 1\n            k += 1\n            \n    # Boundary constraints: r_i <= x_i, r_i <= 1-x_i, r_i <= y_i, r_i <= 1-y_i\n    for i in range(n):\n        A_ub[k, i] = 1; k += 1 # r_i <= x_i\n        A_ub[k, i] = 1; k += 1 # r_i <= 1 - x_i\n        A_ub[k, i] = 1; k += 1 # r_i <= y_i\n        A_ub[k, i] = 1; k += 1 # r_i <= 1 - y_i\n        \n    c_lp = -np.ones(n)\n    \n    def get_S_and_grad(centers_flat):\n        \"\"\"Calculates the sum of radii and its gradient with respect to centers.\"\"\"\n        centers = centers_flat.reshape((n, 2))\n        x = centers[:, 0]\n        y = centers[:, 1]\n        \n        # Build the b_ub vector (the right-hand side of the LP constraints)\n        b_ub = np.zeros(num_constraints)\n        \n        # Distances between all pairs of centers\n        dx = x[:, np.newaxis] - x[np.newaxis, :]\n        dy = y[:, np.newaxis] - y[np.newaxis, :]\n        d_sq = dx**2 + dy**2 + 1e-13\n        d = np.sqrt(d_sq)\n        \n        # Fill pairwise distance bounds\n        k = 0\n        for i in range(n):\n            for j in range(i + 1, n):\n                b_ub[k] = d[i, j]\n                k += 1\n                \n        # Fill boundary distance bounds\n        for i in range(n):\n            b_ub[k] = x[i]; k += 1\n            b_ub[k] = 1.0 - x[i]; k += 1\n            b_ub[k] = y[i]; k += 1\n            b_ub[k] = 1.0 - y[i]; k += 1\n            \n        # Solve the Linear Program to find optimal radii for fixed centers\n        # We use the 'highs' method for speed and reliability.\n        res = linprog(c_lp, A_ub=A_ub, b_ub=b_ub, method='highs')\n        \n        if not res.success or res.x is None:\n            return 0.0, np.zeros(2 * n), np.zeros(n)\n        \n        sum_radii = -res.fun\n        radii = res.x\n        \n        # Shadow prices (duals) of the LP constraints\n        # By strong duality, dS/db_k = dual_k. \n        # In SciPy's 'highs', the marginals for A_ub*r <= b_ub are typically <= 0.\n        y_dual = -res.ineqlin.marginals\n        \n        # Calculate gradient of sum_radii S with respect to x and y using the chain rule\n        grad_x = np.zeros(n)\n        grad_y = np.zeros(n)\n        \n        k = 0\n        for i in range(n):\n            for j in range(i + 1, n):\n                val = y_dual[k]\n                if val > 1e-10:\n                    dist = d[i, j]\n                    # Gradient of distance d_ij w.r.t. x_i is (x_i - x_j) / d_ij\n                    common_x = val * (x[i] - x[j]) / dist\n                    common_y = val * (y[i] - y[j]) / dist\n                    grad_x[i] += common_x\n                    grad_x[j] -= common_x\n                    grad_y[i] += common_y\n                    grad_y[j] -= common_y\n                k += 1\n                \n        for i in range(n):\n            # Gradient contributions from boundary constraints\n            grad_x[i] += y_dual[k]; k += 1     # from r_i <= x_i\n            grad_x[i] -= y_dual[k]; k += 1     # from r_i <= 1 - x_i\n            grad_y[i] += y_dual[k]; k += 1     # from r_i <= y_i\n            grad_y[i] -= y_dual[k]; k += 1     # from r_i <= 1 - y_i\n            \n        return sum_radii, np.concatenate([grad_x, grad_y]), radii\n\n    def objective_and_jac(centers_flat):\n        S, grad, _ = get_S_and_grad(centers_flat)\n        return -S, -grad\n\n    best_sum = 0\n    best_centers = np.random.rand(n, 2)\n    best_radii = np.zeros(n)\n    \n    iter_idx = 0\n    # Run until nearly 300 seconds have passed\n    while time.time() - start_time < 280:\n        if iter_idx == 0:\n            # 1. Grid-based initialization (5x5 + 1)\n            xg, yg = np.meshgrid(np.linspace(0.1, 0.9, 5), np.linspace(0.1, 0.9, 5))\n            x_init = np.concatenate([xg.flatten(), [0.5]])\n            y_init = np.concatenate([yg.flatten(), [0.5]])\n        elif iter_idx == 1:\n            # 2. Hexagonal-like initialization\n            x_init = np.tile(np.linspace(0.1, 0.9, 5), 5)\n            y_init = np.repeat(np.linspace(0.1, 0.9, 5), 5)\n            x_init[::2] += 0.05\n            x_init = np.concatenate([x_init, [0.5]])\n            y_init = np.concatenate([y_init, [0.95]])\n        elif iter_idx % 4 == 0 and best_sum > 0:\n            # 3. Neighborhood exploration: Perturb the best found configuration\n            scale = 0.05 / (1 + (iter_idx // 20))\n            x_init = np.clip(best_centers[:, 0] + np.random.normal(0, scale, n), 0.01, 0.99)\n            y_init = np.clip(best_centers[:, 1] + np.random.normal(0, scale, n), 0.01, 0.99)\n        else:\n            # 4. Random initialization\n            x_init = np.random.uniform(0.05, 0.95, n)\n            y_init = np.random.uniform(0.05, 0.95, n)\n            \n        centers_flat = np.concatenate([x_init, y_init])\n        \n        # Optimize center coordinates using L-BFGS-B based on the LP-gradient\n        res = minimize(objective_and_jac,\n                       centers_flat,\n                       jac=True,\n                       method='L-BFGS-B',\n                       bounds=[(0, 1)] * (2 * n),\n                       options={'maxiter': 100, 'ftol': 1e-8})\n        \n        # Evaluate the final sum and radii for the optimized layout\n        current_sum, _, current_radii = get_S_and_grad(res.x)\n        \n        if current_sum > best_sum:\n            best_sum = current_sum\n            best_centers = res.x.reshape((n, 2))\n            best_radii = current_radii\n            \n        iter_idx += 1\n        \n    return best_centers, best_radii, best_sum\n\nif __name__ == \"__main__\":\n    centers, radii, total_r = run_packing()\n```",
  "reasoning": "",
  "timestamp": "2026-02-10T23:46:50.034053",
  "cost_data": null,
  "model_config": {
    "model": "gemini-3-flash-preview",
    "temperature": 0.7,
    "provider_debug": {
      "finish_reason": "STOP",
      "usage_metadata": {
        "prompt_token_count": 2574,
        "candidates_token_count": 2366,
        "thoughts_token_count": 18594
      },
      "response_text_len": 6819
    }
  },
  "llm_call_duration_s": 125.79013886407483,
  "eval_duration_s": 280.81759381701704
}