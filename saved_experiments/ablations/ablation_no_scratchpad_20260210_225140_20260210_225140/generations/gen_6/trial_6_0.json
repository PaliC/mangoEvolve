{
  "trial_id": "trial_6_0",
  "generation": 6,
  "parent_id": "trial_5_3",
  "code": "import numpy as np\nfrom scipy.optimize import minimize, linprog\nimport time\n\ndef run_packing():\n    \"\"\"\n    Packs 26 circles into a unit square [0,1] x [0,1] to maximize the sum of their radii.\n    The strategy:\n    1. Multi-start approach with random, grid-based, and perturbed initializations.\n    2. Nonlinear optimization using a penalty method (L-BFGS-B) to find promising layouts.\n    3. Linear Programming (LP) to find the exact optimal radii for fixed center layouts.\n    4. Adaptive perturbation (shaking) of the best found solutions to escape local optima.\n    \"\"\"\n    n = 26\n    start_time = time.time()\n    \n    # Precompute indices for efficiency\n    triu_i, triu_j = np.triu_indices(n, k=1)\n    num_overlap = len(triu_i)\n    \n    # Pre-calculate the constant part of the LP constraint matrix\n    # Overlap constraints: r_i + r_j <= distance(C_i, C_j)\n    A_ub_overlap = np.zeros((num_overlap, n))\n    for k in range(num_overlap):\n        A_ub_overlap[k, triu_i[k]] = 1\n        A_ub_overlap[k, triu_j[k]] = 1\n    c_lp = -np.ones(n) # Objective: maximize sum(r) -> minimize -sum(r)\n    \n    best_sum = 0\n    best_centers = np.random.rand(n, 2)\n    best_radii = np.zeros(n)\n\n    def get_radii(centers):\n        \"\"\"Solves the LP to find the optimal radii for a fixed set of centers.\"\"\"\n        x, y = centers[:, 0], centers[:, 1]\n        dx = x[triu_i] - x[triu_j]\n        dy = y[triu_i] - y[triu_j]\n        b_ub = np.sqrt(dx**2 + dy**2)\n        \n        # Radii must satisfy boundary constraints: r_i <= dist to wall\n        # We use bounds in linprog for r_i <= x_i, r_i <= 1-x_i, etc.\n        bounds = [(0, max(0.0, min(x[i], 1-x[i], y[i], 1-y[i]))) for i in range(n)]\n        \n        try:\n            # Highs is the most efficient solver for this scale\n            res = linprog(c_lp, A_ub=A_ub_overlap, b_ub=b_ub, bounds=bounds, method='highs')\n            if res.success:\n                return -res.fun, res.x\n        except:\n            # Fallback for older scipy versions\n            res = linprog(c_lp, A_ub=A_ub_overlap, b_ub=b_ub, bounds=bounds)\n            if res.success:\n                return -res.fun, res.x\n        return 0, np.zeros(n)\n\n    def penalty_obj(vars, lam):\n        \"\"\"Penalty-based objective function for L-BFGS-B.\"\"\"\n        x, y, r = vars[:n], vars[n:2*n], vars[2*n:]\n        \n        # Boundary violation penalty\n        b = np.concatenate([r-x, x+r-1, r-y, y+r-1])\n        p_bound = np.sum(np.maximum(0, b)**2)\n        \n        # Overlap violation penalty\n        dx = x[:, None] - x[None, :]\n        dy = y[:, None] - y[None, :]\n        d = np.sqrt(dx**2 + dy**2 + 1e-12)\n        rr = r[:, None] + r[None, :]\n        violation = rr - d\n        p_overlap = np.sum(np.triu(np.maximum(0, violation)**2, k=1))\n        \n        return -np.sum(r) + lam * (p_bound + p_overlap)\n\n    def penalty_grad(vars, lam):\n        \"\"\"Gradient of the penalty-based objective function.\"\"\"\n        x, y, r = vars[:n], vars[n:2*n], vars[2*n:]\n        dx_vec, dy_vec, dr_vec = np.zeros(n), np.zeros(n), -np.ones(n)\n        \n        # Boundary gradients\n        b1, b2, b3, b4 = r-x, x+r-1, r-y, y+r-1\n        m1, m2, m3, m4 = b1>0, b2>0, b3>0, b4>0\n        dx_vec += 2*lam*(-b1*m1 + b2*m2)\n        dy_vec += 2*lam*(-b3*m3 + b4*m4)\n        dr_vec += 2*lam*(b1*m1 + b2*m2 + b3*m3 + b4*m4)\n        \n        # Overlap gradients\n        dx_mat = x[:, None] - x[None, :]\n        dy_mat = y[:, None] - y[None, :]\n        d_mat = np.sqrt(dx_mat**2 + dy_mat**2 + 1e-12)\n        rr_mat = r[:, None] + r[None, :]\n        violation = rr_mat - d_mat\n        v_mask = violation > 0\n        np.fill_diagonal(v_mask, False)\n        \n        common_mat = 2*lam*violation*v_mask / d_mat\n        dx_vec += np.sum(common_mat * (-dx_mat), axis=1)\n        dy_vec += np.sum(common_mat * (-dy_mat), axis=1)\n        dr_vec += np.sum(2*lam*violation*v_mask, axis=1)\n        \n        return np.concatenate([dx_vec, dy_vec, dr_vec])\n\n    iter_idx = 0\n    # Main optimization loop\n    while time.time() - start_time < 275:\n        if iter_idx == 0:\n            # Grid-based initialization\n            xg, yg = np.meshgrid(np.linspace(0.1, 0.9, 5), np.linspace(0.1, 0.9, 5))\n            x_init = np.concatenate([xg.flatten(), [0.5]])\n            y_init = np.concatenate([yg.flatten(), [0.5]])\n        elif iter_idx % 5 == 0 and best_sum > 0:\n            # Shake the current best solution (Basin Hopping)\n            scale = 0.1 if iter_idx % 10 == 0 else 0.02\n            x_init = np.clip(best_centers[:, 0] + np.random.normal(0, scale, n), 0.01, 0.99)\n            y_init = np.clip(best_centers[:, 1] + np.random.normal(0, scale, n), 0.01, 0.99)\n        else:\n            # Random initialization\n            x_init = np.random.uniform(0.05, 0.95, n)\n            y_init = np.random.uniform(0.05, 0.95, n)\n        \n        r_init = np.ones(n) * 0.04\n        vars_curr = np.concatenate([x_init, y_init, r_init])\n        \n        # Incremental penalty strength (Continuation Method)\n        for lam in [20, 200, 2000]:\n            res = minimize(penalty_obj, vars_curr, args=(lam,), jac=penalty_grad, \n                           method='L-BFGS-B', bounds=[(0,1)]*2*n + [(0,0.5)]*n,\n                           options={'maxiter': 200})\n            vars_curr = res.x\n        \n        centers = np.stack([vars_curr[:n], vars_curr[n:2*n]], axis=1)\n        centers = np.clip(centers, 0, 1)\n        curr_sum, curr_radii = get_radii(centers)\n        \n        if curr_sum > best_sum:\n            best_sum, best_radii, best_centers = curr_sum, curr_radii, centers\n        \n        iter_idx += 1\n        \n    # Final refinement of the best configuration found\n    if best_sum > 0:\n        vars_curr = np.concatenate([best_centers[:, 0], best_centers[:, 1], best_radii])\n        for lam in [2000, 10000]:\n            res = minimize(penalty_obj, vars_curr, args=(lam,), jac=penalty_grad, \n                           method='L-BFGS-B', bounds=[(0,1)]*2*n + [(0,0.5)]*n,\n                           options={'maxiter': 500})\n            vars_curr = res.x\n        centers = np.stack([vars_curr[:n], vars_curr[n:2*n]], axis=1)\n        centers = np.clip(centers, 0, 1)\n        best_sum, best_radii = get_radii(centers)\n        best_centers = centers\n        \n    return best_centers, best_radii, best_sum",
  "metrics": {
    "valid": true,
    "score": 2.6329475787756205,
    "eval_time": 275.8452124595642,
    "error": null
  },
  "prompt": "\nImprove the following circle packing solution (score=2.635317965104822).\nThe goal is to maximize the sum of 26 radii in a unit square.\n\nCurrent best code:\nimport numpy as np\nfrom scipy.optimize import minimize, linprog\nimport time\n\ndef run_packing():\n    \"\"\"\n    Packs 26 circles into a unit square [0,1] x [0,1] to maximize the sum of their radii.\n    The strategy uses a hybrid approach:\n    1. Multi-start with a combination of grid-based, random, and basin-hopping initializations.\n    2. Non-linear optimization (L-BFGS-B) with a penalty method to find promising center layouts.\n    3. Linear Programming (LP) to find the exact optimal radii for those fixed centers.\n    \n    This strategy focuses on exploring the neighborhood of the best-found solutions\n    using an adaptive perturbation method, similar to the core idea of CMA-ES.\n    \"\"\"\n    n = 26\n    start_time = time.time()\n    best_sum = 0\n    best_centers = np.random.rand(n, 2) * 0.8 + 0.1\n    best_radii = np.zeros(n)\n\n    # Pre-calculate the constant part of the LP constraint matrix\n    num_pairs = n * (n - 1) // 2\n    A_ub = np.zeros((num_pairs, n))\n    k = 0\n    for i in range(n):\n        for j in range(i + 1, n):\n            A_ub[k, i], A_ub[k, j] = 1, 1\n            k += 1\n    c_lp = -np.ones(n)\n\n    def objective(vars, n, lam):\n        # vars contains [x1...xn, y1...yn, r1...rn]\n        x, y, r = vars[:n], vars[n:2*n], vars[2*n:]\n        \n        # Boundary violation penalty\n        # Constraints: r_i <= x_i, r_i <= 1-x_i, r_i <= y_i, r_i <= 1-y_i\n        b1 = r - x\n        b2 = x + r - 1\n        b3 = r - y\n        b4 = y + r - 1\n        p_bound = np.sum(np.maximum(0, b1)**2 + np.maximum(0, b2)**2 + \n                         np.maximum(0, b3)**2 + np.maximum(0, b4)**2)\n        \n        # Overlap violation penalty\n        # Constraints: r_i + r_j <= distance(C_i, C_j)\n        dx = x[:, np.newaxis] - x[np.newaxis, :]\n        dy = y[:, np.newaxis] - y[np.newaxis, :]\n        d = np.sqrt(dx**2 + dy**2 + 1e-12)\n        rr = r[:, np.newaxis] + r[np.newaxis, :]\n        violation = np.maximum(0, rr - d)\n        # Use only upper triangle to avoid double counting and diagonal\n        p_overlap = np.sum(np.triu(violation**2, k=1))\n        \n        # Objective: Maximize sum(r) -> Minimize -sum(r)\n        return -np.sum(r) + lam * (p_bound + p_overlap)\n\n    def gradient(vars, n, lam):\n        x, y, r = vars[:n], vars[n:2*n], vars[2*n:]\n        dx_vec, dy_vec, dr_vec = np.zeros(n), np.zeros(n), -np.ones(n)\n        \n        # Boundary gradients\n        b1, b2, b3, b4 = r - x, x + r - 1, r - y, y + r - 1\n        m1, m2, m3, m4 = b1 > 0, b2 > 0, b3 > 0, b4 > 0\n        dx_vec += 2 * lam * (-b1 * m1 + b2 * m2)\n        dy_vec += 2 * lam * (-b3 * m3 + b4 * m4)\n        dr_vec += 2 * lam * (b1 * m1 + b2 * m2 + b3 * m3 + b4 * m4)\n        \n        # Overlap gradients\n        dx_mat = x[:, np.newaxis] - x[np.newaxis, :]\n        dy_mat = y[:, np.newaxis] - y[np.newaxis, :]\n        d_mat = np.sqrt(dx_mat**2 + dy_mat**2 + 1e-12)\n        rr_mat = r[:, np.newaxis] + r[np.newaxis, :]\n        violation = rr_mat - d_mat\n        mask = violation > 0\n        np.fill_diagonal(mask, False)\n        \n        common = 2 * lam * violation * mask\n        # Gradient of -d_ij w.r.t x_i is -(x_i - x_j) / d_ij\n        dx_vec += np.sum(common * (-dx_mat / d_mat), axis=1)\n        dy_vec += np.sum(common * (-dy_mat / d_mat), axis=1)\n        dr_vec += np.sum(common, axis=1)\n        \n        return np.concatenate([dx_vec, dy_vec, dr_vec])\n\n    iter_idx = 0\n    while time.time() - start_time < 285:\n        # Hybrid initialization strategy\n        if iter_idx == 0:\n            # 1. Grid-like initialization (5x5 + 1)\n            xg, yg = np.meshgrid(np.linspace(0.1, 0.9, 5), np.linspace(0.1, 0.9, 5))\n            x_init = np.concatenate([xg.flatten(), [0.5]])\n            y_init = np.concatenate([yg.flatten(), [0.5]])\n        elif iter_idx % 4 == 0 and best_sum > 0:\n            # 2. Neighborhood exploration: Perturb the best configuration (Basin Hopping)\n            scale = 0.05 / (1 + (iter_idx % 20)) \n            x_init = np.clip(best_centers[:, 0] + np.random.normal(0, scale, n), 0.01, 0.99)\n            y_init = np.clip(best_centers[:, 1] + np.random.normal(0, scale, n), 0.01, 0.99)\n        else:\n            # 3. Pure random initialization\n            x_init = np.random.uniform(0.05, 0.95, n)\n            y_init = np.random.uniform(0.05, 0.95, n)\n            \n        # Initial radii guess\n        r_init = np.ones(n) * 0.04\n        vars_curr = np.concatenate([x_init, y_init, r_init])\n        \n        # Optimization with increasing penalty strength (Continuation Method)\n        for lam in [15, 150, 1500]:\n            res = minimize(objective, vars_curr, args=(n, lam), jac=gradient, method='L-BFGS-B', \n                           bounds=[(0, 1)]*2*n + [(0, 0.5)]*n, \n                           options={'maxiter': 300, 'ftol': 1e-7})\n            vars_curr = res.x\n            \n        # Extract centers and clip to square\n        x_final = np.clip(vars_curr[:n], 0, 1)\n        y_final = np.clip(vars_curr[n:2*n], 0, 1)\n        \n        # Solve LP to find the exact optimal radii for the fixed centers\n        b_ub = np.zeros(num_pairs)\n        k = 0\n        for i in range(n):\n            for j in range(i + 1, n):\n                b_ub[k] = np.sqrt((x_final[i] - x_final[j])**2 + (y_final[i] - y_final[j])**2)\n                k += 1\n        \n        # Radii must also satisfy boundary constraints: r_i <= dist to wall\n        max_r_bound = np.minimum.reduce([x_final, 1 - x_final, y_final, 1 - y_final])\n        lp_bounds = [(0, max(0.0, b)) for b in max_r_bound]\n        \n        try:\n            # Highs is significantly faster for LP\n            lp_res = linprog(c_lp, A_ub=A_ub, b_ub=b_ub, bounds=lp_bounds, method='highs')\n        except:\n            # Fallback for older environments\n            lp_res = linprog(c_lp, A_ub=A_ub, b_ub=b_ub, bounds=lp_bounds)\n            \n        if lp_res.success:\n            current_sum = -lp_res.fun\n            if current_sum > best_sum:\n                best_sum = current_sum\n                best_radii = lp_res.x\n                best_centers = np.stack([x_final, y_final], axis=1)\n        \n        iter_idx += 1\n\n    return best_centers, best_radii, best_sum\n\nStrategy:\n1. Use the current best centers and radii as starting points.\n2. Apply SLSQP with very tight tolerances (ftol=1e-12).\n3. Ensure the constraints (no overlap, inside square) are strictly met.\n4. Try a small 'shaking' phase: perturb the centers slightly (1e-4) and re-optimize multiple times, keeping the best result.\n5. Focus on the sum of radii objective.\n",
  "response": "```python\nimport numpy as np\nfrom scipy.optimize import minimize, linprog\nimport time\n\ndef run_packing():\n    \"\"\"\n    Packs 26 circles into a unit square [0,1] x [0,1] to maximize the sum of their radii.\n    The strategy:\n    1. Multi-start approach with random, grid-based, and perturbed initializations.\n    2. Nonlinear optimization using a penalty method (L-BFGS-B) to find promising layouts.\n    3. Linear Programming (LP) to find the exact optimal radii for fixed center layouts.\n    4. Adaptive perturbation (shaking) of the best found solutions to escape local optima.\n    \"\"\"\n    n = 26\n    start_time = time.time()\n    \n    # Precompute indices for efficiency\n    triu_i, triu_j = np.triu_indices(n, k=1)\n    num_overlap = len(triu_i)\n    \n    # Pre-calculate the constant part of the LP constraint matrix\n    # Overlap constraints: r_i + r_j <= distance(C_i, C_j)\n    A_ub_overlap = np.zeros((num_overlap, n))\n    for k in range(num_overlap):\n        A_ub_overlap[k, triu_i[k]] = 1\n        A_ub_overlap[k, triu_j[k]] = 1\n    c_lp = -np.ones(n) # Objective: maximize sum(r) -> minimize -sum(r)\n    \n    best_sum = 0\n    best_centers = np.random.rand(n, 2)\n    best_radii = np.zeros(n)\n\n    def get_radii(centers):\n        \"\"\"Solves the LP to find the optimal radii for a fixed set of centers.\"\"\"\n        x, y = centers[:, 0], centers[:, 1]\n        dx = x[triu_i] - x[triu_j]\n        dy = y[triu_i] - y[triu_j]\n        b_ub = np.sqrt(dx**2 + dy**2)\n        \n        # Radii must satisfy boundary constraints: r_i <= dist to wall\n        # We use bounds in linprog for r_i <= x_i, r_i <= 1-x_i, etc.\n        bounds = [(0, max(0.0, min(x[i], 1-x[i], y[i], 1-y[i]))) for i in range(n)]\n        \n        try:\n            # Highs is the most efficient solver for this scale\n            res = linprog(c_lp, A_ub=A_ub_overlap, b_ub=b_ub, bounds=bounds, method='highs')\n            if res.success:\n                return -res.fun, res.x\n        except:\n            # Fallback for older scipy versions\n            res = linprog(c_lp, A_ub=A_ub_overlap, b_ub=b_ub, bounds=bounds)\n            if res.success:\n                return -res.fun, res.x\n        return 0, np.zeros(n)\n\n    def penalty_obj(vars, lam):\n        \"\"\"Penalty-based objective function for L-BFGS-B.\"\"\"\n        x, y, r = vars[:n], vars[n:2*n], vars[2*n:]\n        \n        # Boundary violation penalty\n        b = np.concatenate([r-x, x+r-1, r-y, y+r-1])\n        p_bound = np.sum(np.maximum(0, b)**2)\n        \n        # Overlap violation penalty\n        dx = x[:, None] - x[None, :]\n        dy = y[:, None] - y[None, :]\n        d = np.sqrt(dx**2 + dy**2 + 1e-12)\n        rr = r[:, None] + r[None, :]\n        violation = rr - d\n        p_overlap = np.sum(np.triu(np.maximum(0, violation)**2, k=1))\n        \n        return -np.sum(r) + lam * (p_bound + p_overlap)\n\n    def penalty_grad(vars, lam):\n        \"\"\"Gradient of the penalty-based objective function.\"\"\"\n        x, y, r = vars[:n], vars[n:2*n], vars[2*n:]\n        dx_vec, dy_vec, dr_vec = np.zeros(n), np.zeros(n), -np.ones(n)\n        \n        # Boundary gradients\n        b1, b2, b3, b4 = r-x, x+r-1, r-y, y+r-1\n        m1, m2, m3, m4 = b1>0, b2>0, b3>0, b4>0\n        dx_vec += 2*lam*(-b1*m1 + b2*m2)\n        dy_vec += 2*lam*(-b3*m3 + b4*m4)\n        dr_vec += 2*lam*(b1*m1 + b2*m2 + b3*m3 + b4*m4)\n        \n        # Overlap gradients\n        dx_mat = x[:, None] - x[None, :]\n        dy_mat = y[:, None] - y[None, :]\n        d_mat = np.sqrt(dx_mat**2 + dy_mat**2 + 1e-12)\n        rr_mat = r[:, None] + r[None, :]\n        violation = rr_mat - d_mat\n        v_mask = violation > 0\n        np.fill_diagonal(v_mask, False)\n        \n        common_mat = 2*lam*violation*v_mask / d_mat\n        dx_vec += np.sum(common_mat * (-dx_mat), axis=1)\n        dy_vec += np.sum(common_mat * (-dy_mat), axis=1)\n        dr_vec += np.sum(2*lam*violation*v_mask, axis=1)\n        \n        return np.concatenate([dx_vec, dy_vec, dr_vec])\n\n    iter_idx = 0\n    # Main optimization loop\n    while time.time() - start_time < 275:\n        if iter_idx == 0:\n            # Grid-based initialization\n            xg, yg = np.meshgrid(np.linspace(0.1, 0.9, 5), np.linspace(0.1, 0.9, 5))\n            x_init = np.concatenate([xg.flatten(), [0.5]])\n            y_init = np.concatenate([yg.flatten(), [0.5]])\n        elif iter_idx % 5 == 0 and best_sum > 0:\n            # Shake the current best solution (Basin Hopping)\n            scale = 0.1 if iter_idx % 10 == 0 else 0.02\n            x_init = np.clip(best_centers[:, 0] + np.random.normal(0, scale, n), 0.01, 0.99)\n            y_init = np.clip(best_centers[:, 1] + np.random.normal(0, scale, n), 0.01, 0.99)\n        else:\n            # Random initialization\n            x_init = np.random.uniform(0.05, 0.95, n)\n            y_init = np.random.uniform(0.05, 0.95, n)\n        \n        r_init = np.ones(n) * 0.04\n        vars_curr = np.concatenate([x_init, y_init, r_init])\n        \n        # Incremental penalty strength (Continuation Method)\n        for lam in [20, 200, 2000]:\n            res = minimize(penalty_obj, vars_curr, args=(lam,), jac=penalty_grad, \n                           method='L-BFGS-B', bounds=[(0,1)]*2*n + [(0,0.5)]*n,\n                           options={'maxiter': 200})\n            vars_curr = res.x\n        \n        centers = np.stack([vars_curr[:n], vars_curr[n:2*n]], axis=1)\n        centers = np.clip(centers, 0, 1)\n        curr_sum, curr_radii = get_radii(centers)\n        \n        if curr_sum > best_sum:\n            best_sum, best_radii, best_centers = curr_sum, curr_radii, centers\n        \n        iter_idx += 1\n        \n    # Final refinement of the best configuration found\n    if best_sum > 0:\n        vars_curr = np.concatenate([best_centers[:, 0], best_centers[:, 1], best_radii])\n        for lam in [2000, 10000]:\n            res = minimize(penalty_obj, vars_curr, args=(lam,), jac=penalty_grad, \n                           method='L-BFGS-B', bounds=[(0,1)]*2*n + [(0,0.5)]*n,\n                           options={'maxiter': 500})\n            vars_curr = res.x\n        centers = np.stack([vars_curr[:n], vars_curr[n:2*n]], axis=1)\n        centers = np.clip(centers, 0, 1)\n        best_sum, best_radii = get_radii(centers)\n        best_centers = centers\n        \n    return best_centers, best_radii, best_sum\n\n```",
  "reasoning": "",
  "timestamp": "2026-02-10T23:46:28.242436",
  "cost_data": null,
  "model_config": {
    "model": "gemini-3-flash-preview",
    "temperature": 0.7,
    "provider_debug": {
      "finish_reason": "STOP",
      "usage_metadata": {
        "prompt_token_count": 2630,
        "candidates_token_count": 2291,
        "thoughts_token_count": 17273
      },
      "response_text_len": 6291
    }
  },
  "llm_call_duration_s": 108.97056829102803,
  "eval_duration_s": 275.8452195529826
}