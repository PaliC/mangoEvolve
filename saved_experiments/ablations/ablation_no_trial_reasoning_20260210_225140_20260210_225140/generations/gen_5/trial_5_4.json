{
  "trial_id": "trial_5_4",
  "generation": 5,
  "parent_id": "trial_1_3",
  "code": "import numpy as np\nfrom scipy.optimize import minimize\nimport time\n\ndef run_packing():\n    \"\"\"\n    Pack 26 circles into a unit square [0,1] x [0,1] to maximize the sum of their radii.\n    Uses a multi-start strategy followed by a 'Shrink-and-Grow' local optimization.\n    \"\"\"\n    n = 26\n    i_idx, j_idx = np.triu_indices(n, k=1)\n\n    def con_func(v):\n        \"\"\"\n        Constraints: circles must be inside the square and must not overlap.\n        \"\"\"\n        x = v[:n]\n        y = v[n:2*n]\n        r = v[2*n:]\n        \n        # Boundary constraints: x_i - r_i >= 0, 1 - x_i - r_i >= 0, etc.\n        c_boundary = np.empty(4 * n)\n        c_boundary[0:n] = x - r\n        c_boundary[n:2*n] = 1.0 - x - r\n        c_boundary[2*n:3*n] = y - r\n        c_boundary[3*n:4*n] = 1.0 - y - r\n        \n        # Overlap constraints: (x_i - x_j)^2 + (y_i - y_j)^2 - (r_i + r_j)^2 >= 0\n        c_overlap = (x[i_idx] - x[j_idx])**2 + (y[i_idx] - y[j_idx])**2 - (r[i_idx] + r[j_idx])**2\n        \n        return np.concatenate([c_boundary, c_overlap])\n\n    def objective(v):\n        \"\"\"Maximize sum of radii.\"\"\"\n        return -np.sum(v[2*n:])\n\n    def objective_grad(v):\n        \"\"\"Gradient of the objective function.\"\"\"\n        grad = np.zeros(3 * n)\n        grad[2*n:] = -1.0\n        return grad\n\n    best_v = None\n    best_sum = 0\n    start_time = time.time()\n    \n    # --- Initialization Phase ---\n    inits = []\n    \n    # 1. Grid-based start (5x5 grid plus one extra circle)\n    grid_coords = np.linspace(0.12, 0.88, 5)\n    xx, yy = np.meshgrid(grid_coords, grid_coords)\n    x_grid = np.append(xx.flatten(), 0.5)\n    y_grid = np.append(yy.flatten(), 0.5)\n    # Add a small amount of random noise to break symmetry\n    x_grid += np.random.normal(0, 0.01, n)\n    y_grid += np.random.normal(0, 0.01, n)\n    inits.append(np.concatenate([x_grid, y_grid, np.ones(n) * 0.08]))\n\n    # 2. Random starts\n    for _ in range(15):\n        x_rand = np.random.uniform(0.1, 0.9, n)\n        y_rand = np.random.uniform(0.1, 0.9, n)\n        inits.append(np.concatenate([x_rand, y_rand, np.ones(n) * 0.05]))\n        \n    # --- Global Search Phase ---\n    for v0 in inits:\n        if time.time() - start_time > 200:\n            break\n        \n        # SLSQP optimization for the current start\n        res = minimize(objective, v0, method='SLSQP', \n                       jac=objective_grad,\n                       constraints={'type': 'ineq', 'fun': con_func},\n                       bounds=[(0, 1)] * (2 * n) + [(0, 0.5)] * n,\n                       options={'maxiter': 80})\n        \n        if -res.fun > best_sum:\n            best_sum = -res.fun\n            best_v = res.x\n        \n        # If we reach a value close to the best known, we can focus on refining it\n        if best_sum > 2.6359:\n            break\n\n    # --- Shrink-and-Grow Refinement Phase ---\n    if best_v is not None:\n        v_current = best_v.copy()\n        while time.time() - start_time < 285:\n            # Shrink: reduce radii slightly\n            v_nudge = v_current.copy()\n            v_nudge[2*n:] *= 0.98\n            # Nudge: add small random noise to centers\n            v_nudge[:2*n] += np.random.normal(0, 0.005, 2 * n)\n            v_nudge[:2*n] = np.clip(v_nudge[:2*n], 0, 1)\n            \n            # Re-optimize (Grow)\n            res = minimize(objective, v_nudge, method='SLSQP', \n                           jac=objective_grad,\n                           constraints={'type': 'ineq', 'fun': con_func},\n                           bounds=[(0, 1)] * (2 * n) + [(0, 0.5)] * n,\n                           options={'maxiter': 100})\n            \n            if -res.fun > best_sum:\n                best_sum = -res.fun\n                best_v = res.x\n                v_current = res.x\n            else:\n                # Still use the local result to keep exploring the configuration space\n                v_current = res.x\n\n    # Prepare results\n    centers = np.vstack([best_v[:n], best_v[n:2*n]]).T\n    radii = best_v[2*n:]\n    sum_radii = best_sum\n    \n    return centers, radii, sum_radii\n\nif __name__ == \"__main__\":\n    centers, radii, sum_radii = run_packing()",
  "metrics": {
    "valid": false,
    "score": 0.0,
    "eval_time": 285.56105518341064,
    "error": "Circle 7 at (0.84156727344731, 0.3057116130639868) with radius 0.26579440797660436 extends outside x-bounds"
  },
  "prompt": "Use a 'Shrink-and-Grow' strategy. Start with a random configuration. 1. Optimize sum of radii using SLSQP. 2. Identify the smallest circles and 'nudge' them towards larger gaps or swap them with neighbors. 3. Slightly shrink all radii to allow centers to move more freely, then re-optimize. This helps the configuration escape local optima that are 'jammed'.",
  "response": "```python\nimport numpy as np\nfrom scipy.optimize import minimize\nimport time\n\ndef run_packing():\n    \"\"\"\n    Pack 26 circles into a unit square [0,1] x [0,1] to maximize the sum of their radii.\n    Uses a multi-start strategy followed by a 'Shrink-and-Grow' local optimization.\n    \"\"\"\n    n = 26\n    i_idx, j_idx = np.triu_indices(n, k=1)\n\n    def con_func(v):\n        \"\"\"\n        Constraints: circles must be inside the square and must not overlap.\n        \"\"\"\n        x = v[:n]\n        y = v[n:2*n]\n        r = v[2*n:]\n        \n        # Boundary constraints: x_i - r_i >= 0, 1 - x_i - r_i >= 0, etc.\n        c_boundary = np.empty(4 * n)\n        c_boundary[0:n] = x - r\n        c_boundary[n:2*n] = 1.0 - x - r\n        c_boundary[2*n:3*n] = y - r\n        c_boundary[3*n:4*n] = 1.0 - y - r\n        \n        # Overlap constraints: (x_i - x_j)^2 + (y_i - y_j)^2 - (r_i + r_j)^2 >= 0\n        c_overlap = (x[i_idx] - x[j_idx])**2 + (y[i_idx] - y[j_idx])**2 - (r[i_idx] + r[j_idx])**2\n        \n        return np.concatenate([c_boundary, c_overlap])\n\n    def objective(v):\n        \"\"\"Maximize sum of radii.\"\"\"\n        return -np.sum(v[2*n:])\n\n    def objective_grad(v):\n        \"\"\"Gradient of the objective function.\"\"\"\n        grad = np.zeros(3 * n)\n        grad[2*n:] = -1.0\n        return grad\n\n    best_v = None\n    best_sum = 0\n    start_time = time.time()\n    \n    # --- Initialization Phase ---\n    inits = []\n    \n    # 1. Grid-based start (5x5 grid plus one extra circle)\n    grid_coords = np.linspace(0.12, 0.88, 5)\n    xx, yy = np.meshgrid(grid_coords, grid_coords)\n    x_grid = np.append(xx.flatten(), 0.5)\n    y_grid = np.append(yy.flatten(), 0.5)\n    # Add a small amount of random noise to break symmetry\n    x_grid += np.random.normal(0, 0.01, n)\n    y_grid += np.random.normal(0, 0.01, n)\n    inits.append(np.concatenate([x_grid, y_grid, np.ones(n) * 0.08]))\n\n    # 2. Random starts\n    for _ in range(15):\n        x_rand = np.random.uniform(0.1, 0.9, n)\n        y_rand = np.random.uniform(0.1, 0.9, n)\n        inits.append(np.concatenate([x_rand, y_rand, np.ones(n) * 0.05]))\n        \n    # --- Global Search Phase ---\n    for v0 in inits:\n        if time.time() - start_time > 200:\n            break\n        \n        # SLSQP optimization for the current start\n        res = minimize(objective, v0, method='SLSQP', \n                       jac=objective_grad,\n                       constraints={'type': 'ineq', 'fun': con_func},\n                       bounds=[(0, 1)] * (2 * n) + [(0, 0.5)] * n,\n                       options={'maxiter': 80})\n        \n        if -res.fun > best_sum:\n            best_sum = -res.fun\n            best_v = res.x\n        \n        # If we reach a value close to the best known, we can focus on refining it\n        if best_sum > 2.6359:\n            break\n\n    # --- Shrink-and-Grow Refinement Phase ---\n    if best_v is not None:\n        v_current = best_v.copy()\n        while time.time() - start_time < 285:\n            # Shrink: reduce radii slightly\n            v_nudge = v_current.copy()\n            v_nudge[2*n:] *= 0.98\n            # Nudge: add small random noise to centers\n            v_nudge[:2*n] += np.random.normal(0, 0.005, 2 * n)\n            v_nudge[:2*n] = np.clip(v_nudge[:2*n], 0, 1)\n            \n            # Re-optimize (Grow)\n            res = minimize(objective, v_nudge, method='SLSQP', \n                           jac=objective_grad,\n                           constraints={'type': 'ineq', 'fun': con_func},\n                           bounds=[(0, 1)] * (2 * n) + [(0, 0.5)] * n,\n                           options={'maxiter': 100})\n            \n            if -res.fun > best_sum:\n                best_sum = -res.fun\n                best_v = res.x\n                v_current = res.x\n            else:\n                # Still use the local result to keep exploring the configuration space\n                v_current = res.x\n\n    # Prepare results\n    centers = np.vstack([best_v[:n], best_v[n:2*n]]).T\n    radii = best_v[2*n:]\n    sum_radii = best_sum\n    \n    return centers, radii, sum_radii\n\nif __name__ == \"__main__\":\n    centers, radii, sum_radii = run_packing()\n```",
  "reasoning": "",
  "timestamp": "2026-02-10T23:38:19.570799",
  "cost_data": null,
  "model_config": {
    "model": "gemini-3-flash-preview",
    "temperature": 0.7,
    "provider_debug": {
      "finish_reason": "STOP",
      "usage_metadata": {
        "prompt_token_count": 312,
        "candidates_token_count": 1446,
        "thoughts_token_count": 19192
      },
      "response_text_len": 4135
    }
  },
  "llm_call_duration_s": 119.7815900829155,
  "eval_duration_s": 285.56106259301305
}