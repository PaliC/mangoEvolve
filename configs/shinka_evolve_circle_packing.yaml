# Shinka Evolve config: GPT-5 as root, mixed Google/OpenRouter children
# Uses native Google API for Gemini models, OpenRouter for everything else
#
# Requires: OPENROUTER_API_KEY + GEMINI_API_KEY environment variables
#
# Models used:
#   - Root: GPT-5 with xhigh reasoning (OpenRouter)
#   - Children: Gemini 2.5 Pro, Gemini 2.5 Flash (Google),
#     Claude Sonnet 4 (OpenRouter), O4-mini, GPT-5, GPT-5-mini, GPT-5-nano (OpenRouter)

experiment:
  name: "shinka_evolve_circle_packing"
  output_dir: "./experiments"

# Root LLM: GPT-5 with high reasoning for smart orchestration
root_llm:
  provider: "openrouter"
  model: "openai/gpt-5"
  cost_per_million_input_tokens: 1.25
  cost_per_million_output_tokens: 10.00
  max_iterations: 500
  reasoning:
    enabled: true
    effort: "high"

# Multiple child LLMs - root can choose based on task
child_llms:
  # Gemini 2.5 Pro - strong reasoning via native Google API
  - alias: "gemini-pro"
    model: "gemini-2.5-pro"
    provider: "google"
    cost_per_million_input_tokens: 1.25
    cost_per_million_output_tokens: 10.00
    calibration_calls: 5
    reasoning:
      enabled: true
      effort: "high"

  # Gemini 2.5 Flash - fast and cost-effective via native Google API
  - alias: "gemini-flash"
    model: "gemini-2.5-flash"
    provider: "google"
    cost_per_million_input_tokens: 0.30
    cost_per_million_output_tokens: 2.50
    calibration_calls: 5
    reasoning:
      enabled: true
      effort: "high"

  # Claude Sonnet 4 via OpenRouter (Bedrock-backed)
  - alias: "sonnet"
    model: "anthropic/claude-sonnet-4"
    provider: "openrouter"
    cost_per_million_input_tokens: 3.00
    cost_per_million_output_tokens: 15.00
    calibration_calls: 5
    reasoning:
      enabled: true
      effort: "high"

  # O4-mini - OpenAI reasoning model, cost-effective
  - alias: "o4-mini"
    model: "openai/o4-mini"
    provider: "openrouter"
    cost_per_million_input_tokens: 1.10
    cost_per_million_output_tokens: 4.40
    calibration_calls: 5
    reasoning:
      enabled: true
      effort: "high"

  # GPT-5 - high quality reasoning
  - alias: "gpt5"
    model: "openai/gpt-5"
    provider: "openrouter"
    cost_per_million_input_tokens: 1.25
    cost_per_million_output_tokens: 10.00
    calibration_calls: 5
    reasoning:
      enabled: true
      effort: "high"

  # GPT-5-mini - good quality, cost-effective
  - alias: "gpt5-mini"
    model: "openai/gpt-5-mini"
    provider: "openrouter"
    cost_per_million_input_tokens: 0.25
    cost_per_million_output_tokens: 2.00
    calibration_calls: 5

  # GPT-5-nano - fastest, most cost-effective
  - alias: "gpt5-nano"
    model: "openai/gpt-5-nano"
    provider: "openrouter"
    cost_per_million_input_tokens: 0.05
    cost_per_million_output_tokens: 0.40
    calibration_calls: 5

default_child_llm_alias: "gemini-flash"

evaluation:
  evaluator_fn: "mango_evolve.evaluation.circle_packing:CirclePackingEvaluator"
  evaluator_kwargs:
    n_circles: 26
    timeout_seconds: 300

evolution:
  max_generations: 20
  max_children_per_generation: 8

budget:
  max_total_cost: 50.0
